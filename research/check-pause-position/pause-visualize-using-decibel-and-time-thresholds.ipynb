{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デシベルと、時間長の閾値を用いて、pauseを抽出する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import ndimage\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/Users/takeshitashunji/Programming/Python/PausePrediction/data\")\n",
    "assert DATA_DIR.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvs_path = Path(\"/Users/takeshitashunji/Downloads/jvs_ver1 2\")\n",
    "\n",
    "# jvs001~jvs100\n",
    "jvs_list = [f\"{i:03}\" for i in range(1, 101)]\n",
    "\n",
    "# wavファイルのパスをデータフレームを作成\n",
    "\n",
    "columns = [\"jvs\", \"speach_type\", \"wav_path\", \"lab_path\"]\n",
    "\n",
    "df = []\n",
    "\n",
    "for jvs in jvs_list:\n",
    "    for speach_type in [\"parallel100\", \"nonpara30\"]:\n",
    "        wav_files = Path(jvs_path / f\"jvs{jvs}\" / speach_type / \"wav24kHz16bit\").glob(\n",
    "            \"*.wav\"\n",
    "        )\n",
    "        base_names = [wav_file.stem for wav_file in wav_files]\n",
    "        for base_name in base_names:\n",
    "            wav_path = (\n",
    "                jvs_path\n",
    "                / f\"jvs{jvs}\"\n",
    "                / speach_type\n",
    "                / \"wav24kHz16bit\"\n",
    "                / f\"{base_name}.wav\"\n",
    "            )\n",
    "            lab_path = (\n",
    "                jvs_path\n",
    "                / f\"jvs{jvs}\"\n",
    "                / speach_type\n",
    "                / \"lab\"\n",
    "                / \"mon\"\n",
    "                / f\"{base_name}.lab\"\n",
    "            )\n",
    "            df.append([jvs, speach_type, wav_path, lab_path])\n",
    "\n",
    "df_jvs = pd.DataFrame(df, columns=columns)\n",
    "\n",
    "df_jvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 音声波形を抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声波形を抽出する。\n",
    "def extract_audio_waveform(audio_file_path, sr=24000):\n",
    "    waveform, sample_rate = librosa.load(audio_file_path, mono=True)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "\n",
    "wav, sr = extract_audio_waveform(df_jvs.iloc[0][\"wav_path\"])\n",
    "print(wav)\n",
    "print(wav.shape)\n",
    "librosa.display.waveshow(wav, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 波形列を追加する\n",
    "df_jvs[\"wave_sequence\"] = df_jvs[\"wav_path\"].apply(\n",
    "    lambda x: extract_audio_waveform(x, 24000)[0]\n",
    ")\n",
    "df_jvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## db列へ変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = librosa.amplitude_to_db(wav)\n",
    "plt.plot(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jvs[\"db_sequence\"] = df_jvs[\"wave_sequence\"].apply(librosa.amplitude_to_db)\n",
    "df_jvs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbと音声長の閾値から、pauseの位置を設定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 連続している部分の抽出\n",
    "  - https://qiita.com/studio_haneya/items/bce843eacb345dfaa97d\n",
    "  - https://qiita.com/isourou/items/a7c32d35a206ec785a6f # これいいね\n",
    "  - https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q12260522332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_length_encoding(arr, min_run_length=3):\n",
    "    \"\"\"\n",
    "    Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "    Parameters:\n",
    "        arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "    \"\"\"\n",
    "    diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))  # 連続する範囲の長さを計算\n",
    "    result = np.repeat(run_lengths >= min_run_length, run_lengths)  # 連続する範囲をTrueに変換\n",
    "    return result\n",
    "\n",
    "\n",
    "# サンプル配列\n",
    "arr = np.array([0, 0, 0, 1, 2, 3, 4, 0, 0, 0, 1, 2])\n",
    "\n",
    "# RLEを実行してブール配列を得る\n",
    "rle_result = run_length_encoding(arr)\n",
    "\n",
    "print(rle_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値の設定\n",
    "db_threshold = -50\n",
    "time_threshold = 50 / 1000  # 50ms\n",
    "sample_rate = 24000\n",
    "\n",
    "\n",
    "# 閾値を超えたらpauseとみなす\n",
    "def detect_pause_position(db_sequence, db_threshold, time_threshold, sample_rate):\n",
    "    \"\"\"dbと音声長の閾値からpauseの位置を判定する。\n",
    "\n",
    "    Args:\n",
    "        db_sequence (np.array): 音声波形をdbに変換した配列\n",
    "        db_threshold (float): 無音区間とするdbの閾値\n",
    "        time_threshold (float): 無音区間が連続した時にpauseとみなす時間の閾値\n",
    "\n",
    "    Returns:\n",
    "        pause_positions (list): pauseの位置のリスト\n",
    "    \"\"\"\n",
    "    under_db_threshold = db_sequence < db_threshold\n",
    "\n",
    "    # 連続区間を抽出\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    is_continuous = run_length_encoding(under_db_threshold, sample_threshold)\n",
    "\n",
    "    # pauseの位置を抽出\n",
    "    pause_positions = under_db_threshold & is_continuous\n",
    "\n",
    "    return pause_positions\n",
    "\n",
    "\n",
    "db_sequence = df_jvs.iloc[0][\"db_sequence\"]\n",
    "pause_position = detect_pause_position(\n",
    "    db_sequence, db_threshold, time_threshold, sample_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 波形の上にpauseの位置を可視化する\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "x = np.arange(len(db_sequence)) / sample_rate\n",
    "ax.plot(x, db_sequence)\n",
    "\n",
    "# dbの閾値を引く\n",
    "ax.axhline(\n",
    "    y=db_threshold,\n",
    "    color=\"r\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    "    alpha=0.7,\n",
    "    label=\"db_threshold\",\n",
    ")\n",
    "\n",
    "# pauseの領域を塗りつぶす\n",
    "plt.fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = extract_audio_waveform(df_jvs.iloc[0][\"wav_path\"])\n",
    "print(wav)\n",
    "print(wav.shape)\n",
    "plt.figure(figsize=(20, 5))\n",
    "librosa.display.waveshow(wav, sr=sr)\n",
    "plt.show()\n",
    "\n",
    "Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値の設定\n",
    "db_threshold = -50\n",
    "time_threshold = 50 / 1000  # 50ms\n",
    "sample_rate = 24000\n",
    "\n",
    "df_jvs[\"db_threshold\"] = db_threshold\n",
    "df_jvs[\"time_threshold\"] = time_threshold\n",
    "df_jvs[\"sr\"] = sample_rate\n",
    "df_jvs[\"pause_position\"] = df_jvs[\"db_sequence\"].apply(\n",
    "    detect_pause_position, args=(db_threshold, time_threshold, sample_rate)\n",
    ")\n",
    "\n",
    "df_jvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jvs.to_csv(\"jvs-pause-visualize.csv\", index=False)\n",
    "df_jvs.to_pickle(DATA_DIR / \"jvs-pause-visualize.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juliusの音素アライメントを可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labファイルの取り出し\n",
    "def read_lab(lab_path):\n",
    "    \"\"\"labファイルを読み込む\"\"\"\n",
    "    # labファイルがない場合\n",
    "    if not Path(lab_path).exists():\n",
    "        print(f\"{lab_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # labファイルがある場合\n",
    "    df_lab = []\n",
    "    with open(lab_path, \"r\") as f:\n",
    "        for phoneme_idx, line in enumerate(f):\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            duration = float(end) - float(start)\n",
    "            df_lab.append(\n",
    "                {\n",
    "                    \"start\": float(start),\n",
    "                    \"end\": float(end),\n",
    "                    \"phoneme\": phoneme,\n",
    "                    \"phoneme_idx\": phoneme_idx,\n",
    "                    \"duration\": duration,\n",
    "                }\n",
    "            )\n",
    "    df_lab = pd.DataFrame(df_lab)\n",
    "    return df_lab\n",
    "\n",
    "\n",
    "read_lab(df_jvs.iloc[0][\"lab_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_phoneme_alignment(lab_path):\n",
    "    \"\"\"Labファイルから音素のアライメントをプロットする\n",
    "\n",
    "    Args:\n",
    "        lab_path (_type_): Labファイルのパス\n",
    "    \"\"\"\n",
    "    df = read_lab(lab_path)\n",
    "\n",
    "    # 描画\n",
    "    fig, ax = plt.subplots(figsize=(20, 2))\n",
    "    for start, end, label, _, _ in df.values:\n",
    "        ax.axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax.text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(0, df[\"end\"].max())\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_phoneme_alignment(df_jvs.loc[0, \"lab_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 並べて可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    3, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4, 2]}\n",
    ")\n",
    "\n",
    "\n",
    "# Plot 1\n",
    "# Plot the original audio signal\n",
    "wav, sr = extract_audio_waveform(df_jvs.iloc[0][\"wav_path\"])\n",
    "axes[0].plot(np.arange(len(wav)) / sr, wav)\n",
    "# librosa.display.waveshow(wav, sr=sr, ax=axes[0])\n",
    "axes[0].set_title(\"Original audio signal\")\n",
    "# axes[0].set_xlabel('Time (seconds)')\n",
    "axes[0].set_ylabel(\"Amplitude\")\n",
    "axes[0].set_xlim(0, len(wav) / sr)\n",
    "\n",
    "# Plot 2\n",
    "# Plot the audio db signal with the pause positions\n",
    "db_sequence = df_jvs.iloc[0][\"db_sequence\"]\n",
    "pause_position = detect_pause_position(\n",
    "    db_sequence, db_threshold, time_threshold, sample_rate\n",
    ")\n",
    "x = np.arange(len(db_sequence)) / sample_rate\n",
    "axes[1].plot(x, db_sequence)\n",
    "# dbの閾値を引く\n",
    "axes[1].axhline(\n",
    "    y=db_threshold,\n",
    "    color=\"r\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    "    alpha=0.7,\n",
    "    label=\"db_threshold\",\n",
    ")\n",
    "# pauseの領域を塗りつぶす\n",
    "axes[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "axes[1].set_title(\"Audio db signal with the pause positions\")\n",
    "# axes[1].set_xlabel('Time (seconds)')\n",
    "axes[1].set_ylabel(\"Amplitude (db)\")\n",
    "axes[1].set_xlim(0, len(db_sequence) / sample_rate)\n",
    "\n",
    "# Plot 3\n",
    "# Plot the phoneme alignment\n",
    "df = read_lab(df_jvs.iloc[0][\"lab_path\"])\n",
    "for start, end, label, _, _ in df.values:\n",
    "    axes[2].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "    axes[2].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "axes[2].set_yticks([])\n",
    "axes[2].set_xlim(0, df[\"end\"].max())\n",
    "axes[2].set_xlabel(\"Time (seconds)\")\n",
    "axes[2].set_title(\"Phoneme alignment\")\n",
    "plt.show()\n",
    "\n",
    "# Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_features(\n",
    "    df_jvs,\n",
    "    db_threshold=-50,\n",
    "    time_threshold=50 / 1000,\n",
    "    sample_rate=24000,\n",
    "    idxloc=0,\n",
    "    savefig=False,\n",
    "):\n",
    "    fig, axes = plt.subplots(\n",
    "        3, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4, 2]}\n",
    "    )\n",
    "\n",
    "    # Plot 1\n",
    "    # Plot the original audio signal\n",
    "    wav, sr = extract_audio_waveform(df_jvs.iloc[idxloc][\"wav_path\"])\n",
    "    axes[0].plot(np.arange(len(wav)) / sr, wav)\n",
    "    # librosa.display.waveshow(wav, sr=sr, ax=axes[0])\n",
    "    axes[0].set_title(\"Original audio signal\")\n",
    "    # axes[0].set_xlabel('Time (seconds)')\n",
    "    axes[0].set_ylabel(\"Amplitude\")\n",
    "    axes[0].set_xlim(0, len(wav) / sr)\n",
    "\n",
    "    # Plot 2\n",
    "    # Plot the audio db signal with the pause positions\n",
    "    db_sequence = df_jvs.iloc[idxloc][\"db_sequence\"]\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "    x = np.arange(len(db_sequence)) / sample_rate\n",
    "    axes[1].plot(x, db_sequence)\n",
    "    # dbの閾値を引く\n",
    "    axes[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    axes[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    axes[1].set_title(\"Audio db signal with the pause positions\")\n",
    "    # axes[1].set_xlabel('Time (seconds)')\n",
    "    axes[1].set_ylabel(\"Amplitude (db)\")\n",
    "    # axes[1].set_xlim(0, len(db_sequence)/sample_rate)\n",
    "    axes[1].set_xlim(0, len(wav) / sr)\n",
    "\n",
    "    # Plot 3\n",
    "    # Plot the phoneme alignment\n",
    "    df = read_lab(df_jvs.iloc[idxloc][\"lab_path\"])\n",
    "    for start, end, label, _, _ in df.values:\n",
    "        axes[2].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        axes[2].text(\n",
    "            (start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8\n",
    "        )\n",
    "    axes[2].set_yticks([])\n",
    "    # axes[2].set_xlim(0, df['end'].max())\n",
    "    axes[2].set_xlim(0, len(wav) / sr)\n",
    "    axes[2].set_xlabel(\"Time (seconds)\")\n",
    "    axes[2].set_title(\"Phoneme alignment\")\n",
    "\n",
    "    print(len(wav))\n",
    "    print(len(db_sequence))\n",
    "    print(len(pause_position))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        wav_path = Path(df_jvs.iloc[idxloc][\"wav_path\"])\n",
    "        dir_path = wav_path.parent\n",
    "        save_path = dir_path / f\"{wav_path.stem}-visualize.png\"\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features(df_jvs, db_threshold=-70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features(df_jvs, db_threshold=-50, time_threshold=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features(df_jvs, db_threshold=-50, time_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df_jvs)):\n",
    "    plot_audio_features(df_jvs, idxloc=idx, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ポーズ分析\n",
    "\n",
    "閾値によって得られた、ポーズを以下の3つに分類する。\n",
    "- sil\n",
    "- PIP：句読点のポーズ\n",
    "- RP：それ以外のポーズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfy_pause(\n",
    "    db_sequence, lab_path, db_threshold=-50, time_threshold=0.05, sample_rate=24000\n",
    "):\n",
    "    \"\"\"ポーズを分類する\n",
    "\n",
    "    Args:\n",
    "        df_jvs (_type_): _description_\n",
    "    \"\"\"\n",
    "    # db_threshold = -50\n",
    "    # time_threshold = 0.05\n",
    "    # sample_rate = 24000\n",
    "\n",
    "    # db_sequence = df_jvs.iloc[0]['db_sequence']\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    def run_length_encoding_range(arr, min_run_length=3):\n",
    "        \"\"\"\n",
    "        Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "        Parameters:\n",
    "            arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "            min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "            list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "        \"\"\"\n",
    "        diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "        run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "        starts = np.concatenate(([0], run_starts))\n",
    "        ends = np.concatenate((run_starts, [len(arr)]))\n",
    "        lengths = ends - starts\n",
    "        ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "        # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "        ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "\n",
    "    # print(pause_ranges)\n",
    "\n",
    "    # df_lab = read_lab(df_jvs.iloc[0]['lab_path'])\n",
    "    df_lab = read_lab(lab_path)\n",
    "\n",
    "    ans = []\n",
    "    for pause_range in pause_ranges:\n",
    "        # df_labのstartもしくは、endが、start, endの範囲内にあるかどうか\n",
    "        pause_start = pause_range[0]\n",
    "        pause_end = pause_range[1]\n",
    "        phoneme_start = df_lab[\"start\"].values * sample_rate\n",
    "        phoneme_end = df_lab[\"end\"].values * sample_rate\n",
    "        is_start_include = (pause_start <= phoneme_start) & (phoneme_start <= pause_end)\n",
    "        is_end_include = (pause_start <= phoneme_end) & (phoneme_end <= pause_end)\n",
    "\n",
    "        include_phonemes = df_lab[is_start_include | is_end_include][\"phoneme\"].values\n",
    "        print(include_phonemes)\n",
    "\n",
    "        if \"sil\" in include_phonemes:\n",
    "            pause_type = \"sil\"\n",
    "        elif \"pau\" in include_phonemes:\n",
    "            pause_type = \"PIP\"\n",
    "        else:\n",
    "            pause_type = \"RP\"\n",
    "\n",
    "        ans.append([pause_range[0], pause_range[1], pause_range[2], pause_type])\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "# 各pause日して、start, end, duration, 分類\n",
    "\n",
    "# df = read_lab(df_jvs.iloc[0]['lab_path'])\n",
    "\n",
    "ans = classfy_pause(df_jvs.iloc[0][\"db_sequence\"], df_jvs.iloc[0][\"lab_path\"])\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvs_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
