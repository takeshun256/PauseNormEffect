{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 早口のオーディオブックが本当に早口か確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 速度0.1 (s/mora)のオーディオブックがあり、本当に早口か確認するために、音声を聞いてみる。\n",
    "\n",
    "- 速度の可視化\n",
    "  - /home/takeshun256/PausePrediction/research/analyze_jmac/check_db_based_pause/話者ごとの話速とポーズ長の関係.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "# conda activate pyopenjtalk_julius\n",
    "\n",
    "# set path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "# import standard library\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# import pyopenjtalk\n",
    "# from pyopenjtalk import run_frontend, g2p\n",
    "import jaconv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import own library\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "\n",
    "# from src.analyze_jmac.text_preprocessing import (\n",
    "#     AudiobookScriptPreprocessor as Preprocessor,\n",
    "# )\n",
    "from src.analyze_jmac.mecab import mecab_wakati_generator, mecab_detailed_generator\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()\n",
    "\n",
    "import csv\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/analyze_jmac\")\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/vad_tool\")\n",
    "from audiobook_yaml_parser import extract_yaml_data\n",
    "from py_webrtcvad_test import getVadSection\n",
    "from vad_tool import VAD_Segmenter\n",
    "from audiobook_dataset_builder import AudiobookDatasetBuilder\n",
    "from audiobook_script_extractor import AudiobookScriptExtractor\n",
    "\n",
    "# python==3.11以上の場合はimportしない\n",
    "# if sys.version_info < (3, 11):\n",
    "#     from text_preprocessing_preprocessor import AudiobookScriptPreprocessor\n",
    "# from text_preprocessing import AudiobookScriptPreprocessor\n",
    "from julius_lab_analysis import JuliusLabAnalyzer\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.io import wavfile\n",
    "import scipy.io.wavfile\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import webrtcvad\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import struct\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "import soundfile as sf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声波形抽出\n",
    "# wav_path -> wav, sr\n",
    "def extract_waveform(audio_file_path, sr=24000):\n",
    "    waveform, sample_rate = librosa.load(audio_file_path, sr=sr, mono=True)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "\n",
    "# wav -> db変換\n",
    "def convert_db(waveform):\n",
    "    # TODO: これは何が違うのか？どちらが適切か？\n",
    "    # db = librosa.power_to_db(waveform)\n",
    "    db = librosa.amplitude_to_db(waveform, ref=np.max)\n",
    "    return db\n",
    "\n",
    "\n",
    "# 連続区間抽出\n",
    "# db -> bool_list\n",
    "def run_length_encoding(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))  # 連続する範囲の長さを計算\n",
    "    result = np.repeat(run_lengths >= min_run_length, run_lengths)  # 連続する範囲をTrueに変換\n",
    "    return result\n",
    "\n",
    "def run_length_encoding_range(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)\n",
    "    run_starts = np.where(diff != 0)[0] + 1\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))\n",
    "    # 連続する範囲の開始、終了インデックスと長さを計算\n",
    "    runs = np.concatenate(([0], run_starts))\n",
    "    ranges_with_length = [(start, start + length, length) for start, length in zip(runs, run_lengths) \n",
    "                        if length >= min_run_length and arr[start]]\n",
    "    return ranges_with_length\n",
    "\n",
    "# Pause区間抽出\n",
    "# db, db_threshold, time_threshold, sr -> pause_bool_list\n",
    "# 閾値を超えたらpauseとみなす\n",
    "def detect_pause_position(\n",
    "    db_sequence, db_threshold=-50, time_threshold=50 / 1000, sample_rate=24000\n",
    "):\n",
    "    \"\"\"dbと音声長の閾値からpauseの位置を判定する。\n",
    "\n",
    "    Args:\n",
    "        db_sequence (np.array): 音声波形をdbに変換した配列\n",
    "        db_threshold (float): 無音区間とするdbの閾値\n",
    "        time_threshold (float): 無音区間が連続した時にpauseとみなす時間の閾値\n",
    "\n",
    "    Returns:\n",
    "        pause_positions (list): pauseの位置のリスト\n",
    "    \"\"\"\n",
    "    under_db_threshold = db_sequence < db_threshold\n",
    "\n",
    "    # 連続区間を抽出\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    is_continuous = run_length_encoding(under_db_threshold, sample_threshold)\n",
    "\n",
    "    # pauseの位置を抽出\n",
    "    pause_positions = under_db_threshold & is_continuous\n",
    "\n",
    "    return pause_positions\n",
    "\n",
    "\n",
    "# pause区間付きの波形の可視化\n",
    "def plot_db_with_pause(db, sr, db_threshold, time_threshold, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax.plot(x, db, label=\"db\")\n",
    "\n",
    "    # dbの閾値を引く\n",
    "    ax.axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        # label=\"db_threshold\",\n",
    "    )\n",
    "\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    plt.fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "\n",
    "    ax.set_xlim(xlim)\n",
    "    # ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 波形の可視化\n",
    "def plot_wavform(waveform, sr, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(waveform)) / sr\n",
    "    ax.plot(x, waveform, label=\"waveform\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 音声再生ボタン生成\n",
    "def play_button(waveform, sr):\n",
    "    display(Audio(waveform, rate=sr, autoplay=True))\n",
    "\n",
    "\n",
    "# アライメントの抽出\n",
    "# lab_path -> df_lab\n",
    "def read_lab(lab_path):\n",
    "    \"\"\"labファイルを読み込む\"\"\"\n",
    "    # labファイルがない場合\n",
    "    if not Path(lab_path).exists():\n",
    "        print(f\"{lab_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # labファイルがある場合\n",
    "    df_lab = []\n",
    "    with open(lab_path, \"r\") as f:\n",
    "        for phoneme_idx, line in enumerate(f):\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            duration = float(end) - float(start)\n",
    "            df_lab.append(\n",
    "                {\n",
    "                    \"start\": float(start),\n",
    "                    \"end\": float(end),\n",
    "                    \"phoneme\": phoneme,\n",
    "                    \"phoneme_idx\": phoneme_idx,\n",
    "                    \"duration\": duration,\n",
    "                }\n",
    "            )\n",
    "    df_lab = pd.DataFrame(df_lab)\n",
    "    return df_lab\n",
    "\n",
    "\n",
    "# アライメントの可視化\n",
    "def plot_phoneme_alignment(df, xlim=None):\n",
    "    \"\"\"Labファイルから音素のアライメントをプロットする\n",
    "\n",
    "    Args:\n",
    "        lab_path (_type_): Labファイルのパス\n",
    "    \"\"\"\n",
    "    # df = read_lab(lab_path)\n",
    "    # display(df[-10:])\n",
    "\n",
    "    # 描画\n",
    "    fig, ax = plt.subplots(figsize=(20, 2))\n",
    "    for start, end, label in df.values:\n",
    "        ax.axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax.text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4, 2]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[2].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax[2].set_xlim(xlim)\n",
    "    ax[2].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all2(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        2, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    # ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].plot(x, wav)\n",
    "    ax[0].set_xlim(xlim)\n",
    "    # ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    # ax[1].plot(x, db, label=\"db\")\n",
    "    ax[1].plot(x, db)\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        # label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    # ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[0].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "    # ax.set_yticks([])\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[1].set_xlabel(\"Time (s)\", fontsize=26)\n",
    "    ax[0].set_ylabel(\"Amplitude\", fontsize=26)\n",
    "    ax[1].set_ylabel(\"Amplitude(db)\", fontsize=26)\n",
    "    # xtickのfontsize=20\n",
    "    ax[0].tick_params(labelsize=20)\n",
    "    ax[1].tick_params(labelsize=20)\n",
    "    # ax[2].tight_layout()\n",
    "    ax[0].legend()\n",
    "\n",
    "    # plt.show(\n",
    "    plt.savefig(\"decibel_plot.svg\", bbox_inches='tight')\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "def get_pause_ranges(\n",
    "    db_sequence, db_threshold=-50, time_threshold=0.05, sample_rate=24000\n",
    "):\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    # def run_length_encoding_range(arr, min_run_length=3):\n",
    "    #     \"\"\"\n",
    "    #     Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "    #     Parameters:\n",
    "    #         arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "    #         min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "    #     Returns:\n",
    "    #         numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "    #         list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "    #     \"\"\"\n",
    "    #     diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    #     run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "    #     starts = np.concatenate(([0], run_starts))\n",
    "    #     ends = np.concatenate((run_starts, [len(arr)]))\n",
    "    #     lengths = ends - starts\n",
    "    #     ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "    #     # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "    #     ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "    #     return ranges\n",
    "\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "    return pause_ranges\n",
    "\n",
    "\n",
    "def classfy_pause(\n",
    "    db_sequence, lab_path, sample_rate=24000, db_threshold=-50, time_threshold=0.05\n",
    "):\n",
    "    \"\"\"ポーズを分類する\n",
    "\n",
    "    Args:\n",
    "        df_jvs (_type_): _description_\n",
    "    \"\"\"\n",
    "    # db_threshold = -50\n",
    "    # time_threshold = 0.05\n",
    "    # sample_rate = 24000\n",
    "\n",
    "    # db_sequence = df_jvs.iloc[0]['db_sequence']\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    # def run_length_encoding_range(arr, min_run_length=3):\n",
    "    #     \"\"\"\n",
    "    #     Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "    #     Parameters:\n",
    "    #         arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "    #         min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "    #     Returns:\n",
    "    #         numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "    #         list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "    #     \"\"\"\n",
    "    #     diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    #     run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "    #     starts = np.concatenate(([0], run_starts))\n",
    "    #     ends = np.concatenate((run_starts, [len(arr)]))\n",
    "    #     lengths = ends - starts\n",
    "    #     ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "    #     # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "    #     ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "    #     return ranges\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "\n",
    "    # print(pause_ranges)\n",
    "\n",
    "    # df_lab = read_lab(df_jvs.iloc[0]['lab_path'])\n",
    "    df_lab = read_lab(lab_path)\n",
    "\n",
    "    ans = []\n",
    "    for pause_range in pause_ranges:\n",
    "        # df_labのstartもしくは、endが、start, endの範囲内にあるかどうか\n",
    "        pause_start = pause_range[0]\n",
    "        pause_end = pause_range[1]\n",
    "        phoneme_start = df_lab[\"start\"].values * sample_rate\n",
    "        phoneme_end = df_lab[\"end\"].values * sample_rate\n",
    "        is_start_include = (pause_start <= phoneme_start) & (phoneme_start <= pause_end)\n",
    "        is_end_include = (pause_start <= phoneme_end) & (phoneme_end <= pause_end)\n",
    "\n",
    "        include_phonemes = df_lab[is_start_include | is_end_include][\"phoneme\"].values\n",
    "        print(include_phonemes)\n",
    "        if \"silE\" in include_phonemes:\n",
    "            pause_type = \"silE\"\n",
    "        elif \"silB\" in include_phonemes:\n",
    "            pause_type = \"silB\"\n",
    "        elif \"sil\" in include_phonemes:\n",
    "            pause_type = \"sil\"\n",
    "        elif \"pau\" in include_phonemes:\n",
    "            pause_type = \"pau\"\n",
    "        elif \"sp\" in include_phonemes:\n",
    "            pause_type = \"sp\"\n",
    "        else:\n",
    "            pause_type = \"RP\"\n",
    "\n",
    "        ans.append([pause_range[0], pause_range[1], pause_range[2], pause_type])\n",
    "    return ans\n",
    "\n",
    "def extract_pause_ranges_from_wavpath(\n",
    "    wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイルからpauseの位置を抽出する\"\"\"\n",
    "\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "\n",
    "    pause_position = detect_pause_position(\n",
    "        db, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "    return pause_ranges\n",
    "\n",
    "\n",
    "# ----setting----\n",
    "# 閾値の設定\n",
    "db_threshold = -30\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 100 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# ---------------\n",
    "wav_p = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_25/audiobook_25_109.wav\"\n",
    "wav, sr = extract_waveform(wav_p, sr=sample_rate)\n",
    "db = convert_db(wav)\n",
    "plot_wavform(wav, sr)\n",
    "plot_db_with_pause(db, sr, db_threshold, time_threshold)\n",
    "pause_ranges = get_pause_ranges(db, db_threshold, time_threshold, sample_rate)\n",
    "print(pause_ranges)\n",
    "pause_ranges_by_wav = extract_pause_ranges_from_wavpath(wav_p, sample_rate, db_threshold, time_threshold)\n",
    "print(pause_ranges_by_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = exp_dir / \"pause_ranges\" / \"rule_based\" / \"df_speed_pause_speaker.pkl\"\n",
    "\n",
    "import pickle\n",
    "with open(fpath, \"rb\") as f:\n",
    "    df_speed_pause_speaker = pickle.load(f)\n",
    "df_speed_pause_speaker = df_speed_pause_speaker.sort_values(\"speed\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speed_pause_speaker.sort_values(\"speed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特に早口のオーディオブックを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiobook_ids = df_speed_pause_speaker[df_speed_pause_speaker[\"speed\"] <= 0.12][\"audiobook_id\"].values\n",
    "print(audiobook_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_from_id(audiobook_id, df_speed_pause_speaker, lab_id=None):\n",
    "    # print(audiobook_id)\n",
    "    df_audiobook = df_speed_pause_speaker[df_speed_pause_speaker[\"audiobook_id\"] == audiobook_id]\n",
    "    display(df_audiobook)\n",
    "    dir_path = Path(\"/data2/takeshun256/jmac_split_and_added_lab\")\n",
    "    wav_paths = sorted(dir_path.glob(f\"{audiobook_id}/*.wav\"))\n",
    "    if lab_id is not None:\n",
    "        lab_path = dir_path / audiobook_id / f\"{audiobook_id}_{lab_id:03d}.labm\"\n",
    "        random_wav_path = dir_path / audiobook_id / f\"{audiobook_id}_{lab_id:03d}.wav\"\n",
    "    else:\n",
    "        random_wav_path = np.random.choice(wav_paths)\n",
    "        # print(random_wav_path)\n",
    "        lab_path = random_wav_path.parent / (random_wav_path.stem + \".labm\")\n",
    "    \n",
    "    assert lab_path.exists(), f\"{lab_path} not found\"\n",
    "    assert random_wav_path.exists(), f\"{random_wav_path} not found\"\n",
    "    \n",
    "    df_temp = read_lab(lab_path)[\"start end phoneme\".split()]\n",
    "    # display(df_temp)\n",
    "    sample_rate = 24000\n",
    "    db_threshold = -30\n",
    "    time_threshold = 100 / 1000  # 100ms\n",
    "    plot_all2(df_temp, random_wav_path, sample_rate, db_threshold, time_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speed_pause_speaker.sort_values(\"pause_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_14\", df_speed_pause_speaker, lab_id=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_14\", df_speed_pause_speaker, lab_id=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_25\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_25\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_41\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_41\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_41\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_56\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_56\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_60\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_60\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_14\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_14\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_34\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_34\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_34\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_34\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_3\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_3\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_42\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_42\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_42\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_42\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_42\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_36\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_35\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_from_id(\"audiobook_45\", df_speed_pause_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvs_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
