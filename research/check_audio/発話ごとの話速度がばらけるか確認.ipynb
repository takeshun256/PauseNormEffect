{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 発話ごとの話速度がばらけるか確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "速度計算のノートブック: 発話ごとの話速度の計算.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "# conda activate pyopenjtalk_julius\n",
    "\n",
    "# set path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "# import standard library\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# import pyopenjtalk\n",
    "# from pyopenjtalk import run_frontend, g2p\n",
    "import jaconv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import own library\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "\n",
    "# from src.analyze_jmac.text_preprocessing import (\n",
    "#     AudiobookScriptPreprocessor as Preprocessor,\n",
    "# )\n",
    "from src.analyze_jmac.mecab import mecab_wakati_generator, mecab_detailed_generator\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()\n",
    "\n",
    "import csv\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/analyze_jmac\")\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/vad_tool\")\n",
    "from audiobook_yaml_parser import extract_yaml_data\n",
    "from py_webrtcvad_test import getVadSection\n",
    "from vad_tool import VAD_Segmenter\n",
    "from audiobook_dataset_builder import AudiobookDatasetBuilder\n",
    "from audiobook_script_extractor import AudiobookScriptExtractor\n",
    "\n",
    "# python==3.11以上の場合はimportしない\n",
    "# if sys.version_info < (3, 11):\n",
    "#     from text_preprocessing_preprocessor import AudiobookScriptPreprocessor\n",
    "# from text_preprocessing import AudiobookScriptPreprocessor\n",
    "from julius_lab_analysis import JuliusLabAnalyzer\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.io import wavfile\n",
    "import scipy.io.wavfile\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import webrtcvad\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import struct\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "import soundfile as sf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声波形抽出\n",
    "# wav_path -> wav, sr\n",
    "def extract_waveform(audio_file_path, sr=24000):\n",
    "    waveform, sample_rate = librosa.load(audio_file_path, sr=sr, mono=True)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "\n",
    "# wav -> db変換\n",
    "def convert_db(waveform):\n",
    "    db = librosa.amplitude_to_db(waveform, ref=np.max)\n",
    "    return db\n",
    "\n",
    "\n",
    "# 連続区間抽出\n",
    "# db -> bool_list\n",
    "def run_length_encoding(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))  # 連続する範囲の長さを計算\n",
    "    result = np.repeat(run_lengths >= min_run_length, run_lengths)  # 連続する範囲をTrueに変換\n",
    "    return result\n",
    "\n",
    "def run_length_encoding_range(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)\n",
    "    run_starts = np.where(diff != 0)[0] + 1\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))\n",
    "    # 連続する範囲の開始、終了インデックスと長さを計算\n",
    "    runs = np.concatenate(([0], run_starts))\n",
    "    ranges_with_length = [(start, start + length, length) for start, length in zip(runs, run_lengths) \n",
    "                        if length >= min_run_length and arr[start]]\n",
    "    return ranges_with_length\n",
    "\n",
    "# Pause区間抽出\n",
    "# db, db_threshold, time_threshold, sr -> pause_bool_list\n",
    "# 閾値を超えたらpauseとみなす\n",
    "def detect_pause_position(\n",
    "    db_sequence, db_threshold=-50, time_threshold=50 / 1000, sample_rate=24000\n",
    "):\n",
    "    \"\"\"dbと音声長の閾値からpauseの位置を判定する。\n",
    "\n",
    "    Args:\n",
    "        db_sequence (np.array): 音声波形をdbに変換した配列\n",
    "        db_threshold (float): 無音区間とするdbの閾値\n",
    "        time_threshold (float): 無音区間が連続した時にpauseとみなす時間の閾値\n",
    "\n",
    "    Returns:\n",
    "        pause_positions (list): pauseの位置のリスト\n",
    "    \"\"\"\n",
    "    under_db_threshold = db_sequence < db_threshold\n",
    "\n",
    "    # 連続区間を抽出\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    is_continuous = run_length_encoding(under_db_threshold, sample_threshold)\n",
    "\n",
    "    # pauseの位置を抽出\n",
    "    pause_positions = under_db_threshold & is_continuous\n",
    "\n",
    "    return pause_positions\n",
    "\n",
    "\n",
    "# pause区間付きの波形の可視化\n",
    "def plot_db_with_pause(db, sr, db_threshold, time_threshold, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax.plot(x, db, label=\"db\")\n",
    "\n",
    "    # dbの閾値を引く\n",
    "    ax.axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    plt.fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 波形の可視化\n",
    "def plot_wavform(waveform, sr, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(waveform)) / sr\n",
    "    ax.plot(x, waveform, label=\"waveform\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 音声再生ボタン生成\n",
    "def play_button(waveform, sr):\n",
    "    display(Audio(waveform, rate=sr, autoplay=True))\n",
    "\n",
    "\n",
    "# アライメントの抽出\n",
    "# lab_path -> df_lab\n",
    "def read_lab(lab_path):\n",
    "    \"\"\"labファイルを読み込む\"\"\"\n",
    "    # labファイルがない場合\n",
    "    if not Path(lab_path).exists():\n",
    "        print(f\"{lab_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # labファイルがある場合\n",
    "    df_lab = []\n",
    "    with open(lab_path, \"r\") as f:\n",
    "        for phoneme_idx, line in enumerate(f):\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            duration = float(end) - float(start)\n",
    "            df_lab.append(\n",
    "                {\n",
    "                    \"start\": float(start),\n",
    "                    \"end\": float(end),\n",
    "                    \"phoneme\": phoneme,\n",
    "                    \"phoneme_idx\": phoneme_idx,\n",
    "                    \"duration\": duration,\n",
    "                }\n",
    "            )\n",
    "    df_lab = pd.DataFrame(df_lab)\n",
    "    return df_lab\n",
    "\n",
    "\n",
    "# アライメントの可視化\n",
    "def plot_phoneme_alignment(df, xlim=None):\n",
    "    \"\"\"Labファイルから音素のアライメントをプロットする\n",
    "\n",
    "    Args:\n",
    "        lab_path (_type_): Labファイルのパス\n",
    "    \"\"\"\n",
    "    # df = read_lab(lab_path)\n",
    "    # display(df[-10:])\n",
    "\n",
    "    # 描画\n",
    "    fig, ax = plt.subplots(figsize=(20, 2))\n",
    "    for start, end, label in df.values:\n",
    "        ax.axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax.text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4, 2]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[2].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax[2].set_xlim(xlim)\n",
    "    ax[2].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all2(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        2, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[0].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "    # ax.set_yticks([])\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[0].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "def get_pause_ranges(\n",
    "    db_sequence, db_threshold=-50, time_threshold=0.05, sample_rate=24000\n",
    "):\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    # def run_length_encoding_range(arr, min_run_length=3):\n",
    "    #     \"\"\"\n",
    "    #     Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "    #     Parameters:\n",
    "    #         arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "    #         min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "    #     Returns:\n",
    "    #         numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "    #         list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "    #     \"\"\"\n",
    "    #     diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    #     run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "    #     starts = np.concatenate(([0], run_starts))\n",
    "    #     ends = np.concatenate((run_starts, [len(arr)]))\n",
    "    #     lengths = ends - starts\n",
    "    #     ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "    #     # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "    #     ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "    #     return ranges\n",
    "\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "    return pause_ranges\n",
    "\n",
    "\n",
    "def classfy_pause(\n",
    "    db_sequence, lab_path, sample_rate=24000, db_threshold=-50, time_threshold=0.05\n",
    "):\n",
    "    \"\"\"ポーズを分類する\n",
    "\n",
    "    Args:\n",
    "        df_jvs (_type_): _description_\n",
    "    \"\"\"\n",
    "    # db_threshold = -50\n",
    "    # time_threshold = 0.05\n",
    "    # sample_rate = 24000\n",
    "\n",
    "    # db_sequence = df_jvs.iloc[0]['db_sequence']\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "\n",
    "    # print(pause_ranges)\n",
    "\n",
    "    # df_lab = read_lab(df_jvs.iloc[0]['lab_path'])\n",
    "    df_lab = read_lab(lab_path)\n",
    "\n",
    "    ans = []\n",
    "    for pause_range in pause_ranges:\n",
    "        # df_labのstartもしくは、endが、start, endの範囲内にあるかどうか\n",
    "        pause_start = pause_range[0]\n",
    "        pause_end = pause_range[1]\n",
    "        phoneme_start = df_lab[\"start\"].values * sample_rate\n",
    "        phoneme_end = df_lab[\"end\"].values * sample_rate\n",
    "        is_start_include = (pause_start <= phoneme_start) & (phoneme_start <= pause_end)\n",
    "        is_end_include = (pause_start <= phoneme_end) & (phoneme_end <= pause_end)\n",
    "\n",
    "        include_phonemes = df_lab[is_start_include | is_end_include][\"phoneme\"].values\n",
    "        print(include_phonemes)\n",
    "        if \"silE\" in include_phonemes:\n",
    "            pause_type = \"silE\"\n",
    "        elif \"silB\" in include_phonemes:\n",
    "            pause_type = \"silB\"\n",
    "        elif \"sil\" in include_phonemes:\n",
    "            pause_type = \"sil\"\n",
    "        elif \"pau\" in include_phonemes:\n",
    "            pause_type = \"pau\"\n",
    "        elif \"sp\" in include_phonemes:\n",
    "            pause_type = \"sp\"\n",
    "        else:\n",
    "            pause_type = \"RP\"\n",
    "\n",
    "        ans.append([pause_range[0], pause_range[1], pause_range[2], pause_type])\n",
    "    return ans\n",
    "\n",
    "def extract_pause_ranges_from_wavpath(\n",
    "    wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイルからpauseの位置を抽出する\"\"\"\n",
    "\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "\n",
    "    pause_position = detect_pause_position(\n",
    "        db, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "    return pause_ranges\n",
    "\n",
    "\n",
    "# ----setting----\n",
    "# 閾値の設定\n",
    "db_threshold = -30\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 100 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# ---------------\n",
    "wav_p = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_25/audiobook_25_109.wav\"\n",
    "wav, sr = extract_waveform(wav_p, sr=sample_rate)\n",
    "db = convert_db(wav)\n",
    "plot_wavform(wav, sr)\n",
    "plot_db_with_pause(db, sr, db_threshold, time_threshold)\n",
    "pause_ranges = get_pause_ranges(db, db_threshold, time_threshold, sample_rate)\n",
    "print(pause_ranges)\n",
    "pause_ranges_by_wav = extract_pause_ranges_from_wavpath(wav_p, sample_rate, db_threshold, time_threshold)\n",
    "print(pause_ranges_by_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = exp_dir / \"発話ごとの話速度.csv\"\n",
    "speed_df = pd.read_csv(fpath)\n",
    "speed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オーディオブックごとの、発話ごとの話速度の平均と分散を計算する。\n",
    "df_stats = speed_df.groupby(\"audiobook_name\").agg([\"mean\", \"std\"])\n",
    "df_stats =  df_stats.sort_values((\"speed\", \"mean\"), ascending=False)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オーディオブックごとの、発話ごとの話速度の平均と分散を計算する。\n",
    "df_stats = speed_df.groupby(\"audiobook_name\").agg([\"mean\", \"std\"])\n",
    "df_stats =  df_stats.sort_values((\"speed\", \"std\"), ascending=False)\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiobook_names = speed_df[\"audiobook_name\"].unique()\n",
    "\n",
    "\n",
    "# 箱ひげ図\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "sns.boxplot(x=\"audiobook_name\", y=\"speed\", data=speed_df, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 箱ひげ図\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "sns.boxplot(x=\"audiobook_name\", y=\"speed\", data=speed_df, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_ylim(0, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- オーディオブックごとの話速度の平均のばらつきは、0.12〜0.18程度であることがわかった。これは、話速度のばらつきが大きいことを意味する？\n",
    "- それぞれのオーディオブック内で、分散は0.96〜0.09程度であることがわかった。これは、話速度のばらつきが小さい？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 会話文 or ナレーション文での話速度の違い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "assert yaml_file_path.exists()\n",
    "\n",
    "with open(yaml_file_path, \"r\") as f:\n",
    "    text_audio_dict = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "# 各chapterの発話に対して、characterとto_whomを取得する。\n",
    "info_list = []\n",
    "for audiobook_name in audiobook_names:\n",
    "    # print(audiobook_name)\n",
    "    for idx, info in enumerate(text_audio_dict[audiobook_name][\"text\"]):\n",
    "        chapter_name = idx\n",
    "        character = info[\"character\"]\n",
    "        to_whom = info[\"to_whom\"]\n",
    "        info_list.append(\n",
    "            {\"audiobook_name\": audiobook_name, \"chapter_name\": chapter_name, \"character\": character, \"to_whom\": to_whom}\n",
    "        )\n",
    "info_df = pd.DataFrame(info_list)\n",
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df[\"character\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfの1行目、2行目の列名を連結した列名に変換する関数\n",
    "def rename_multicol(df):\n",
    "    df_col=df.columns #列名をコピー\n",
    "    df = df.T.reset_index(drop=False).T #一回列名をリセット\n",
    "    for  i in range(df.shape[1]): #列名を新たに定義\n",
    "        rename_col = {i:\"\".join(df_col[i])}\n",
    "        df = df.rename(columns = rename_col)     \n",
    "    df = df.drop([\"level_0\",\"level_1\"],axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speed_character = pd.merge(speed_df, info_df, on=[\"audiobook_name\", \"chapter_name\"])\n",
    "df_speed_character[\"is_narrative\"] = df_speed_character[\"character\"] == \"narrative\"\n",
    "df_speed_character.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audiobook_nameごとに、発話ごとの話速度の平均`speed`と分散`speed_var`を計算する。(is_narrative==True, Falseで分ける)\n",
    "df_stats = df_speed_character.groupby([\"audiobook_name\", \"is_narrative\"]).agg({\"speed\":[\"mean\", \"std\"]})\n",
    "df_stats = df_stats.sort_values((\"speed\", \"mean\"), ascending=False).sort_index(level=0)\n",
    "df_stats = rename_multicol(df_stats.reset_index())\n",
    "display(df_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "df_tmp = []\n",
    "for audiobook_name in df_stats[\"audiobook_name\"].unique():\n",
    "    speed_mean_narrative = df_stats.query(f\"audiobook_name=='{audiobook_name}' & is_narrative==True\")[\"speedmean\"].values[0]\n",
    "    speed_mean_non_narrative = df_stats.query(f\"audiobook_name=='{audiobook_name}' & is_narrative==False\")[\"speedmean\"].values[0]\n",
    "    speed_var_narrative = df_stats.query(f\"audiobook_name=='{audiobook_name}' & is_narrative==True\")[\"speedstd\"].values[0]\n",
    "    speed_var_non_narrative = df_stats.query(f\"audiobook_name=='{audiobook_name}' & is_narrative==False\")[\"speedstd\"].values[0]\n",
    "    df_tmp.append({\"audiobook_name\": audiobook_name, \"speed_mean_narrative\": speed_mean_narrative, \"speed_mean_non_narrative\": speed_mean_non_narrative, \"speed_var_narrative\": speed_var_narrative, \"speed_var_non_narrative\": speed_var_non_narrative})\n",
    "\n",
    "df_tmp = pd.DataFrame(df_tmp)\n",
    "display(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図を作成 x: speed_mean, y: speed_var, hue: is_narrative\n",
    "fig, ax = plt.subplots(figsize=(6, 6 ))\n",
    "df_stats = df_stats.reset_index()\n",
    "sns.scatterplot(x=\"speedmean\", y=df_stats[\"speedstd\"], hue=\"is_narrative\", data=df_stats, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図を作成 audiobook_nameごとに分けて、x: speed_mean_narrative, y: speed_mean_not_narrative hue: audiobook_name\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.scatterplot(x=\"speed_mean_narrative\", y=\"speed_mean_non_narrative\", data=df_tmp, ax=ax)\n",
    "# y=xの直線を引く\n",
    "x = np.arange(0.10, 0.26, 0.01)\n",
    "ax.plot(x, x, color=\"r\", linestyle=\"--\")\n",
    "ax.set_xlim(0.10, 0.25)\n",
    "ax.set_ylim(0.10, 0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図を作成 audiobook_nameごとに分けて、x: speed_mean_narrative, y: speed_mean_not_narrative hue: audiobook_name\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.scatterplot(x=\"speed_var_narrative\", y=\"speed_var_non_narrative\", data=df_tmp, ax=ax)\n",
    "# y=xの直線を引く\n",
    "x = np.arange(0.0, 0.1, 0.01)\n",
    "ax.plot(x, x, color=\"r\", linestyle=\"--\")\n",
    "ax.set_xlim(0.0, 0.1, 0.01)\n",
    "ax.set_ylim(0.0, 0.1, 0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characterごとに可視化\n",
    "\n",
    "# 箱ひげ図\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "sns.boxplot(x=\"audiobook_name\", y=\"speed\", hue=\"is_narrative\", data=df_speed_character, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_ylim(0, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvs_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
