{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "# conda activate pyopenjtalk_julius\n",
    "\n",
    "# set path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "# import standard library\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# import pyopenjtalk\n",
    "# from pyopenjtalk import run_frontend, g2p\n",
    "import jaconv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import own library\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "\n",
    "# from src.analyze_jmac.text_preprocessing import (\n",
    "#     AudiobookScriptPreprocessor as Preprocessor,\n",
    "# )\n",
    "from src.analyze_jmac.mecab import mecab_wakati_generator, mecab_detailed_generator\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声波形抽出\n",
    "# wav_path -> wav, sr\n",
    "def extract_waveform(audio_file_path, sr=24000):\n",
    "    waveform, sample_rate = librosa.load(audio_file_path, sr=sr, mono=True)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "\n",
    "# wav -> db変換\n",
    "def convert_db(waveform):\n",
    "    # TODO: これは何が違うのか？どちらが適切か？\n",
    "    # db = librosa.power_to_db(waveform)\n",
    "    db = librosa.amplitude_to_db(waveform, ref=np.max)\n",
    "    return db\n",
    "\n",
    "\n",
    "# 連続区間抽出\n",
    "# db -> bool_list\n",
    "def run_length_encoding(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))  # 連続する範囲の長さを計算\n",
    "    result = np.repeat(run_lengths >= min_run_length, run_lengths)  # 連続する範囲をTrueに変換\n",
    "    return result\n",
    "\n",
    "def run_length_encoding_range(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)\n",
    "    run_starts = np.where(diff != 0)[0] + 1\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))\n",
    "    # 連続する範囲の開始、終了インデックスと長さを計算\n",
    "    runs = np.concatenate(([0], run_starts))\n",
    "    ranges_with_length = [(start, start + length, length) for start, length in zip(runs, run_lengths) \n",
    "                        if length >= min_run_length and arr[start]]\n",
    "    return ranges_with_length\n",
    "\n",
    "# Pause区間抽出\n",
    "# db, db_threshold, time_threshold, sr -> pause_bool_list\n",
    "# 閾値を超えたらpauseとみなす\n",
    "def detect_pause_position(\n",
    "    db_sequence, db_threshold=-50, time_threshold=50 / 1000, sample_rate=24000\n",
    "):\n",
    "    \"\"\"dbと音声長の閾値からpauseの位置を判定する。\n",
    "\n",
    "    Args:\n",
    "        db_sequence (np.array): 音声波形をdbに変換した配列\n",
    "        db_threshold (float): 無音区間とするdbの閾値\n",
    "        time_threshold (float): 無音区間が連続した時にpauseとみなす時間の閾値\n",
    "\n",
    "    Returns:\n",
    "        pause_positions (list): pauseの位置のリスト\n",
    "    \"\"\"\n",
    "    under_db_threshold = db_sequence < db_threshold\n",
    "\n",
    "    # 連続区間を抽出\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    is_continuous = run_length_encoding(under_db_threshold, sample_threshold)\n",
    "\n",
    "    # pauseの位置を抽出\n",
    "    pause_positions = under_db_threshold & is_continuous\n",
    "\n",
    "    return pause_positions\n",
    "\n",
    "\n",
    "# pause区間付きの波形の可視化\n",
    "def plot_db_with_pause(db, sr, db_threshold, time_threshold, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax.plot(x, db, label=\"db\")\n",
    "\n",
    "    # dbの閾値を引く\n",
    "    ax.axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    plt.fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 波形の可視化\n",
    "def plot_wavform(waveform, sr, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(waveform)) / sr\n",
    "    ax.plot(x, waveform, label=\"waveform\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 音声再生ボタン生成\n",
    "def play_button(waveform, sr):\n",
    "    display(Audio(waveform, rate=sr, autoplay=True))\n",
    "\n",
    "\n",
    "# アライメントの抽出\n",
    "# lab_path -> df_lab\n",
    "def read_lab(lab_path):\n",
    "    \"\"\"labファイルを読み込む\"\"\"\n",
    "    # labファイルがない場合\n",
    "    if not Path(lab_path).exists():\n",
    "        print(f\"{lab_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # labファイルがある場合\n",
    "    df_lab = []\n",
    "    with open(lab_path, \"r\") as f:\n",
    "        for phoneme_idx, line in enumerate(f):\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            duration = float(end) - float(start)\n",
    "            df_lab.append(\n",
    "                {\n",
    "                    \"start\": float(start),\n",
    "                    \"end\": float(end),\n",
    "                    \"phoneme\": phoneme,\n",
    "                    \"phoneme_idx\": phoneme_idx,\n",
    "                    \"duration\": duration,\n",
    "                }\n",
    "            )\n",
    "    df_lab = pd.DataFrame(df_lab)\n",
    "    return df_lab\n",
    "\n",
    "\n",
    "# アライメントの可視化\n",
    "def plot_phoneme_alignment(df, xlim=None):\n",
    "    \"\"\"Labファイルから音素のアライメントをプロットする\n",
    "\n",
    "    Args:\n",
    "        lab_path (_type_): Labファイルのパス\n",
    "    \"\"\"\n",
    "    # df = read_lab(lab_path)\n",
    "    # display(df[-10:])\n",
    "\n",
    "    # 描画\n",
    "    fig, ax = plt.subplots(figsize=(20, 2))\n",
    "    for start, end, label in df.values:\n",
    "        ax.axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax.text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4, 2]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[2].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax[2].set_xlim(xlim)\n",
    "    ax[2].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all2(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        2, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[0].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=12)\n",
    "    # ax.set_yticks([])\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[0].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "def get_pause_ranges(\n",
    "    db_sequence, db_threshold=-50, time_threshold=0.05, sample_rate=24000\n",
    "):\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    # def run_length_encoding_range(arr, min_run_length=3):\n",
    "    #     \"\"\"\n",
    "    #     Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "    #     Parameters:\n",
    "    #         arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "    #         min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "    #     Returns:\n",
    "    #         numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "    #         list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "    #     \"\"\"\n",
    "    #     diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    #     run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "    #     starts = np.concatenate(([0], run_starts))\n",
    "    #     ends = np.concatenate((run_starts, [len(arr)]))\n",
    "    #     lengths = ends - starts\n",
    "    #     ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "    #     # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "    #     ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "    #     return ranges\n",
    "\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "    return pause_ranges\n",
    "\n",
    "\n",
    "def classfy_pause(\n",
    "    db_sequence, lab_path, sample_rate=24000, db_threshold=-50, time_threshold=0.05\n",
    "):\n",
    "    \"\"\"ポーズを分類する\n",
    "\n",
    "    Args:\n",
    "        df_jvs (_type_): _description_\n",
    "    \"\"\"\n",
    "    # db_threshold = -50\n",
    "    # time_threshold = 0.05\n",
    "    # sample_rate = 24000\n",
    "\n",
    "    # db_sequence = df_jvs.iloc[0]['db_sequence']\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    # def run_length_encoding_range(arr, min_run_length=3):\n",
    "    #     \"\"\"\n",
    "    #     Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "    #     Parameters:\n",
    "    #         arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "    #         min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "    #     Returns:\n",
    "    #         numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "    #         list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "    #     \"\"\"\n",
    "    #     diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    #     run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "    #     starts = np.concatenate(([0], run_starts))\n",
    "    #     ends = np.concatenate((run_starts, [len(arr)]))\n",
    "    #     lengths = ends - starts\n",
    "    #     ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "    #     # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "    #     ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "    #     return ranges\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "\n",
    "    # print(pause_ranges)\n",
    "\n",
    "    # df_lab = read_lab(df_jvs.iloc[0]['lab_path'])\n",
    "    df_lab = read_lab(lab_path)\n",
    "\n",
    "    ans = []\n",
    "    for pause_range in pause_ranges:\n",
    "        # df_labのstartもしくは、endが、start, endの範囲内にあるかどうか\n",
    "        pause_start = pause_range[0]\n",
    "        pause_end = pause_range[1]\n",
    "        phoneme_start = df_lab[\"start\"].values * sample_rate\n",
    "        phoneme_end = df_lab[\"end\"].values * sample_rate\n",
    "        is_start_include = (pause_start <= phoneme_start) & (phoneme_start <= pause_end)\n",
    "        is_end_include = (pause_start <= phoneme_end) & (phoneme_end <= pause_end)\n",
    "\n",
    "        include_phonemes = df_lab[is_start_include | is_end_include][\"phoneme\"].values\n",
    "        print(include_phonemes)\n",
    "        if \"silE\" in include_phonemes:\n",
    "            pause_type = \"silE\"\n",
    "        elif \"silB\" in include_phonemes:\n",
    "            pause_type = \"silB\"\n",
    "        elif \"sil\" in include_phonemes:\n",
    "            pause_type = \"sil\"\n",
    "        elif \"pau\" in include_phonemes:\n",
    "            pause_type = \"pau\"\n",
    "        elif \"sp\" in include_phonemes:\n",
    "            pause_type = \"sp\"\n",
    "        else:\n",
    "            pause_type = \"RP\"\n",
    "\n",
    "        ans.append([pause_range[0], pause_range[1], pause_range[2], pause_type])\n",
    "    return ans\n",
    "\n",
    "def extract_pause_ranges_from_wavpath(\n",
    "    wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイルからpauseの位置を抽出する\"\"\"\n",
    "\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "\n",
    "    pause_position = detect_pause_position(\n",
    "        db, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "    return pause_ranges\n",
    "\n",
    "\n",
    "# ----setting----\n",
    "# 閾値の設定\n",
    "db_threshold = -30\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# ---------------\n",
    "wav_p = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_25/audiobook_25_109.wav\"\n",
    "wav, sr = extract_waveform(wav_p, sr=sample_rate)\n",
    "db = convert_db(wav)\n",
    "plot_wavform(wav, sr)\n",
    "plot_db_with_pause(db, sr, db_threshold, time_threshold)\n",
    "pause_ranges = get_pause_ranges(db, db_threshold, time_threshold, sample_rate)\n",
    "print(pause_ranges)\n",
    "pause_ranges_by_wav = extract_pause_ranges_from_wavpath(wav_p, sample_rate, db_threshold, time_threshold)\n",
    "print(pause_ranges_by_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab.yaml\"\n",
    "\n",
    "with open(morp_phons_yaml_path, \"r\") as f:\n",
    "    morp_phons_yaml_data = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_data[\"audiobook_25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_data[\"audiobook_0\"][\"000\"][\"morp_lab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----setting----\n",
    "# 閾値の設定\n",
    "# db_threshold = -50\n",
    "db_threshold = -30\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 80 / 1000  # 200ms\n",
    "# time_threshold = 100 / 1000  # 200ms\n",
    "# time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# ---------------\n",
    "wav_p = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_0/audiobook_0_000.wav\"\n",
    "wav, sr = extract_waveform(wav_p, sr=sample_rate)\n",
    "db = convert_db(wav)\n",
    "# plot_wavform(wav, sr)\n",
    "# plot_db_with_pause(db, sr, db_threshold, time_threshold)\n",
    "pause_ranges = get_pause_ranges(db, db_threshold, time_threshold, sample_rate)\n",
    "print(pause_ranges)\n",
    "\n",
    "# ml = wav_p.replace(\".wav\", \".labm\")\n",
    "# with open(ml, \"r\") as f:\n",
    "#     ml_data = f.readlines()\n",
    "# ml_data = [line.strip() for line in ml_data]\n",
    "# pprint(ml_data)\n",
    "ml_data = morp_phons_yaml_data[\"audiobook_0\"][\"000\"][\"morp_lab\"]\n",
    "print(ml_data)\n",
    "df_temp = pd.DataFrame(\n",
    "    [ml.split(\" \") for ml in ml_data], columns=[\"start\", \"end\", \"phoneme\"]\n",
    ")\n",
    "df_temp[\"start\"] = df_temp[\"start\"].astype(float)\n",
    "df_temp[\"end\"] = df_temp[\"end\"].astype(float)\n",
    "\n",
    "plot_all2(\n",
    "    df_temp,\n",
    "    wav_p,\n",
    "    sample_rate=sample_rate,\n",
    "    db_threshold=db_threshold,\n",
    "    time_threshold=time_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----setting----\n",
    "# 閾値の設定\n",
    "# db_threshold = -50\n",
    "db_threshold = -30\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 80 / 1000  # 200ms\n",
    "# time_threshold = 100 / 1000  # 200ms\n",
    "# time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# ---------------\n",
    "\n",
    "new_morp_phons_yaml_data_path = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_fix_runencode_80ms.yaml\"\n",
    ")\n",
    "\n",
    "new_morp_phons_yaml_data = {}\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data.items()):\n",
    "    audiobook_dict = {}\n",
    "    print(f\"[INFO] audiobook_name: {audiobook_name}\")\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        wav_path = (\n",
    "            Path(DATA_TAKESHUN256_DIR)\n",
    "            / \"jmac_split_and_added_lab\"\n",
    "            / audiobook_name\n",
    "            / f\"{audiobook_name}_{chapter_name}.wav\"\n",
    "        )\n",
    "\n",
    "        if not wav_path.exists():\n",
    "            print(f\"[INFO] {wav_path} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "        try:\n",
    "            db = convert_db(wav)\n",
    "        except ValueError:\n",
    "            print(f\"[INFO] {wav_path} is not for convert_db.\")\n",
    "            continue\n",
    "        pause_ranges = get_pause_ranges(db, db_threshold, time_threshold, sample_rate)\n",
    "\n",
    "        chapter_info[\"wav_path\"] = str(wav_path)\n",
    "        pause_ranges_str = [\n",
    "            \" \".join([str(pause_range[0]), str(pause_range[1]), str(pause_range[2])])\n",
    "            for pause_range in pause_ranges\n",
    "        ]\n",
    "\n",
    "        chapter_info[\"pause_ranges_str\"] = pause_ranges_str\n",
    "        audiobook_dict[chapter_name] = chapter_info\n",
    "\n",
    "    new_morp_phons_yaml_data[audiobook_name] = audiobook_dict\n",
    "    print(f\"[INFO] {audiobook_name} is done.\")\n",
    "\n",
    "\n",
    "# with open(new_morp_phons_yaml_data_path, \"w\") as f:\n",
    "#     yaml.dump(new_morp_phons_yaml_data, f, allow_unicode=True)\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "with open(new_morp_phons_yaml_data_path, \"wb\") as f:\n",
    "    pickle.dump(new_morp_phons_yaml_data, f)\n",
    "\n",
    "print(f\"[INFO] {new_morp_phons_yaml_data_path} is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_morp_phons_yaml_data[\"audiobook_25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルが大きすぎるので、小さくする\n",
    "new_morp_phons_yaml_data_small_path = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_fix_runencode_80ms.yaml\"\n",
    ")\n",
    "\n",
    "new_morp_phons_yaml_data_small = {}\n",
    "for audiobook_name, info in new_morp_phons_yaml_data.items():\n",
    "    audiobook_dict = {}\n",
    "    print(f\"[INFO] audiobook_name: {audiobook_name}\")\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        chapter_dict = {}\n",
    "        if (\n",
    "            \"wav_path\" not in chapter_info\n",
    "            or \"pause_ranges_str\" not in chapter_info\n",
    "            or \"morp_lab\" not in chapter_info\n",
    "        ):\n",
    "            print(f\"[INFO] {chapter_name} is skipped.\")\n",
    "            continue\n",
    "        chapter_dict[\"wav_path\"] = chapter_info[\"wav_path\"]\n",
    "        chapter_dict[\"pause_ranges_str\"] = chapter_info[\"pause_ranges_str\"][:10]\n",
    "        chapter_dict[\"morp_lab\"] = chapter_info[\"morp_lab\"]\n",
    "\n",
    "        audiobook_dict[chapter_name] = chapter_dict\n",
    "    new_morp_phons_yaml_data_small[audiobook_name] = audiobook_dict\n",
    "\n",
    "with open(new_morp_phons_yaml_data_small_path, \"w\") as f:\n",
    "    yaml.dump(new_morp_phons_yaml_data_small, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_loadできないので、pklで保存する。\n",
    "import pickle\n",
    "\n",
    "with open(str(new_morp_phons_yaml_data_path).replace(\"yaml\", \"pkl\"), \"wb\") as f:\n",
    "    pickle.dump(new_morp_phons_yaml_data, f, protocol=4)\n",
    "\n",
    "# load\n",
    "# with open(new_morp_phons_yaml_data_path, \"rb\") as f:\n",
    "#     new_morp_phons_yaml_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_morp_phons_yaml_data_small_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----setting----\n",
    "# 閾値の設定\n",
    "# db_threshold = -50\n",
    "db_threshold = -30\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# ---------------\n",
    "# wav_p = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_25/audiobook_25_100.wav\"\n",
    "wav_p = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_0/audiobook_0_000.wav\"\n",
    "wav, sr = extract_waveform(wav_p, sr=sample_rate)\n",
    "db = convert_db(wav)\n",
    "# plot_wavform(wav, sr)\n",
    "# plot_db_with_pause(db, sr, db_threshold, time_threshold)\n",
    "pause_ranges = get_pause_ranges(db, db_threshold, time_threshold, sample_rate)\n",
    "print(pause_ranges)\n",
    "\n",
    "# ml = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_25/audiobook_25_100.labm\"\n",
    "# ml = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_0/audiobook_0_000.labm\"\n",
    "ml = wav_p.replace(\".wav\", \".labm\")\n",
    "with open(ml, \"r\") as f:\n",
    "    ml_data = f.readlines()\n",
    "ml_data = [line.strip() for line in ml_data]\n",
    "pprint(ml_data)\n",
    "\n",
    "df_temp = pd.DataFrame(\n",
    "    [ml.split(\" \") for ml in ml_data], columns=[\"start\", \"end\", \"phoneme\"]\n",
    ")\n",
    "df_temp[\"start\"] = df_temp[\"start\"].astype(float)\n",
    "df_temp[\"end\"] = df_temp[\"end\"].astype(float)\n",
    "\n",
    "plot_all2(\n",
    "    df_temp,\n",
    "    wav_p,\n",
    "    sample_rate=sample_rate,\n",
    "    db_threshold=db_threshold,\n",
    "    time_threshold=time_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvs_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
