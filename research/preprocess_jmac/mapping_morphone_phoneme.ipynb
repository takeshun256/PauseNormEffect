{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# éŸ³ç´ ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€å½¢æ…‹ç´ ã®å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. JMAC ã®ãµã‚ŠãŒãªéƒ¨åˆ†ã‚’é™¤ã„ã¦Â `pyopenjtalk.run_frontend`Â ã§å½¢æ…‹ç´ ã”ã¨ã«èª­ã¿æƒ…å ±ã‚’å¾—ã‚‹\n",
    "2. JMAC ã®ãµã‚ŠãŒãªã¨æ¯”ã¹ã¦ï¼Œç•°ãªã£ã¦ã„ã‚‹ã¨ã“ã‚ã¯çµæœã‚’ä¸Šæ›¸ãã™ã‚‹ï¼ˆç„¡å£°éŸ³ã‚’è¡¨ã™Â `'`Â ã«æ³¨æ„ã™ã‚‹ï¼‰ \n",
    "3. ä¸Šè¨˜ã®ãƒ«ãƒ¼ãƒ«ã§ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã®ç™ºéŸ³ã‚’å–ã‚Šå‡ºã™\n",
    "4. jaconv ãªã©ã§ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãªã«å¤‰æ›ã—ï¼Œã•ã‚‰ã« jaconv ã®Â `hiragana2julius`Â ã§éŸ³ç´ åˆ—ã«å¤‰æ›ã™ã‚‹\n",
    "5. å½¢æ…‹ç´ ã”ã¨ã«éŸ³ç´ åˆ—ã‚’ä¿å­˜ã—ã¦ãŠã\n",
    "6. éŸ³ç´ åˆ—ã‚’ã¤ãªã’ãŸã‚‚ã®ã‚’ Julius ã«å…¥åŠ›ã—ã¦ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆçµæœã‚’å¾—ã‚‹\n",
    "7. å½¢æ…‹ç´ ã”ã¨ã®éŸ³ç´ åˆ—ã¨æ¯”è¼ƒã—ã¦ï¼Œå½¢æ…‹ç´ ã”ã¨ã«æ™‚é–“æƒ…å ±ã‚’å¾—ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate pyopenjtalk_julius\n",
    "\n",
    "# set path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "# import standard library\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import pyopenjtalk\n",
    "from pyopenjtalk import run_frontend, g2p\n",
    "import jaconv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import own library\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "from src.analyze_jmac.text_preprocessing import (\n",
    "    AudiobookScriptPreprocessor as Preprocessor,\n",
    ")\n",
    "from src.analyze_jmac.mecab import mecab_wakati_generator, mecab_detailed_generator\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_frontend(\"ã“ã‚Œã¯ã€[ç§|ã‚ãŸã—]ãŒå°ã•ã„ã€ã¨ãã«ã€æ‘ã®[èŒ‚å¹³|ã‚‚ã¸ã„]ã¨ã„ã†ãŠã˜ã„ã•ã‚“ã‹ã‚‰ãã„ãŸãŠè©±ã§ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†é–¢æ•°ã‚’å®šç¾©\n",
    "\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã‚’è¡Œã†\n",
    "\n",
    "    1. JMAC ã®ãµã‚ŠãŒãªéƒ¨åˆ†ã‚’é™¤ã„ã¦Â `pyopenjtalk.run_frontend`Â ã§å½¢æ…‹ç´ ã”ã¨ã«èª­ã¿æƒ…å ±ã‚’å¾—ã‚‹\n",
    "    2. JMAC ã®ãµã‚ŠãŒãªã¨æ¯”ã¹ã¦ï¼Œç•°ãªã£ã¦ã„ã‚‹ã¨ã“ã‚ã¯çµæœã‚’ä¸Šæ›¸ãã™ã‚‹ï¼ˆç„¡å£°éŸ³ã‚’è¡¨ã™Â `'`Â ã«æ³¨æ„ã™ã‚‹ï¼‰\n",
    "    3. ä¸Šè¨˜ã®ãƒ«ãƒ¼ãƒ«ã§ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã®ç™ºéŸ³ã‚’å–ã‚Šå‡ºã™\n",
    "    4. jaconv ãªã©ã§ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãªã«å¤‰æ›ã—ï¼Œã•ã‚‰ã« jaconv ã®Â `hiragana2julius`Â ã§éŸ³ç´ åˆ—ã«å¤‰æ›ã™ã‚‹\n",
    "    5. å½¢æ…‹ç´ ã”ã¨ã«éŸ³ç´ åˆ—ã‚’ä¿å­˜ã—ã¦ãŠã\n",
    "    # 6. éŸ³ç´ åˆ—ã‚’ã¤ãªã’ãŸã‚‚ã®ã‚’ Julius ã«å…¥åŠ›ã—ã¦ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆçµæœã‚’å¾—ã‚‹\n",
    "    # 7. å½¢æ…‹ç´ ã”ã¨ã®éŸ³ç´ åˆ—ã¨æ¯”è¼ƒã—ã¦ï¼Œå½¢æ…‹ç´ ã”ã¨ã«æ™‚é–“æƒ…å ±ã‚’å¾—ã‚‹\n",
    "\n",
    "    Usage:\n",
    "        >>> text_preprocessor = TextPreprocessor()\n",
    "        >>> text_preprocessor.preprocess_text(text)\n",
    "\n",
    "    Input:\n",
    "        text (str): JMAC ã®ãƒ†ã‚­ã‚¹ãƒˆ, e.g., 'ã“ã‚Œã¯ã€[ç§|ã‚ãŸã—]ãŒå°ã•ã„ã¨ãã«ã€æ‘ã®[èŒ‚å¹³|ã‚‚ã¸ã„]ã¨ã„ã†ãŠã˜ã„ã•ã‚“ã‹ã‚‰ãã„ãŸãŠè©±ã§ã™ã€‚'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mecab_wakati_generator = mecab_wakati_generator\n",
    "        self.mecab_detailed_generator = mecab_detailed_generator\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_brackets_to_kanji(x):\n",
    "        \"\"\"ãƒ–ãƒ©ã‚±ãƒƒãƒˆå†…ã®æ¼¢å­—ã‚’å–ã‚Šå‡ºã™.\n",
    "\n",
    "        Example:\n",
    "            å…¥åŠ›: \"ãŠ[è“å­|ã‹ã—]ãŒã²ã¨ã¤\" # [kanji|furigana]\n",
    "            å‡ºåŠ›: \"ãŠè“å­ãŒã²ã¨ã¤\"\n",
    "        \"\"\"\n",
    "        return re.sub(r\"\\[(.+?)\\|(.+?)\\]\", r\"\\1\", x)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_brackets_to_furigana(x):\n",
    "        \"\"\"ãƒ–ãƒ©ã‚±ãƒƒãƒˆå†…ã®ãµã‚ŠãŒãªã‚’å–ã‚Šå‡ºã™.\n",
    "\n",
    "        Example:\n",
    "            å…¥åŠ›: \"ãŠ[è“å­|ã‹ã—]ãŒã²ã¨ã¤\" # [kanji|furigana]\n",
    "            å‡ºåŠ›: \"ãŠã‹ã—ãŒã²ã¨ã¤\"\n",
    "        \"\"\"\n",
    "        return re.sub(r\"\\[(.+?)\\|(.+?)\\]\", r\"\\2\", x)\n",
    "\n",
    "    def normalize(self, text):\n",
    "        return jaconv.normalize(text)\n",
    "\n",
    "    def get_jmac_blacket_dict(self, text):\n",
    "        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ–ãƒ©ã‚±ãƒƒãƒˆå†…ã®ã€Œæ¼¢å­—ã€ã¨ã€Œãµã‚ŠãŒãªã®pronã€ã®å¯¾å¿œã‚’å–å¾—ã™ã‚‹.\"\"\"\n",
    "        blacket_dict = {}\n",
    "        for kanji, furigana in re.findall(r\"\\[(.+?)\\|(.+?)\\]\", text):\n",
    "            blacket_dict[kanji] = furigana\n",
    "        blacket_dict = {\n",
    "            k: \"\".join([njd[\"pron\"] for njd in run_frontend(self.normalize(v))])\n",
    "            for k, v in blacket_dict.items()\n",
    "        }\n",
    "        return blacket_dict\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        self.original_text = text\n",
    "        self.blacket_removed_kanji_text = self.remove_brackets_to_kanji(text)\n",
    "        self.normalized_text = self.normalize(self.blacket_removed_kanji_text)\n",
    "        self.njd_features = run_frontend(self.normalized_text)\n",
    "\n",
    "        self.jmac_blacket_dict = self.get_jmac_blacket_dict(self.original_text)\n",
    "\n",
    "        # å½¢æ…‹ç´ å˜ä½ã®éŸ³ç´ åˆ—ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "        self.morp_pron_list = []  # [[morphome, katakana], ...]\n",
    "\n",
    "        # JMAC ã®ãµã‚ŠãŒãªã¨æ¯”ã¹ã¦ï¼Œç•°ãªã£ã¦ã„ã‚‹ã¨ã“ã‚ã¯çµæœã‚’ä¸Šæ›¸ãã™ã‚‹ï¼ˆç„¡å£°éŸ³ã‚’è¡¨ã™ ' ã«æ³¨æ„ã™ã‚‹ï¼‰\n",
    "        for njd_feature in self.njd_features:\n",
    "            # è¨˜å·ã¯ã€ã®ã¿ã‚’å–ã‚Šå‡ºã™\n",
    "            if njd_feature[\"pos\"] == \"è¨˜å·\":\n",
    "                if njd_feature[\"string\"] == \"ã€\":\n",
    "                    pron = \"ã€\"\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                orig = njd_feature[\"string\"]\n",
    "                pron = njd_feature[\"pron\"]\n",
    "                if (\n",
    "                    orig in self.jmac_blacket_dict\n",
    "                    and self.jmac_blacket_dict[orig] != pron\n",
    "                ):\n",
    "                    pron = self.jmac_blacket_dict[orig]\n",
    "            pron = pron.replace(\"â€™\", \"\")  # ç„¡å£°éŸ³ã‚’è¡¨ã™ ' ã¯å‰Šé™¤ã™ã‚‹\n",
    "            # 3. ä¸Šè¨˜ã®ãƒ«ãƒ¼ãƒ«ã§ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã®ç™ºéŸ³ã‚’å–ã‚Šå‡ºã™\n",
    "            self.morp_pron_list.append([njd_feature[\"string\"], pron])\n",
    "        # print(f\"self.morp_pron_list: {self.morp_pron_list}\")\n",
    "        # 4. jaconv ãªã©ã§ã‚«ã‚¿ã‚«ãƒŠâ†’ã²ã‚‰ãŒãªã«å¤‰æ›ã—ï¼Œã•ã‚‰ã« jaconv ã®Â `hiragana2julius`Â ã§éŸ³ç´ åˆ—ã«å¤‰æ›ã™ã‚‹\n",
    "        self.morp_phons_list = []  # [[morphome, [phoneme, ...]], ...\n",
    "        for m, p in self.morp_pron_list:\n",
    "            if p == \"ã€\":\n",
    "                self.morp_phons_list.append([m, [\"sp\"]])\n",
    "            else:\n",
    "                self.morp_phons_list.append(\n",
    "                    [m, jaconv.hiragana2julius(jaconv.kata2hira(p)).split(\" \")]\n",
    "                )\n",
    "\n",
    "        morp_join = \"\".join([m for m, p in self.morp_phons_list])\n",
    "        phons_join = \" \".join([p for _, phons in self.morp_phons_list for p in phons])\n",
    "\n",
    "        output_dict = {\n",
    "            \"morp_join\": morp_join,\n",
    "            \"phons_join\": phons_join,\n",
    "            \"morp_phons_list\": self.morp_phons_list,\n",
    "        }\n",
    "        return output_dict\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        text,\n",
    "    ):\n",
    "        return self.preprocess_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "origã¯ã€stringã®å½¢ã‚’é€šå¸¸ã®çŠ¶æ…‹ã«æˆ»ã—ãŸã‚‚ã® ã„ãŸ -> ã„ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor()\n",
    "s = \" ã“ã‚Œã¯ã€[ç§|ã‚ãŸã—]ãŒå°ã•ã€€ã„ã¨ãã«ã€æ‘ã®[èŒ‚å¹³|ã‚‚ã¸ã„]  ã¨ã„ã†...ãŠã˜ ã„ ã•ãƒ¼ã‚“!?ã‹ã‚‰ãã€   ã„ãŸ ãŠè©±ã§ã™ã€‚\"\n",
    "text_preprocessor(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚„ã‚‹ã“ã¨\n",
    "1. å¯¾å¿œè¡¨ã‚’ä½œã‚‹\n",
    "2. éŸ³ç´ åˆ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿å­˜ã™ã‚‹\n",
    "3. Juliusã‚’ã‹ã‘ã‚‹(æ‰‹ç›´ã—ã§ããŸã‚‰)\n",
    "4. labã‚’å¾—ã‚‹\n",
    "5. fix_align.pyã§labã‹ã‚‰lab2ã‚’ä½œã‚‹\n",
    "6. lab2ã‹ã‚‰ã€å½¢æ…‹ç´ å˜ä½ã®labã‚’ä½œã‚‹\n",
    "7. éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç„¡éŸ³åŒºé–“ã®æƒ…å ±ã‚’å¾—ã¦ä¿å­˜ã™ã‚‹\n",
    "8. å„å½¢æ…‹ç´ é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹\n",
    "9. ãƒªã‚¹ãƒˆã§ã€(å½¢æ…‹ç´ , True, å½¢æ…‹ç´ , False, ...)ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹\n",
    "10. tokenåŒ–ã™ã‚‹\n",
    "11. BERTã§å­¦ç¿’ã™ã‚‹\n",
    "12. ç²¾åº¦ã‚’ç¢ºèªã™ã‚‹, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚‚ç¢ºèªã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.å¯¾å¿œè¡¨ã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¾å¿œè¡¨ã®ä½œæˆã¨ä¿å­˜\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "output_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()\n",
    "\n",
    "with open(yaml_file_path, \"r\") as f:\n",
    "    yaml_data = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "transcript_dict = {}\n",
    "for audiobook_name, info in tqdm(yaml_data.items()):\n",
    "    transcript_lines = []\n",
    "    author = info[\"author\"]\n",
    "    book = info[\"book\"]\n",
    "    mp3 = info[\"mp3\"]\n",
    "    url = info[\"url\"]\n",
    "    wav = info[\"wav\"]\n",
    "    text = info[\"text\"]\n",
    "\n",
    "    # make text_dict\n",
    "    text_dict = {}\n",
    "    for chapter_idx, chapter_info in enumerate(text):\n",
    "        chapter_idx_str = str(chapter_idx).zfill(3)\n",
    "        # update chapter_info\n",
    "        sent_str = chapter_info[\"sent\"]\n",
    "        morp_phons_dict = text_preprocessor(sent_str)\n",
    "        morp_join = morp_phons_dict[\"morp_join\"]\n",
    "        phons_join = morp_phons_dict[\"phons_join\"]\n",
    "        morp_phons_list = morp_phons_dict[\"morp_phons_list\"]\n",
    "\n",
    "        chapter_info[\"morp_join\"] = morp_join\n",
    "        chapter_info[\"phons_join\"] = phons_join\n",
    "        chapter_info[\"morp_phons_list\"] = morp_phons_list\n",
    "\n",
    "        text_dict[chapter_idx_str] = chapter_info\n",
    "\n",
    "    # make audiobook_dict\n",
    "    audiobook_dict = {}\n",
    "    audiobook_dict[\"author\"] = author\n",
    "    audiobook_dict[\"book\"] = book\n",
    "    audiobook_dict[\"mp3\"] = mp3\n",
    "    audiobook_dict[\"url\"] = url\n",
    "    audiobook_dict[\"wav\"] = wav\n",
    "    audiobook_dict[\"text\"] = text_dict\n",
    "\n",
    "    # make trascript_dict\n",
    "    transcript_dict[audiobook_name] = audiobook_dict\n",
    "\n",
    "pprint(transcript_dict[\"audiobook_0\"])\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(transcript_dict, f, allow_unicode=True)\n",
    "\n",
    "print(f\"output_yaml_path: {output_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ã‚¢ã‚¤ã‚¹ã€\".strip(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.éŸ³ç´ åˆ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿å­˜ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons.yaml\"\n",
    "output_dict_path = Path(DATA_TAKESHUN256_DIR) / \"jmac_split_and_added_lab\"\n",
    "\n",
    "with open(morp_phons_yaml_path, \"r\") as f:\n",
    "    morp_phons_yaml_data = yaml.safe_load(f)\n",
    "\n",
    "# å„chapterã®phons_joinã‚’å–ã‚Šå‡ºã—ã¦ã€ãã‚Œãã‚Œãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data.items()):\n",
    "    for chapter_name, chapter_info in info[\"text\"].items():\n",
    "        phons_join = chapter_info[\"phons_join\"]\n",
    "        if not isinstance(phons_join, str):\n",
    "            raise ValueError(\"phons_join is not str\")\n",
    "        output_path = (\n",
    "            output_dict_path / audiobook_name / f\"{audiobook_name}_{chapter_name}.txt\"\n",
    "        )\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(phons_join)\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Juliusã‚’ã‹ã‘ã‚‹(æ‰‹ç›´ã—ã§ããŸã‚‰)\n",
    "\n",
    "- BERTã®è©•ä¾¡å¾Œã«æ‰‹ç›´ã—ã™ã‚‹(ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’1ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã§ã‚¹ã‚­ãƒƒãƒ—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹)\n",
    "- `./all_audiobook_julius_segment.sh`ã§juliusã‚’ã‹ã‘ã‚‹\n",
    "- ãƒ­ã‚°å–ã‚‹ãªã‚‰ã€`./all_audiobook_julius_segment.sh > /home/takeshun256/PausePrediction/logs/all_audiobook_julius_segment_2023-11-01_0630.log 2>&1`\n",
    "\n",
    "- å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡ºã‚‹ã®ã§ã€\n",
    "    - `find /data2/takeshun256 -type f -size +100M`\n",
    "    - `find /data2/takeshun256 -type f -size +100M -delete`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.labã‚’å¾—ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3ç•ªã§ç”Ÿæˆå®Œäº†ã—ã¦ã„ã‚‹\n",
    "- `check_file_counts_eq_julius_segment.sh` ã§ç”Ÿæˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã©ã‚Œã ã‘ã‚ã‚‹ã‹ç¢ºèªã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ğŸŸ¢ audiobook_0 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_1 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_10 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ audiobook_11 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ audiobook_12 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ audiobook_13 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ audiobook_14 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ audiobook_15 lab:134 wav:134 txt:134 log:134\n",
    "ğŸŸ¢ audiobook_16 lab:134 wav:134 txt:134 log:134\n",
    "ğŸŸ¢ audiobook_17 lab:355 wav:355 txt:355 log:355\n",
    "ğŸŸ¢ audiobook_18 lab:311 wav:311 txt:311 log:311\n",
    "ğŸŸ¢ audiobook_19 lab:103 wav:103 txt:103 log:103\n",
    "ğŸŸ¢ audiobook_2 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_20 lab:103 wav:103 txt:103 log:103\n",
    "ğŸŸ¢ audiobook_21 lab:471 wav:471 txt:471 log:471\n",
    "ğŸŸ¢ audiobook_22 lab:471 wav:471 txt:471 log:471\n",
    "ğŸŸ¢ audiobook_23 lab:471 wav:471 txt:471 log:471\n",
    "ğŸŸ¢ audiobook_24 lab:471 wav:471 txt:471 log:471\n",
    "ğŸŸ¢ audiobook_25 lab:160 wav:160 txt:160 log:160\n",
    "ğŸŸ¢ audiobook_26 lab:164 wav:164 txt:164 log:164\n",
    "ğŸŸ¢ audiobook_27 lab:164 wav:164 txt:164 log:164\n",
    "âŒ audiobook_28 lab:8 wav:472 txt:472 log:9\n",
    "âŒ audiobook_29 lab:9 wav:472 txt:472 log:10\n",
    "ğŸŸ¢ audiobook_3 lab:178 wav:178 txt:178 log:178\n",
    "âŒ audiobook_30 lab:37 wav:472 txt:472 log:38\n",
    "ğŸŸ¢ audiobook_31 lab:167 wav:167 txt:167 log:167\n",
    "ğŸŸ¢ audiobook_32 lab:167 wav:167 txt:167 log:167\n",
    "ğŸŸ¢ audiobook_33 lab:167 wav:167 txt:167 log:167\n",
    "ğŸŸ¢ audiobook_34 lab:167 wav:167 txt:167 log:167\n",
    "ğŸŸ¢ audiobook_35 lab:167 wav:167 txt:167 log:167\n",
    "ğŸŸ¢ audiobook_36 lab:167 wav:167 txt:167 log:167\n",
    "ğŸŸ¢ audiobook_37 lab:266 wav:266 txt:266 log:266\n",
    "ğŸŸ¢ audiobook_38 lab:266 wav:266 txt:266 log:266\n",
    "ğŸŸ¢ audiobook_39 lab:266 wav:266 txt:266 log:266\n",
    "ğŸŸ¢ audiobook_4 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_40 lab:266 wav:266 txt:266 log:266\n",
    "ğŸŸ¢ audiobook_41 lab:266 wav:266 txt:266 log:266\n",
    "ğŸŸ¢ audiobook_42 lab:241 wav:241 txt:241 log:241\n",
    "ğŸŸ¢ audiobook_43 lab:241 wav:241 txt:241 log:241\n",
    "ğŸŸ¢ audiobook_44 lab:241 wav:241 txt:241 log:241\n",
    "ğŸŸ¢ audiobook_45 lab:241 wav:241 txt:241 log:241\n",
    "ğŸŸ¢ audiobook_46 lab:241 wav:241 txt:241 log:241\n",
    "ğŸŸ¢ audiobook_47 lab:165 wav:165 txt:165 log:165\n",
    "ğŸŸ¢ audiobook_48 lab:165 wav:165 txt:165 log:165\n",
    "ğŸŸ¢ audiobook_49 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_5 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_50 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_51 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_52 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_53 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_54 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_55 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_56 lab:64 wav:64 txt:64 log:64\n",
    "ğŸŸ¢ audiobook_57 lab:188 wav:188 txt:188 log:188\n",
    "ğŸŸ¢ audiobook_58 lab:188 wav:188 txt:188 log:188\n",
    "ğŸŸ¢ audiobook_59 lab:188 wav:188 txt:188 log:188\n",
    "ğŸŸ¢ audiobook_6 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_60 lab:188 wav:188 txt:188 log:188\n",
    "ğŸŸ¢ audiobook_61 lab:179 wav:179 txt:179 log:179\n",
    "ğŸŸ¢ audiobook_62 lab:472 wav:472 txt:472 log:472\n",
    "ğŸŸ¢ audiobook_63 lab:472 wav:472 txt:472 log:472\n",
    "ğŸŸ¢ audiobook_64 lab:472 wav:472 txt:472 log:472\n",
    "ğŸŸ¢ audiobook_65 lab:472 wav:472 txt:472 log:472\n",
    "ğŸŸ¢ audiobook_66 lab:207 wav:207 txt:207 log:207\n",
    "ğŸŸ¢ audiobook_67 lab:207 wav:207 txt:207 log:207\n",
    "ğŸŸ¢ audiobook_68 lab:207 wav:207 txt:207 log:207\n",
    "ğŸŸ¢ audiobook_69 lab:207 wav:207 txt:207 log:207\n",
    "ğŸŸ¢ audiobook_7 lab:178 wav:178 txt:178 log:178\n",
    "ğŸŸ¢ audiobook_70 lab:111 wav:111 txt:111 log:111\n",
    "ğŸŸ¢ audiobook_71 lab:111 wav:111 txt:111 log:111\n",
    "ğŸŸ¢ audiobook_72 lab:111 wav:111 txt:111 log:111\n",
    "ğŸŸ¢ audiobook_73 lab:111 wav:111 txt:111 log:111\n",
    "ğŸŸ¢ audiobook_8 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ audiobook_9 lab:112 wav:112 txt:112 log:112\n",
    "ğŸŸ¢ text lab:0 wav:0 txt:0 log:0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.fix_align.pyã§labã‹ã‚‰lab2ã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `./fix_align_all.sh > \"/home/takeshun256/PausePrediction/logs/fix_align_all_2023-11-01_20:10.log\" 2>&1` ã§lab2ã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_30/audiobook_30_171.lab\"\n",
    "with open(s, \"r\") as f:\n",
    "    s = f.readlines()\n",
    "s = [s.strip() for s in s]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.lab2ã‹ã‚‰ã€å½¢æ…‹ç´ å˜ä½ã®labã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. éŸ³ç´ å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€å½¢æ…‹ç´ å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
    "2. ãã‚Œãã‚Œã®labãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€yamlãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éŸ³ç´ å˜ä½ã®labã‹ã‚‰ã€morphomeå˜ä½ã®labã‚’ä½œæˆã™ã‚‹\n",
    "def get_morp_lab_from_phon_lab(phon_lab: list, morp_phons_list: list):\n",
    "    # morp_phons_listã®åˆã‚ã¨æœ€å¾Œã®ã€Œã€ã€ã‚’å‰Šé™¤ã™ã‚‹\n",
    "    if morp_phons_list[0][0] == \"ã€\":\n",
    "        morp_phons_list = morp_phons_list[1:]\n",
    "    if morp_phons_list[-1][0] == \"ã€\":\n",
    "        morp_phons_list = morp_phons_list[:-1]\n",
    "\n",
    "    # assert (len(phon_lab) == sum([len(phons) for _, phons in morp_phons_list]) + 2), \\\n",
    "    #     f\"len(phon_lab): {len(phon_lab)}, sum([len(phons) for _, phons in morp_phons_list]): {sum([len(phons) for _, phons in morp_phons_list])} + silB + silE \\n phon_lab: {phon_lab} \\n morp_phons_list: {morp_phons_list}\"\n",
    "\n",
    "    # phon_labã‚’1ã¤ãšã¤å–ã‚Šå‡ºã—ã¦ã€morp_phons_listã®ã©ã®ãƒªã‚¹ãƒˆã«ã¯ã„ã‚‹ã‹æˆ»ã‚‰ãšã«æ¢ç´¢ã™ã‚‹\n",
    "    phon_lab = iter([s.strip() for s in phon_lab])\n",
    "    morp_lab = []\n",
    "\n",
    "    morp_lab.append(next(phon_lab))  # silB\n",
    "    for morp, phons in morp_phons_list:\n",
    "        starts = []\n",
    "        ends = []\n",
    "        if morp == \"ã€\":\n",
    "            start, end, phon = next(phon_lab).split()\n",
    "            starts.append(start)\n",
    "            ends.append(end)\n",
    "            assert phon == \"sp\", f\"phon: {phon}\"\n",
    "        else:\n",
    "            i = 0\n",
    "            while True:\n",
    "                start, end, phon = next(phon_lab).split()\n",
    "                starts.append(start)\n",
    "                ends.append(end)\n",
    "                if phon == \"sp\":\n",
    "                    continue\n",
    "                if phon == phons[i]:\n",
    "                    i += 1\n",
    "                if i == len(phons):\n",
    "                    break\n",
    "\n",
    "            # for _ in range(len(phons)):\n",
    "            #     start, end, _ = next(phon_lab).split()\n",
    "            #     starts.append(start)\n",
    "            #     ends.append(end)\n",
    "\n",
    "        morp_l = f\"{min(starts)} {max(ends)} {morp}\"\n",
    "        morp_lab.append(morp_l)\n",
    "    morp_lab.append(next(phon_lab))  # silE\n",
    "\n",
    "    return morp_lab\n",
    "\n",
    "\n",
    "phon_lab = [\n",
    "    \"0.0000000 0.4051875 silB\\n\",\n",
    "    \"0.4051875 0.5051875 k\\n\",\n",
    "    \"0.5051875 0.5351875 o\\n\",\n",
    "    \"0.5351875 0.5751875 r\\n\",\n",
    "    \"0.5751875 0.6451875 e\\n\",\n",
    "    \"0.6451875 0.8351875 w\\n\",\n",
    "    \"0.8351875 0.9751875 a\\n\",\n",
    "    \"0.9751875 1.6269375 sp\\n\",\n",
    "    \"1.6269375 1.7169375 w\\n\",\n",
    "    \"1.7169375 1.7769375 a\\n\",\n",
    "    \"1.7769375 1.8369375 t\\n\",\n",
    "    \"1.8369375 1.8669375 a\\n\",\n",
    "    \"1.8669375 2.0169375 sh\\n\",\n",
    "    \"2.0169375 2.0669375 i\\n\",\n",
    "    \"2.0669375 2.1069375 g\\n\",\n",
    "    \"2.1069375 2.1969375 a\\n\",\n",
    "    \"2.1969375 2.3369375 ch\\n\",\n",
    "    \"2.3369375 2.4169375 i:\\n\",\n",
    "    \"2.4169375 2.5169375 s\\n\",\n",
    "    \"2.5169375 2.5769375 a\\n\",\n",
    "    \"2.5769375 2.6469375 i\\n\",\n",
    "    \"2.6469375 2.6869375 t\\n\",\n",
    "    \"2.6869375 2.7469375 o\\n\",\n",
    "    \"2.7469375 2.8269375 k\\n\",\n",
    "    \"2.8269375 2.8769375 i\\n\",\n",
    "    \"2.8769375 2.9469375 n\\n\",\n",
    "    \"2.9469375 3.1169375 i\\n\",\n",
    "    \"3.1169375 3.7069375 sp\\n\",\n",
    "    \"3.7069375 3.7869375 m\\n\",\n",
    "    \"3.7869375 3.8269375 u\\n\",\n",
    "    \"3.8269375 3.8769375 r\\n\",\n",
    "    \"3.8769375 3.9569375 a\\n\",\n",
    "    \"3.9569375 4.0369375 n\\n\",\n",
    "    \"4.0369375 4.1069375 o\\n\",\n",
    "    \"4.1069375 4.1769375 m\\n\",\n",
    "    \"4.1769375 4.2669375 o\\n\",\n",
    "    \"4.2669375 4.3569375 h\\n\",\n",
    "    \"4.3569375 4.5069375 e\\n\",\n",
    "    \"4.5069375 4.5469375 i\\n\",\n",
    "    \"4.5469375 4.6069375 t\\n\",\n",
    "    \"4.6069375 4.6969375 o\\n\",\n",
    "    \"4.6969375 4.7269375 i\\n\",\n",
    "    \"4.7269375 5.0569375 u\\n\",\n",
    "    \"5.0569375 5.1669375 o\\n\",\n",
    "    \"5.1669375 5.2669375 j\\n\",\n",
    "    \"5.2669375 5.3269375 i:\\n\",\n",
    "    \"5.3269375 5.4469375 s\\n\",\n",
    "    \"5.4469375 5.5069375 a\\n\",\n",
    "    \"5.5069375 5.5969375 N\\n\",\n",
    "    \"5.5969375 5.6569375 k\\n\",\n",
    "    \"5.6569375 5.7169375 a\\n\",\n",
    "    \"5.7169375 5.7469375 r\\n\",\n",
    "    \"5.7469375 5.8169375 a\\n\",\n",
    "    \"5.8169375 5.9669375 k\\n\",\n",
    "    \"5.9669375 6.1069375 i:\\n\",\n",
    "    \"6.1069375 6.1469375 t\\n\",\n",
    "    \"6.1469375 6.1969375 a\\n\",\n",
    "    \"6.1969375 6.2369375 o\\n\",\n",
    "    \"6.2369375 6.3869375 h\\n\",\n",
    "    \"6.3869375 6.4169375 a\\n\",\n",
    "    \"6.4169375 6.4769375 n\\n\",\n",
    "    \"6.4769375 6.5169375 a\\n\",\n",
    "    \"6.5169375 6.6369375 sh\\n\",\n",
    "    \"6.6369375 6.6769375 i\\n\",\n",
    "    \"6.6769375 6.7269375 d\\n\",\n",
    "    \"6.7269375 6.7869375 e\\n\",\n",
    "    \"6.7869375 6.9969375 s\\n\",\n",
    "    \"6.9969375 7.0269375 u\\n\",\n",
    "    \"7.0269375 7.2850000 silE\\n\",\n",
    "]\n",
    "morp_phons_list = [\n",
    "    [\"ã“ã‚Œ\", [\"k\", \"o\", \"r\", \"e\"]],\n",
    "    [\"ã¯\", [\"w\", \"a\"]],\n",
    "    [\"ã€\", [\"sp\"]],\n",
    "    [\"ç§\", [\"w\", \"a\", \"t\", \"a\", \"sh\", \"i\"]],\n",
    "    [\"ãŒ\", [\"g\", \"a\"]],\n",
    "    [\"å°ã•ã„\", [\"ch\", \"i:\", \"s\", \"a\", \"i\"]],\n",
    "    [\"ã¨ã\", [\"t\", \"o\", \"k\", \"i\"]],\n",
    "    [\"ã«\", [\"n\", \"i\"]],\n",
    "    [\"ã€\", [\"sp\"]],\n",
    "    [\"æ‘\", [\"m\", \"u\", \"r\", \"a\"]],\n",
    "    [\"ã®\", [\"n\", \"o\"]],\n",
    "    [\"èŒ‚å¹³\", [\"m\", \"o\", \"h\", \"e\", \"i\"]],\n",
    "    [\"ã¨\", [\"t\", \"o\"]],\n",
    "    [\"ã„ã†\", [\"i\", \"u\"]],\n",
    "    [\"ãŠã˜ã„ã•ã‚“\", [\"o\", \"j\", \"i:\", \"s\", \"a\", \"N\"]],\n",
    "    [\"ã‹ã‚‰\", [\"k\", \"a\", \"r\", \"a\"]],\n",
    "    [\"ãã„\", [\"k\", \"i:\"]],\n",
    "    [\"ãŸ\", [\"t\", \"a\"]],\n",
    "    [\"ãŠè©±\", [\"o\", \"h\", \"a\", \"n\", \"a\", \"sh\", \"i\"]],\n",
    "    [\"ã§ã™\", [\"d\", \"e\", \"s\", \"u\"]],\n",
    "    [\"ã€\", [\"sp\"]],\n",
    "]\n",
    "\n",
    "get_morp_lab_from_phon_lab(phon_lab, morp_phons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon_lab = [\n",
    "    \"0.0000000 0.4051875 silB\\n\",\n",
    "    \"0.4051875 0.5051875 k\\n\",\n",
    "    \"0.5051875 0.5351875 o\\n\",\n",
    "    \"0.5351875 0.5751875 r\\n\",\n",
    "    \"0.5751875 0.6451875 e\\n\",\n",
    "    \"0.6451875 0.8351875 w\\n\",\n",
    "    \"0.8351875 0.9751875 a\\n\",\n",
    "    \"0.9751875 1.6269375 sp\\n\",\n",
    "    \"1.6269375 1.7169375 w\\n\",\n",
    "    \"1.7169375 1.7769375 a\\n\",\n",
    "    \"1.7769375 1.8369375 t\\n\",\n",
    "    \"1.8369375 1.8669375 a\\n\",\n",
    "    \"1.8669375 2.0169375 sh\\n\",\n",
    "    \"2.0169375 2.0669375 i\\n\",\n",
    "    \"2.0669375 2.1069375 g\\n\",\n",
    "    \"2.1069375 2.1969375 a\\n\",\n",
    "    \"2.1969375 2.3369375 ch\\n\",\n",
    "    \"2.3369375 2.4169375 i:\\n\",\n",
    "    \"2.4169375 2.5169375 s\\n\",\n",
    "    \"2.5169375 2.5769375 a\\n\",\n",
    "    \"2.5769375 2.6469375 i\\n\",\n",
    "    \"2.6469375 2.6869375 t\\n\",\n",
    "    \"2.6869375 2.7469375 o\\n\",\n",
    "    \"2.7469375 2.8269375 k\\n\",\n",
    "    \"2.8269375 2.8769375 i\\n\",\n",
    "    \"2.8769375 2.9469375 n\\n\",\n",
    "    \"2.9469375 3.1169375 i\\n\",\n",
    "    \"3.1169375 3.7069375 sp\\n\",\n",
    "    \"3.7069375 3.7869375 m\\n\",\n",
    "    \"3.7869375 3.8269375 u\\n\",\n",
    "    \"3.8269375 3.8769375 r\\n\",\n",
    "    \"3.8769375 3.9569375 a\\n\",\n",
    "    \"3.9569375 4.0369375 n\\n\",\n",
    "    \"4.0369375 4.1069375 o\\n\",\n",
    "    \"4.1069375 4.1769375 m\\n\",\n",
    "    \"4.1769375 4.2669375 o\\n\",\n",
    "    \"4.2669375 4.3569375 h\\n\",\n",
    "    \"4.3569375 4.5069375 e\\n\",\n",
    "    \"4.5069375 4.5469375 i\\n\",\n",
    "    \"4.5469375 4.6069375 t\\n\",\n",
    "    \"4.6069375 4.6969375 o\\n\",\n",
    "    \"4.6969375 4.7269375 i\\n\",\n",
    "    \"4.7269375 5.0569375 u\\n\",\n",
    "    \"5.0569375 5.1669375 o\\n\",\n",
    "    \"5.1669375 5.2669375 j\\n\",\n",
    "    \"5.2669375 5.3269375 i:\\n\",\n",
    "    \"5.3269375 5.4469375 s\\n\",\n",
    "    \"5.4469375 5.5069375 a\\n\",\n",
    "    \"5.5069375 5.5969375 N\\n\",\n",
    "    \"5.5969375 5.6569375 k\\n\",\n",
    "    \"5.6569375 5.7169375 a\\n\",\n",
    "    \"5.7169375 5.7469375 r\\n\",\n",
    "    \"5.7469375 5.8169375 a\\n\",\n",
    "    \"5.8169375 5.9669375 k\\n\",\n",
    "    \"5.9669375 6.1069375 i:\\n\",\n",
    "    \"6.1069375 6.1469375 t\\n\",\n",
    "    \"6.1469375 6.1969375 a\\n\",\n",
    "    \"6.1969375 6.2369375 o\\n\",\n",
    "    \"6.2369375 6.3869375 h\\n\",\n",
    "    \"6.3869375 6.4169375 a\\n\",\n",
    "    \"6.4169375 6.4769375 n\\n\",\n",
    "    \"6.4769375 6.5169375 a\\n\",\n",
    "    \"6.5169375 6.6369375 sh\\n\",\n",
    "    \"6.6369375 6.6769375 i\\n\",\n",
    "    \"6.6769375 6.7269375 d\\n\",\n",
    "    \"6.7269375 6.7869375 e\\n\",\n",
    "    \"6.7869375 6.9969375 s\\n\",\n",
    "    \"6.9969375 7.0269375 u\\n\",\n",
    "    \"7.0269375 7.2850000 silE\\n\",\n",
    "]\n",
    "phon_lab = [s.strip() for s in phon_lab]\n",
    "phon_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon_lab = [\n",
    "    \"0.0000000 0.3808750 silB\\n\",\n",
    "    \"0.3808750 0.4713125 t\\n\",\n",
    "    \"0.4713125 0.5213125 o\\n\",\n",
    "    \"0.5213125 0.6713125 s\\n\",\n",
    "    \"0.6713125 0.7212500 a\\n\",\n",
    "    \"0.7212500 0.8613125 k\\n\",\n",
    "    \"0.8613125 0.9113125 e\\n\",\n",
    "    \"0.9113125 1.1313125 N\\n\",\n",
    "    \"1.1313125 1.1613125 d\\n\",\n",
    "    \"1.1613125 1.3775000 e\\n\",\n",
    "    \"1.3775000 2.1078750 sp\\n\",\n",
    "    \"2.1078750 2.1778750 m\\n\",\n",
    "    \"2.1778750 2.3178750 e\\n\",\n",
    "    \"2.3178750 2.4378750 o\\n\",\n",
    "    \"2.4378750 2.5578750 o\\n\",\n",
    "    \"2.5578750 2.7078750 s\\n\",\n",
    "    \"2.7078750 2.7978750 a\\n\",\n",
    "    \"2.7978750 2.9178750 e\\n\",\n",
    "    \"2.9178750 3.0078750 n\\n\",\n",
    "    \"3.0078750 3.1178750 a\\n\",\n",
    "    \"3.1178750 3.1678750 g\\n\",\n",
    "    \"3.1678750 3.2578750 a\\n\",\n",
    "    \"3.2578750 3.3078750 r\\n\",\n",
    "    \"3.3078750 3.5244375 a\\n\",\n",
    "    \"3.5244375 3.8215625 sp\\n\",\n",
    "    \"3.8215625 3.9963750 k\\n\",\n",
    "    \"3.9963750 4.1910625 sp\\n\",\n",
    "    \"4.1910625 4.3510625 a:\\n\",\n",
    "    \"4.3510625 4.4810625 s\\n\",\n",
    "    \"4.4810625 4.5910625 a\\n\",\n",
    "    \"4.5910625 4.7110625 N\\n\",\n",
    "    \"4.7110625 4.7410625 k\\n\",\n",
    "    \"4.7410625 4.8810625 i\\n\",\n",
    "    \"4.8810625 4.9610625 ts\\n\",\n",
    "    \"4.9610625 5.0110625 u\\n\",\n",
    "    \"5.0110625 5.0810625 n\\n\",\n",
    "    \"5.0810625 5.1410000 e\\n\",\n",
    "    \"5.1410000 5.2410625 n\\n\",\n",
    "    \"5.2410625 5.3310625 o\\n\",\n",
    "    \"5.3310625 5.4310625 t\\n\",\n",
    "    \"5.4310625 5.5010625 o\\n\",\n",
    "    \"5.5010625 5.6110625 k\\n\",\n",
    "    \"5.6110625 5.7010625 o\\n\",\n",
    "    \"5.7010625 5.7710625 r\\n\",\n",
    "    \"5.7710625 5.8610625 o\\n\",\n",
    "    \"5.8610625 6.0610625 e\\n\",\n",
    "    \"6.0610625 6.5841875 k\\n\",\n",
    "    \"6.5841875 6.6241875 o\\n\",\n",
    "    \"6.6241875 6.7141875 r\\n\",\n",
    "    \"6.7141875 6.8041875 o\\n\",\n",
    "    \"6.8041875 6.8841875 g\\n\",\n",
    "    \"6.8841875 6.9991875 e\\n\",\n",
    "    \"6.9991875 7.0393125 t\\n\",\n",
    "    \"7.0393125 7.1416875 e\\n\",\n",
    "    \"7.1416875 7.2360000 k\\n\",\n",
    "    \"7.2360000 7.2760000 i\\n\",\n",
    "    \"7.2760000 7.3460000 m\\n\",\n",
    "    \"7.3460000 7.4260000 a\\n\",\n",
    "    \"7.4260000 7.5660000 sh\\n\",\n",
    "    \"7.5660000 7.5960000 i\\n\",\n",
    "    \"7.5960000 7.6883125 t\\n\",\n",
    "    \"7.6883125 7.9083125 a\\n\",\n",
    "    \"7.9083125 8.2800000 silE\\n\",\n",
    "]\n",
    "morp_phons_list = [\n",
    "    [\"ã¨\", [\"t\", \"o\"]],\n",
    "    [\"å«ã‚“\", [\"s\", \"a\", \"k\", \"e\", \"N\"]],\n",
    "    [\"ã§\", [\"d\", \"e\"]],\n",
    "    [\"ã€\", [\"sp\"]],\n",
    "    [\"çœ¼\", [\"m\", \"e\"]],\n",
    "    [\"ã‚’\", [\"o\"]],\n",
    "    [\"æŠ‘ãˆ\", [\"o\", \"s\", \"a\", \"e\"]],\n",
    "    [\"ãªãŒã‚‰\", [\"n\", \"a\", \"g\", \"a\", \"r\", \"a\"]],\n",
    "    [\"ã€\", [\"sp\"]],\n",
    "    [\"æ¯ã•ã‚“\", [\"k\", \"a:\", \"s\", \"a\", \"N\"]],\n",
    "    [\"ç‹\", [\"k\", \"i\", \"ts\", \"u\", \"n\", \"e\"]],\n",
    "    [\"ã®\", [\"n\", \"o\"]],\n",
    "    [\"ã¨ã“ã‚\", [\"t\", \"o\", \"k\", \"o\", \"r\", \"o\"]],\n",
    "    [\"ã¸\", [\"e\"]],\n",
    "    [\"ã“ã‚ã’\", [\"k\", \"o\", \"r\", \"o\", \"g\", \"e\"]],\n",
    "    [\"ã¦\", [\"t\", \"e\"]],\n",
    "    [\"æ¥\", [\"k\", \"i\"]],\n",
    "    [\"ã¾ã—\", [\"m\", \"a\", \"sh\", \"i\"]],\n",
    "    [\"ãŸ\", [\"t\", \"a\"]],\n",
    "]\n",
    "print(len(phon_lab))\n",
    "print(sum([len(phons) for _, phons in morp_phons_list]) + 2)\n",
    "\n",
    "# éŸ³ç´ ã‚’ä¸¦ã¹ã‚‹\n",
    "print(\" \".join([s.strip().split(\" \")[2] for s in phon_lab[1:-1]]))\n",
    "print(\" \".join([p for _, phons in morp_phons_list for p in phons]))\n",
    "get_morp_lab_from_phon_lab(phon_lab, morp_phons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. éŸ³ç´ å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€å½¢æ…‹ç´ å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
    "morp_phons_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons.yaml\"\n",
    "lab_dict_path = Path(DATA_TAKESHUN256_DIR) / \"jmac_split_and_added_lab\"\n",
    "\n",
    "with open(morp_phons_yaml_path, \"r\") as f:\n",
    "    morp_phons_yaml_data = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(morp_phons_yaml_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. éŸ³ç´ å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã€å½¢æ…‹ç´ å˜ä½ã®labãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
    "# morp_phons_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons.yaml\"\n",
    "# lab_dict_path = Path(DATA_TAKESHUN256_DIR) / \"jmac_split_and_added_lab\"\n",
    "\n",
    "# with open(morp_phons_yaml_path, \"r\") as f:\n",
    "#     morp_phons_yaml_data = yaml.safe_load(f)\n",
    "\n",
    "# å„chapterã«ã¤ã„ã¦ã€lab2ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã€å½¢æ…‹ç´ å˜ä½ã®labmãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
    "new_morp_phons_yaml_data = {}\n",
    "for audiobook_name, info in morp_phons_yaml_data.items():\n",
    "    audiobook_dict = {}\n",
    "    print(f\"[INFO] audiobook_name: {audiobook_name}\")\n",
    "    for chapter_name, chapter_info in info[\"text\"].items():\n",
    "        phon_lab_path = (\n",
    "            lab_dict_path / audiobook_name / f\"{audiobook_name}_{chapter_name}.lab2\"\n",
    "        )\n",
    "        morp_lab_path = (\n",
    "            lab_dict_path / audiobook_name / f\"{audiobook_name}_{chapter_name}.labm\"\n",
    "        )\n",
    "        print(f\"[INFO] phon_lab_path: {phon_lab_path}\")\n",
    "        if not phon_lab_path.exists():\n",
    "            print(f\"[INFO] {phon_lab_path} is not exist.\")\n",
    "            continue\n",
    "\n",
    "        with open(phon_lab_path, \"r\") as f:\n",
    "            phon_lab = f.readlines()\n",
    "\n",
    "        if phon_lab == []:\n",
    "            print(f\"[INFO] {phon_lab_path} is empty.\")\n",
    "            with open(morp_lab_path, \"w\") as f:\n",
    "                f.write(\"\")\n",
    "            continue\n",
    "\n",
    "        morp_phons_list = chapter_info[\"morp_phons_list\"]\n",
    "\n",
    "        # ã‹ãªã‚Šã‚ºãƒ¬ã¦ã„ãŸã‚‰ã€ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "        if (\n",
    "            abs(len(phon_lab) - sum([len(phons) for _, phons in morp_phons_list]) - 2)\n",
    "            > 10\n",
    "        ):\n",
    "            print(f\"[INFO] {phon_lab_path} is too different.\")\n",
    "            continue\n",
    "\n",
    "        # phon_labgãŒsilB silEã®ã¿ã®å ´åˆã¯ã€ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹\n",
    "        if len(phon_lab) <= 2:\n",
    "            print(f\"[INFO] {phon_lab_path} is only silB silE.\")\n",
    "            continue\n",
    "\n",
    "        morp_lab = get_morp_lab_from_phon_lab(phon_lab, morp_phons_list)\n",
    "\n",
    "        with open(morp_lab_path, \"w\") as f:\n",
    "            for s in morp_lab:\n",
    "                f.write(f\"{s}\\n\")\n",
    "\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ãã‚Œãã‚Œã®labãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã€phon_lab, morp_labã¨ã—ã¦è¿½åŠ ã™ã‚‹\n",
    "morp_phons_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons.yaml\"\n",
    "lab_dict_path = Path(DATA_TAKESHUN256_DIR) / \"jmac_split_and_added_lab\"\n",
    "output_yaml_path = exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab.yaml\"\n",
    "\n",
    "with open(morp_phons_yaml_path, \"r\") as f:\n",
    "    morp_phons_yaml_data = yaml.safe_load(f)\n",
    "\n",
    "# å„chapterã«ã¤ã„ã¦ã€lab2ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã€ãã‚Œãã‚Œã®chapterã®phon_labã¨ã—ã¦è¿½åŠ ã™ã‚‹\n",
    "new_morp_phons_yaml_data = {}\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data.items()):\n",
    "    audiobook_dict = {}\n",
    "    for chapter_name, chapter_info in info[\"text\"].items():\n",
    "        phon_lab_path = (\n",
    "            lab_dict_path / audiobook_name / f\"{audiobook_name}_{chapter_name}.lab2\"\n",
    "        )\n",
    "        morp_lab_path = (\n",
    "            lab_dict_path / audiobook_name / f\"{audiobook_name}_{chapter_name}.labm\"\n",
    "        )\n",
    "\n",
    "        # if not phon_lab_path.exists() or not morp_lab_path.exists():\n",
    "        #     print(f\"[INFO] {phon_lab_path} or {morp_lab_path} is not exist.\")\n",
    "        #     continue\n",
    "\n",
    "        # with open(phon_lab_path, \"r\") as f:\n",
    "        #     lab_lines = f.readlines()\n",
    "        # lab_lines = [s.strip() for s in lab_lines]\n",
    "        # chapter_info[\"phon_lab\"] = lab_lines\n",
    "\n",
    "        # with open(morp_lab_path, \"r\") as f:\n",
    "        #     lab_lines = f.readlines()\n",
    "        # lab_lines = [s.strip() for s in lab_lines]\n",
    "        # chapter_info[\"morp_lab\"] = lab_lines\n",
    "\n",
    "        if not phon_lab_path.exists():\n",
    "            print(f\"[INFO] {phon_lab_path} is not exist.\")\n",
    "        else:\n",
    "            with open(phon_lab_path, \"r\") as f:\n",
    "                lab_lines = f.readlines()\n",
    "            lab_lines = [s.strip() for s in lab_lines]\n",
    "            chapter_info[\"phon_lab\"] = lab_lines\n",
    "\n",
    "        if not morp_lab_path.exists():\n",
    "            print(f\"[INFO] {morp_lab_path} is not exist.\")\n",
    "        else:\n",
    "            with open(morp_lab_path, \"r\") as f:\n",
    "                lab_lines = f.readlines()\n",
    "            lab_lines = [s.strip() for s in lab_lines]\n",
    "            chapter_info[\"morp_lab\"] = lab_lines\n",
    "\n",
    "        audiobook_dict[chapter_name] = chapter_info\n",
    "    new_morp_phons_yaml_data[audiobook_name] = audiobook_dict\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(new_morp_phons_yaml_data, f, allow_unicode=True)\n",
    "\n",
    "print(f\"output_yaml_path: {output_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_pause_rangesã‚’å®Ÿè¡Œå¾Œã€ã“ã“ã‹ã‚‰å®Ÿè¡Œã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç„¡éŸ³åŒºé–“ã®æƒ…å ±ã‚’å¾—ã¦ä¿å­˜ã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `get_pause_ranges.ipynb` ã§ç„¡éŸ³åŒºé–“ã®æƒ…å ±ã‚’å¾—ã¦ä¿å­˜ã™ã‚‹\n",
    "- `exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause.yaml\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.å„å½¢æ…‹ç´ é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_fix_runencode.yaml\"\n",
    ")\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "# picke\n",
    "# import pickle\n",
    "# with open(morp_phons_yaml_path_small, \"rb\") as f:\n",
    "#     morp_phons_yaml_data_small = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_data_small[\"audiobook_0\"][\"000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug\n",
    "chap = morp_phons_yaml_data_small[\"audiobook_0\"][\"000\"]\n",
    "morp_lab = chap[\"morp_lab\"]\n",
    "pause_ranges_str = chap[\"pause_ranges_str\"]\n",
    "pprint(morp_lab)\n",
    "print(pause_ranges_str)\n",
    "\n",
    "sr = 24000\n",
    "\n",
    "pause_ranges_str = [s.split(\" \") for s in pause_ranges_str]\n",
    "pause_range = [\n",
    "    [float(start) / sr, float(end) / sr, float(length) / sr]\n",
    "    for start, end, length in pause_ranges_str\n",
    "]\n",
    "pprint(pause_range)\n",
    "\n",
    "morp_pause_list = []\n",
    "for i, s in enumerate(morp_lab):\n",
    "    start, end, morp = s.strip().split(\" \")\n",
    "    start = float(start)\n",
    "    end = float(end)\n",
    "\n",
    "    print(f\"start: {start}, end: {end}, morp: {morp}\")\n",
    "    for pause_start, pause_end, pause_length in pause_range:\n",
    "        if pause_start <= start <= pause_end:\n",
    "            print(f\"pause_start: {pause_start}, pause_end: {pause_end}\")\n",
    "            morp_pause_list.append(\"[PAUSE]\")\n",
    "    morp_pause_list.append(morp)\n",
    "    for pause_start, pause_end, pause_length in pause_range:\n",
    "        if pause_start <= end <= pause_end:\n",
    "            morp_pause_list.append(\"[PAUSE]\")\n",
    "    print(morp_pause_list)\n",
    "\n",
    "print(morp_pause_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml_path = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_str.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_fix_encode_str.yaml\"\n",
    ")\n",
    "sr = 24000\n",
    "\n",
    "\n",
    "output_yaml_data = {}\n",
    "# å„ morp_lab ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ™‚åˆ»ãŒç„¡éŸ³åŒºé–“ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        morp_lab = chapter_info[\"morp_lab\"]\n",
    "        pause_ranges_str = chapter_info[\"pause_ranges_str\"]\n",
    "        pause_ranges_str = [s.split(\" \") for s in pause_ranges_str]\n",
    "        pause_ranges = [\n",
    "            [float(start) / sr, float(end) / sr, float(length) / sr]\n",
    "            for start, end, length in pause_ranges_str\n",
    "        ]\n",
    "\n",
    "        morp_pause_list = []\n",
    "\n",
    "        # morp_labã‚’çµåˆã™ã‚‹éš›ã«ã€ãã®é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹å ´åˆã¯ã€ç„¡éŸ³åŒºé–“[PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "        for i, s in enumerate(morp_lab):\n",
    "            start, end, morp = s.strip().split(\" \")\n",
    "            start = float(start)\n",
    "            end = float(end)\n",
    "\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= start <= pause_end:\n",
    "                    morp_pause_list.append(\"[PAUSE]\")\n",
    "            morp_pause_list.append(morp)\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= end <= pause_end:\n",
    "                    morp_pause_list.append(\"[PAUSE]\")\n",
    "\n",
    "\n",
    "        # print(morp_pause_list)\n",
    "        # morp_pause_listã‚’çµåˆã—ã¦ã€morp_pause_clipã‚’ä½œæˆã™ã‚‹\n",
    "        # rule1. é€£ç¶šã—ã¦ã„ã‚‹[PAUSE]ã¯1ã¤ã«ã¾ã¨ã‚ã‚‹\n",
    "        # rule2. silB, silEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        # rule3, spã‚’[PAUSE]ã«å¤‰æ›ã™ã‚‹\n",
    "        morp_pause_clip = []\n",
    "        for i, s in enumerate(morp_pause_list):\n",
    "            if s == \"[PAUSE]\":\n",
    "                if len(morp_pause_clip) != 0:\n",
    "                    if morp_pause_clip[-1] == \"[PAUSE]\":\n",
    "                        continue\n",
    "            if s == \"silB\" or s == \"silE\":\n",
    "                continue\n",
    "            # if s == \"ã€\":\n",
    "            #     s = \"[PAUSE]\"\n",
    "            morp_pause_clip.append(s)\n",
    "        morp_pause_str = \"\".join(morp_pause_clip)\n",
    "\n",
    "        # chapter_infoã«è¿½åŠ ã™ã‚‹\n",
    "        chapter_info[\"morp_pause_str\"] = morp_pause_str\n",
    "        chapter_info[\"morp_pause_clip\"] = morp_pause_clip\n",
    "        info[chapter_name] = chapter_info\n",
    "    output_yaml_data[audiobook_name] = info\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(output_yaml_data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml_data[\"audiobook_0\"][\"000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒãƒ¼ã‚ºé•·ã®ãƒ‡ãƒ¼ã‚¿ã‚‚ä½œæˆã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml_path = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_str.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str.yaml\"\n",
    ")\n",
    "sr = 24000\n",
    "\n",
    "\n",
    "# å„pause_rangeã«å¯¾ã—ã¦ã€ãã®ä¸­ã®morpsã‚’å–å¾—ã™ã‚‹ã€‚\n",
    "# ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "\n",
    "\n",
    "output_yaml_data = {}\n",
    "# å„ morp_lab ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ™‚åˆ»ãŒç„¡éŸ³åŒºé–“ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        morp_lab = chapter_info[\"morp_lab\"]\n",
    "        pause_ranges_str = chapter_info[\"pause_ranges_str\"]\n",
    "        pause_ranges_str = [s.split(\" \") for s in pause_ranges_str]\n",
    "        pause_ranges = [\n",
    "            [float(start) / sr, float(end) / sr, float(length) / sr]\n",
    "            for start, end, length in pause_ranges_str\n",
    "        ]\n",
    "\n",
    "        morp_pause_list = []\n",
    "        continue_break = False\n",
    "        # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "        for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            for i, s in enumerate(morp_lab):\n",
    "                start, end, morp = s.strip().split(\" \")\n",
    "                start = float(start)\n",
    "                end = float(end)\n",
    "                if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "                    if morp not in [\"ã€\", \"silB\", \"silE\"]:\n",
    "                        # raise Exception(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        print(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        continue_break = True\n",
    "        if continue_break:\n",
    "            print(f\"[INFO] {audiobook_name} {chapter_name} is skipped.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # morp_labã‚’çµåˆã™ã‚‹éš›ã«ã€ãã®é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹å ´åˆã¯ã€ç„¡éŸ³åŒºé–“[PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "        for i, s in enumerate(morp_lab):\n",
    "            start, end, morp = s.strip().split(\" \")\n",
    "            start = float(start)\n",
    "            end = float(end)\n",
    "            \n",
    "            # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "            # for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            #     if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "            #         if morp != \"ã€\":\n",
    "            #             morps = [m for m in morp_pause_list if m != \"ã€\"]\n",
    "            #             assert len(morps) < 1, f\"len(morps): {len(morps)}, morps: {morps}\"\n",
    "            #         break\n",
    "\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "            # = morphãŒã€Œã€ã€ã®å ´åˆã¯ã€ãã®ä¸­ã«å«ã¾ã‚Œã‚‹pause rangeãŒãªã„ã‹è¦‹ã¦ã€ã‚ã‚Œã°ãã®pause_rangeã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= start <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            if morp == \"ã€\":\n",
    "                for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                    if start <= pause_start <= end and start <= pause_end <= end:\n",
    "                        morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "                        break\n",
    "            \n",
    "            morp_pause_list.append(morp)\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= end <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # print(morp_pause_list)\n",
    "        # morp_pause_listã‚’çµåˆã—ã¦ã€morp_pause_clipã‚’ä½œæˆã™ã‚‹\n",
    "        # rule1. é€£ç¶šã—ã¦ã„ã‚‹[PAUSE]ã¯1ã¤ã«ã¾ã¨ã‚ã‚‹\n",
    "        # rule2. silB, silEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        # rule3, spã‚’[PAUSE]ã«å¤‰æ›ã™ã‚‹\n",
    "        morp_pause_clip = []\n",
    "        for i, s in enumerate(morp_pause_list):\n",
    "            if \"PAUSE\" in s:\n",
    "                if len(morp_pause_clip) != 0:\n",
    "                    if \"PAUSE\" in morp_pause_clip[-1]:\n",
    "                        continue\n",
    "            if s == \"silB\" or s == \"silE\":\n",
    "                continue\n",
    "            # if s == \"ã€\":\n",
    "            #     s = \"[PAUSE]\"\n",
    "            morp_pause_clip.append(s)\n",
    "        morp_pause_str = \"\".join(morp_pause_clip)\n",
    "\n",
    "        # chapter_infoã«è¿½åŠ ã™ã‚‹\n",
    "        chapter_info[\"morp_pause_str\"] = morp_pause_str\n",
    "        chapter_info[\"morp_pause_clip\"] = morp_pause_clip\n",
    "        info[chapter_name] = chapter_info\n",
    "    output_yaml_data[audiobook_name] = info\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(output_yaml_data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¿ƒéŸ³ã®ãƒãƒ¼ã‚ºã¯å…¥ã‚Œãªã„è¨ˆæ¸¬ã‚‚ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml_path = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_str.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str_wo_sokuon.yaml\"\n",
    ")\n",
    "sr = 24000\n",
    "\n",
    "\n",
    "# å„pause_rangeã«å¯¾ã—ã¦ã€ãã®ä¸­ã®morpsã‚’å–å¾—ã™ã‚‹ã€‚\n",
    "# ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "\n",
    "\n",
    "output_yaml_data = {}\n",
    "# å„ morp_lab ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ™‚åˆ»ãŒç„¡éŸ³åŒºé–“ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        morp_lab = chapter_info[\"morp_lab\"]\n",
    "        pause_ranges_str = chapter_info[\"pause_ranges_str\"]\n",
    "        pause_ranges_str = [s.split(\" \") for s in pause_ranges_str]\n",
    "        pause_ranges = [\n",
    "            [float(start) / sr, float(end) / sr, float(length) / sr]\n",
    "            for start, end, length in pause_ranges_str\n",
    "        ]\n",
    "\n",
    "        morp_pause_list = []\n",
    "        continue_break = False\n",
    "        # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "        for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            for i, s in enumerate(morp_lab):\n",
    "                start, end, morp = s.strip().split(\" \")\n",
    "                start = float(start)\n",
    "                end = float(end)\n",
    "                if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "                    if morp not in [\"ã€\", \"silB\", \"silE\"]:\n",
    "                        # raise Exception(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        print(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        continue_break = True\n",
    "        if continue_break:\n",
    "            print(f\"[INFO] {audiobook_name} {chapter_name} is skipped.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # morp_labã‚’çµåˆã™ã‚‹éš›ã«ã€ãã®é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹å ´åˆã¯ã€ç„¡éŸ³åŒºé–“[PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "        for i, s in enumerate(morp_lab):\n",
    "            start, end, morp = s.strip().split(\" \")\n",
    "            start = float(start)\n",
    "            end = float(end)\n",
    "            \n",
    "            # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "            # for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            #     if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "            #         if morp != \"ã€\":\n",
    "            #             morps = [m for m in morp_pause_list if m != \"ã€\"]\n",
    "            #             assert len(morps) < 1, f\"len(morps): {len(morps)}, morps: {morps}\"\n",
    "            #         break\n",
    "\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "            # = morphãŒã€Œã€ã€ã®å ´åˆã¯ã€ãã®ä¸­ã«å«ã¾ã‚Œã‚‹pause rangeãŒãªã„ã‹è¦‹ã¦ã€ã‚ã‚Œã°ãã®pause_rangeã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= start <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            if morp == \"ã€\":\n",
    "                for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                    if start <= pause_start <= end and start <= pause_end <= end:\n",
    "                        morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "                        break\n",
    "            \n",
    "            morp_pause_list.append(morp)\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= end <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # print(morp_pause_list)\n",
    "        # morp_pause_listã‚’çµåˆã—ã¦ã€morp_pause_clipã‚’ä½œæˆã™ã‚‹\n",
    "        # rule1. é€£ç¶šã—ã¦ã„ã‚‹[PAUSE]ã¯1ã¤ã«ã¾ã¨ã‚ã‚‹\n",
    "        # rule2. silB, silEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        # rule3, spã‚’[PAUSE]ã«å¤‰æ›ã™ã‚‹\n",
    "        morp_pause_clip = []\n",
    "        for i, s in enumerate(morp_pause_list):\n",
    "            if \"PAUSE\" in s:\n",
    "                if len(morp_pause_clip) != 0:\n",
    "                    if \"PAUSE\" in morp_pause_clip[-1]:\n",
    "                        continue\n",
    "            if s == \"silB\" or s == \"silE\":\n",
    "                continue\n",
    "            # if s == \"ã€\":\n",
    "            #     s = \"[PAUSE]\"\n",
    "            morp_pause_clip.append(s)\n",
    "        \n",
    "        #  PAUSEã®ç›´å‰ã®morpã®æœ€å¾Œã®æ–‡å­—ãŒã€Œã£ã€ã®å ´åˆã¯ã€PAUSEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        morp_pause_clip_new = []\n",
    "        for i, s in enumerate(morp_pause_clip):\n",
    "            if (\"PAUSE\" in s) and (i != 0):\n",
    "                if (morp_pause_clip[i-1][-1] == \"ã£\" or morp_pause_clip[i-1][-1] == \"ãƒƒ\"):\n",
    "                    print(f\"[INFO] {morp_pause_clip[i-1]} == ä¿ƒéŸ³ã®ãŸã‚ã€PAUSEã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "                else:\n",
    "                    morp_pause_clip_new.append(s)\n",
    "            else:\n",
    "                morp_pause_clip_new.append(s)\n",
    "        \n",
    "        morp_pause_str = \"\".join(morp_pause_clip_new)\n",
    "\n",
    "        # chapter_infoã«è¿½åŠ ã™ã‚‹\n",
    "        chapter_info[\"morp_pause_str\"] = morp_pause_str\n",
    "        chapter_info[\"morp_pause_clip\"] = morp_pause_clip_new\n",
    "        info[chapter_name] = chapter_info\n",
    "    output_yaml_data[audiobook_name] = info\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(output_yaml_data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.ãƒªã‚¹ãƒˆã§ã€(å½¢æ…‹ç´ , True, å½¢æ…‹ç´ , False, ...)ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_fix_encode_str.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "df = []\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        if (\n",
    "            \"morp_pause_str\" not in chapter_info\n",
    "            or \"morp_pause_clip\" not in chapter_info\n",
    "        ):\n",
    "            continue\n",
    "        morp_pause_str = chapter_info[\"morp_pause_str\"]\n",
    "        morp_pause_clip = chapter_info[\"morp_pause_clip\"]\n",
    "\n",
    "        df.append([audiobook_name, chapter_name, morp_pause_str, morp_pause_clip])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df, columns=[\"audiobook_name\", \"chapter_name\", \"morp_pause_str\", \"morp_pause_clip\"]\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(df[\"morp_pause_clip\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_no_pause(ss):\n",
    "    # [NO_PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "    result = []\n",
    "    for i in range(len(ss)):\n",
    "        # ãƒªã‚¹ãƒˆã®å…ˆé ­ã¨æœ€å¾Œã«ã‚‚[NO_PAUSE]ã‚’å…¥ã‚Œã‚‹ãŸã‚ã®æ¡ä»¶åˆ†å²\n",
    "        if i == 0 and ss[i] != \"[PAUSE]\":\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        elif i > 0 and ss[i-1] != \"[PAUSE]\" and ss[i] != \"[PAUSE]\":\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        result.append(ss[i])\n",
    "        if i == len(ss) - 1 and ss[i] != \"[PAUSE]\":\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "    return result\n",
    "\n",
    "# insert_no_pause(df[\"morp_pause_clip\"].iloc[0])\n",
    "\n",
    "df[\"morp_pause_clip_no_pause\"] = df[\"morp_pause_clip\"].apply(insert_no_pause)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(exp_dir / \"bert_traindata_pause_position.csv\", index=False)\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "df.to_pickle(exp_dir / \"bert_traindata_pause_position.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [\n",
    "    \"[PAUSE]\",\n",
    "    \"ã“ã‚Œ\",\n",
    "    \"ã¯\",\n",
    "    \"[PAUSE]\",\n",
    "    \"ç§\",\n",
    "    \"ãŒ\",\n",
    "    \"å°ã•ã„\",\n",
    "    \"ã¨ã\",\n",
    "    \"ã«\",\n",
    "    \"[PAUSE]\",\n",
    "    \"æ‘\",\n",
    "    \"ã®\",\n",
    "    \"èŒ‚å¹³\",\n",
    "    \"ã¨\",\n",
    "    \"ã„ã†\",\n",
    "    \"ãŠã˜ã„ã•ã‚“\",\n",
    "    \"ã‹ã‚‰\",\n",
    "    \"ãã„\",\n",
    "    \"ãŸ\",\n",
    "    \"ãŠè©±\",\n",
    "    \"[PAUSE]\",\n",
    "    \"ã§ã™\",\n",
    "]\n",
    "ss = df[\"morp_pause_clip\"].iloc[0]\n",
    "\n",
    "# ãƒªã‚¹ãƒˆã‚’ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒˆã—ã¦[PAUSE]ãŒãªã„å ´æ‰€ã«[NO_PAUSE]ã‚’æŒ¿å…¥\n",
    "result = []\n",
    "for i in range(len(ss)):\n",
    "    # ãƒªã‚¹ãƒˆã®å…ˆé ­ã¨æœ€å¾Œã«ã‚‚[NO_PAUSE]ã‚’å…¥ã‚Œã‚‹ãŸã‚ã®æ¡ä»¶åˆ†å²\n",
    "    if i == 0 and ss[i] != \"[PAUSE]\":\n",
    "        result.append(\"[NO_PAUSE]\")\n",
    "    elif i > 0 and ss[i-1] != \"[PAUSE]\" and ss[i] != \"[PAUSE]\":\n",
    "        result.append(\"[NO_PAUSE]\")\n",
    "    result.append(ss[i])\n",
    "    if i == len(ss) - 1 and ss[i] != \"[PAUSE]\":\n",
    "        result.append(\"[NO_PAUSE]\")\n",
    "\n",
    "print(result)\n",
    "\n",
    "# [PAUSE]ã‚’1, [NO_PAUSE]ã‚’0ã«å¤‰æ›ã—ã€ãã‚Œä»¥å¤–ã¯ãã®ã¾ã¾ä¿æŒ\n",
    "final_list = [1 if word == \"[PAUSE]\" else 0 if word == \"[NO_PAUSE]\" else word for word in result]\n",
    "print(final_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [\n",
    "    \"[PAUSE]\",\n",
    "    \"ã“ã‚Œ\",\n",
    "    \"ã¯\",\n",
    "    \"[PAUSE]\",\n",
    "    \"ç§\",\n",
    "    \"ãŒ\",\n",
    "    \"å°ã•ã„\",\n",
    "    \"ã¨ã\",\n",
    "    \"ã«\",\n",
    "    \"[PAUSE]\",\n",
    "    \"æ‘\",\n",
    "    \"ã®\",\n",
    "    \"èŒ‚å¹³\",\n",
    "    \"ã¨\",\n",
    "    \"ã„ã†\",\n",
    "    \"ãŠã˜ã„ã•ã‚“\",\n",
    "    \"ã‹ã‚‰\",\n",
    "    \"ãã„\",\n",
    "    \"ãŸ\",\n",
    "    \"ãŠè©±\",\n",
    "    \"[PAUSE]\",\n",
    "    \"ã§ã™\",\n",
    "]\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morp_pause_clipã«ã¤ã„ã¦ã€å„å½¢æ…‹ç´ ã®é–“ã«[PAUSE]ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹\n",
    "df.loc[0, \"morp_pause_clip\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.ãƒªã‚¹ãƒˆã§ã€(å½¢æ…‹ç´ , True, å½¢æ…‹ç´ , False, ...)ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ lengthã‚‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "df = []\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        if (\n",
    "            \"morp_pause_str\" not in chapter_info\n",
    "            or \"morp_pause_clip\" not in chapter_info\n",
    "        ):\n",
    "            continue\n",
    "        morp_pause_str = chapter_info[\"morp_pause_str\"]\n",
    "        morp_pause_clip = chapter_info[\"morp_pause_clip\"]\n",
    "\n",
    "        df.append([audiobook_name, chapter_name, morp_pause_str, morp_pause_clip])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df, columns=[\"audiobook_name\", \"chapter_name\", \"morp_pause_str\", \"morp_pause_clip\"]\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(df[\"morp_pause_clip\"].iloc[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_no_pause(ss):\n",
    "    # [NO_PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "    result = []\n",
    "    for i in range(len(ss)):\n",
    "        # ãƒªã‚¹ãƒˆã®å…ˆé ­ã¨æœ€å¾Œã«ã‚‚[NO_PAUSE]ã‚’å…¥ã‚Œã‚‹ãŸã‚ã®æ¡ä»¶åˆ†å²\n",
    "        if i == 0 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        elif i > 0 and \"PAUSE\" not in ss[i-1] and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        result.append(ss[i])\n",
    "        if i == len(ss) - 1 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "    return result\n",
    "\n",
    "# insert_no_pause(df[\"morp_pause_clip\"].iloc[0])\n",
    "\n",
    "df[\"morp_pause_clip_no_pause\"] = df[\"morp_pause_clip\"].apply(insert_no_pause)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(exp_dir / \"bert_traindata_pause_position_with_length.csv\", index=False)\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "df.to_pickle(exp_dir / \"bert_traindata_pause_position_with_length.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"morp_pause_clip_no_pause\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.ãƒªã‚¹ãƒˆã§ã€(å½¢æ…‹ç´ , True, å½¢æ…‹ç´ , False, ...)ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ lengthã‚‚, ä¿ƒéŸ³ã®ãƒãƒ¼ã‚ºã¯å…¥ã‚Œãªã„è¨ˆæ¸¬ã‚‚ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str_wo_sokuon.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "df = []\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        if (\n",
    "            \"morp_pause_str\" not in chapter_info\n",
    "            or \"morp_pause_clip\" not in chapter_info\n",
    "        ):\n",
    "            continue\n",
    "        morp_pause_str = chapter_info[\"morp_pause_str\"]\n",
    "        morp_pause_clip = chapter_info[\"morp_pause_clip\"]\n",
    "\n",
    "        df.append([audiobook_name, chapter_name, morp_pause_str, morp_pause_clip])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df, columns=[\"audiobook_name\", \"chapter_name\", \"morp_pause_str\", \"morp_pause_clip\"]\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(df[\"morp_pause_clip\"].iloc[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_no_pause(ss):\n",
    "    # [NO_PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "    result = []\n",
    "    for i in range(len(ss)):\n",
    "        # ãƒªã‚¹ãƒˆã®å…ˆé ­ã¨æœ€å¾Œã«ã‚‚[NO_PAUSE]ã‚’å…¥ã‚Œã‚‹ãŸã‚ã®æ¡ä»¶åˆ†å²\n",
    "        if i == 0 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        elif i > 0 and \"PAUSE\" not in ss[i-1] and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        result.append(ss[i])\n",
    "        if i == len(ss) - 1 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "    return result\n",
    "\n",
    "# insert_no_pause(df[\"morp_pause_clip\"].iloc[0])\n",
    "\n",
    "df[\"morp_pause_clip_no_pause\"] = df[\"morp_pause_clip\"].apply(insert_no_pause)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon.csv\", index=False)\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "df.to_pickle(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"morp_pause_clip_no_pause\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80msã®timeé–¾å€¤ã®ãƒãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ä¿ƒéŸ³ã®ãƒãƒ¼ã‚ºã¯å…¥ã‚Œãªã„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_fix_runencode_80ms.yaml\"\n",
    ")\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "# picke\n",
    "# import pickle\n",
    "# with open(morp_phons_yaml_path_small, \"rb\") as f:\n",
    "#     morp_phons_yaml_data_small = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml_path = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_str.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str_wo_sokuon_80ms.yaml\"\n",
    ")\n",
    "sr = 24000\n",
    "\n",
    "\n",
    "# å„pause_rangeã«å¯¾ã—ã¦ã€ãã®ä¸­ã®morpsã‚’å–å¾—ã™ã‚‹ã€‚\n",
    "# ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "\n",
    "\n",
    "output_yaml_data = {}\n",
    "# å„ morp_lab ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ™‚åˆ»ãŒç„¡éŸ³åŒºé–“ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        morp_lab = chapter_info[\"morp_lab\"]\n",
    "        pause_ranges_str = chapter_info[\"pause_ranges_str\"]\n",
    "        pause_ranges_str = [s.split(\" \") for s in pause_ranges_str]\n",
    "        pause_ranges = [\n",
    "            [float(start) / sr, float(end) / sr, float(length) / sr]\n",
    "            for start, end, length in pause_ranges_str\n",
    "        ]\n",
    "\n",
    "        morp_pause_list = []\n",
    "        continue_break = False\n",
    "        # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "        for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            for i, s in enumerate(morp_lab):\n",
    "                start, end, morp = s.strip().split(\" \")\n",
    "                start = float(start)\n",
    "                end = float(end)\n",
    "                if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "                    if morp not in [\"ã€\", \"silB\", \"silE\"]:\n",
    "                        # raise Exception(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        print(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        continue_break = True\n",
    "        if continue_break:\n",
    "            print(f\"[INFO] {audiobook_name} {chapter_name} is skipped.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # morp_labã‚’çµåˆã™ã‚‹éš›ã«ã€ãã®é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹å ´åˆã¯ã€ç„¡éŸ³åŒºé–“[PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "        for i, s in enumerate(morp_lab):\n",
    "            start, end, morp = s.strip().split(\" \")\n",
    "            start = float(start)\n",
    "            end = float(end)\n",
    "            \n",
    "            # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "            # for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            #     if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "            #         if morp != \"ã€\":\n",
    "            #             morps = [m for m in morp_pause_list if m != \"ã€\"]\n",
    "            #             assert len(morps) < 1, f\"len(morps): {len(morps)}, morps: {morps}\"\n",
    "            #         break\n",
    "\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "            # = morphãŒã€Œã€ã€ã®å ´åˆã¯ã€ãã®ä¸­ã«å«ã¾ã‚Œã‚‹pause rangeãŒãªã„ã‹è¦‹ã¦ã€ã‚ã‚Œã°ãã®pause_rangeã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= start <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            if morp == \"ã€\":\n",
    "                for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                    if start <= pause_start <= end and start <= pause_end <= end:\n",
    "                        morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "                        break\n",
    "            \n",
    "            morp_pause_list.append(morp)\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= end <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # print(morp_pause_list)\n",
    "        # morp_pause_listã‚’çµåˆã—ã¦ã€morp_pause_clipã‚’ä½œæˆã™ã‚‹\n",
    "        # rule1. é€£ç¶šã—ã¦ã„ã‚‹[PAUSE]ã¯1ã¤ã«ã¾ã¨ã‚ã‚‹\n",
    "        # rule2. silB, silEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        # rule3, spã‚’[PAUSE]ã«å¤‰æ›ã™ã‚‹\n",
    "        morp_pause_clip = []\n",
    "        for i, s in enumerate(morp_pause_list):\n",
    "            if \"PAUSE\" in s:\n",
    "                if len(morp_pause_clip) != 0:\n",
    "                    if \"PAUSE\" in morp_pause_clip[-1]:\n",
    "                        continue\n",
    "            if s == \"silB\" or s == \"silE\":\n",
    "                continue\n",
    "            # if s == \"ã€\":\n",
    "            #     s = \"[PAUSE]\"\n",
    "            morp_pause_clip.append(s)\n",
    "        \n",
    "        #  PAUSEã®ç›´å‰ã®morpã®æœ€å¾Œã®æ–‡å­—ãŒã€Œã£ã€ã®å ´åˆã¯ã€PAUSEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        morp_pause_clip_new = []\n",
    "        for i, s in enumerate(morp_pause_clip):\n",
    "            if (\"PAUSE\" in s) and (i != 0):\n",
    "                if (morp_pause_clip[i-1][-1] == \"ã£\" or morp_pause_clip[i-1][-1] == \"ãƒƒ\"):\n",
    "                    print(f\"[INFO] {morp_pause_clip[i-1]} == ä¿ƒéŸ³ã®ãŸã‚ã€PAUSEã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "                else:\n",
    "                    morp_pause_clip_new.append(s)\n",
    "            else:\n",
    "                morp_pause_clip_new.append(s)\n",
    "        \n",
    "        morp_pause_str = \"\".join(morp_pause_clip_new)\n",
    "\n",
    "        # chapter_infoã«è¿½åŠ ã™ã‚‹\n",
    "        chapter_info[\"morp_pause_str\"] = morp_pause_str\n",
    "        chapter_info[\"morp_pause_clip\"] = morp_pause_clip_new\n",
    "        info[chapter_name] = chapter_info\n",
    "    output_yaml_data[audiobook_name] = info\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(output_yaml_data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str_wo_sokuon_80ms.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "df = []\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        if (\n",
    "            \"morp_pause_str\" not in chapter_info\n",
    "            or \"morp_pause_clip\" not in chapter_info\n",
    "        ):\n",
    "            continue\n",
    "        morp_pause_str = chapter_info[\"morp_pause_str\"]\n",
    "        morp_pause_clip = chapter_info[\"morp_pause_clip\"]\n",
    "\n",
    "        df.append([audiobook_name, chapter_name, morp_pause_str, morp_pause_clip])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df, columns=[\"audiobook_name\", \"chapter_name\", \"morp_pause_str\", \"morp_pause_clip\"]\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_no_pause(ss):\n",
    "    # [NO_PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "    result = []\n",
    "    for i in range(len(ss)):\n",
    "        # ãƒªã‚¹ãƒˆã®å…ˆé ­ã¨æœ€å¾Œã«ã‚‚[NO_PAUSE]ã‚’å…¥ã‚Œã‚‹ãŸã‚ã®æ¡ä»¶åˆ†å²\n",
    "        if i == 0 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        elif i > 0 and \"PAUSE\" not in ss[i-1] and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        result.append(ss[i])\n",
    "        if i == len(ss) - 1 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "    return result\n",
    "\n",
    "# insert_no_pause(df[\"morp_pause_clip\"].iloc[0])\n",
    "\n",
    "df[\"morp_pause_clip_no_pause\"] = df[\"morp_pause_clip\"].apply(insert_no_pause)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon_80ms.csv\", index=False)\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "df.to_pickle(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon_80ms.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100msã®timeé–¾å€¤ã®ãƒãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ä¿ƒéŸ³ã®ãƒãƒ¼ã‚ºã¯å…¥ã‚Œãªã„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_fix_runencode_100ms.yaml\"\n",
    ")\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "# picke\n",
    "# import pickle\n",
    "# with open(morp_phons_yaml_path_small, \"rb\") as f:\n",
    "#     morp_phons_yaml_data_small = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_yaml_path = (\n",
    "    # exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_small_str.yaml\"\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str_wo_sokuon_100ms.yaml\"\n",
    ")\n",
    "sr = 24000\n",
    "\n",
    "\n",
    "# å„pause_rangeã«å¯¾ã—ã¦ã€ãã®ä¸­ã®morpsã‚’å–å¾—ã™ã‚‹ã€‚\n",
    "# ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "# pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "\n",
    "\n",
    "output_yaml_data = {}\n",
    "# å„ morp_lab ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ™‚åˆ»ãŒç„¡éŸ³åŒºé–“ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        morp_lab = chapter_info[\"morp_lab\"]\n",
    "        pause_ranges_str = chapter_info[\"pause_ranges_str\"]\n",
    "        pause_ranges_str = [s.split(\" \") for s in pause_ranges_str]\n",
    "        pause_ranges = [\n",
    "            [float(start) / sr, float(end) / sr, float(length) / sr]\n",
    "            for start, end, length in pause_ranges_str\n",
    "        ]\n",
    "\n",
    "        morp_pause_list = []\n",
    "        continue_break = False\n",
    "        # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "        for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            for i, s in enumerate(morp_lab):\n",
    "                start, end, morp = s.strip().split(\" \")\n",
    "                start = float(start)\n",
    "                end = float(end)\n",
    "                if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "                    if morp not in [\"ã€\", \"silB\", \"silE\"]:\n",
    "                        # raise Exception(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        print(f\"pause_start: {pause_start}, pause_end: {pause_end}, morp: {morp}\")\n",
    "                        continue_break = True\n",
    "        if continue_break:\n",
    "            print(f\"[INFO] {audiobook_name} {chapter_name} is skipped.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # morp_labã‚’çµåˆã™ã‚‹éš›ã«ã€ãã®é–“ã«ç„¡éŸ³åŒºé–“ãŒã‚ã‚‹å ´åˆã¯ã€ç„¡éŸ³åŒºé–“[PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "        for i, s in enumerate(morp_lab):\n",
    "            start, end, morp = s.strip().split(\" \")\n",
    "            start = float(start)\n",
    "            end = float(end)\n",
    "            \n",
    "            # ã€ã‚’é™¤ã„ãŸmorpsã®æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ã€assertã™ã‚‹ã€‚\n",
    "            # for pause_start, pause_end, pause_length in pause_ranges:\n",
    "            #     if pause_start <= start <= pause_end and pause_start <= end <= pause_end:\n",
    "            #         if morp != \"ã€\":\n",
    "            #             morps = [m for m in morp_pause_list if m != \"ã€\"]\n",
    "            #             assert len(morps) < 1, f\"len(morps): {len(morps)}, morps: {morps}\"\n",
    "            #         break\n",
    "\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®endãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å¾Œã‚ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startã¨endãŒ0ã“ã®å ´åˆã¯ã€ãã®pause_rangeãŒå«ã¾ã‚Œã‚‹morpãŒã€Œã€ã€ã®å ´åˆã¯ã€Œã€ã€ã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚ãã‚Œä»¥å¤–ã®å ´åˆã¯pause_rangeã‚’å‰Šé™¤ã™ã‚‹ã€‚\n",
    "            # = morphãŒã€Œã€ã€ã®å ´åˆã¯ã€ãã®ä¸­ã«å«ã¾ã‚Œã‚‹pause rangeãŒãªã„ã‹è¦‹ã¦ã€ã‚ã‚Œã°ãã®pause_rangeã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            # pause_rangeã®ä¸­ã«å«ã¾ã‚Œã‚‹ã€morpã®startãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®morpã®å‰ã«pause_lengthã‚’è¿½åŠ ã™ã‚‹ã€‚\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= start <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            if morp == \"ã€\":\n",
    "                for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                    if start <= pause_start <= end and start <= pause_end <= end:\n",
    "                        morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "                        break\n",
    "            \n",
    "            morp_pause_list.append(morp)\n",
    "            for pause_start, pause_end, pause_length in pause_ranges:\n",
    "                if pause_start <= end <= pause_end:\n",
    "                    morp_pause_list.append(f\"[PAUSE {pause_length}]\")\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # print(morp_pause_list)\n",
    "        # morp_pause_listã‚’çµåˆã—ã¦ã€morp_pause_clipã‚’ä½œæˆã™ã‚‹\n",
    "        # rule1. é€£ç¶šã—ã¦ã„ã‚‹[PAUSE]ã¯1ã¤ã«ã¾ã¨ã‚ã‚‹\n",
    "        # rule2. silB, silEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        # rule3, spã‚’[PAUSE]ã«å¤‰æ›ã™ã‚‹\n",
    "        morp_pause_clip = []\n",
    "        for i, s in enumerate(morp_pause_list):\n",
    "            if \"PAUSE\" in s:\n",
    "                if len(morp_pause_clip) != 0:\n",
    "                    if \"PAUSE\" in morp_pause_clip[-1]:\n",
    "                        continue\n",
    "            if s == \"silB\" or s == \"silE\":\n",
    "                continue\n",
    "            # if s == \"ã€\":\n",
    "            #     s = \"[PAUSE]\"\n",
    "            morp_pause_clip.append(s)\n",
    "        \n",
    "        #  PAUSEã®ç›´å‰ã®morpã®æœ€å¾Œã®æ–‡å­—ãŒã€Œã£ã€ã®å ´åˆã¯ã€PAUSEã‚’å‰Šé™¤ã™ã‚‹\n",
    "        morp_pause_clip_new = []\n",
    "        for i, s in enumerate(morp_pause_clip):\n",
    "            if (\"PAUSE\" in s) and (i != 0):\n",
    "                if (morp_pause_clip[i-1][-1] == \"ã£\" or morp_pause_clip[i-1][-1] == \"ãƒƒ\"):\n",
    "                    print(f\"[INFO] {morp_pause_clip[i-1]} == ä¿ƒéŸ³ã®ãŸã‚ã€PAUSEã‚’å‰Šé™¤ã—ã¾ã™ã€‚\")\n",
    "                else:\n",
    "                    morp_pause_clip_new.append(s)\n",
    "            else:\n",
    "                morp_pause_clip_new.append(s)\n",
    "        \n",
    "        morp_pause_str = \"\".join(morp_pause_clip_new)\n",
    "\n",
    "        # chapter_infoã«è¿½åŠ ã™ã‚‹\n",
    "        chapter_info[\"morp_pause_str\"] = morp_pause_str\n",
    "        chapter_info[\"morp_pause_clip\"] = morp_pause_clip_new\n",
    "        info[chapter_name] = chapter_info\n",
    "    output_yaml_data[audiobook_name] = info\n",
    "    print(f\"[INFO] {audiobook_name} is saved.\")\n",
    "\n",
    "with open(output_yaml_path, \"w\") as f:\n",
    "    yaml.dump(output_yaml_data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morp_phons_yaml_path_small = (\n",
    "    exp_dir / \"text_audio_dict_new_with_morp_phons_and_lab_with_pause_with_length_small_fix_encode_str_wo_sokuon_100ms.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "with open(morp_phons_yaml_path_small, \"r\") as f:\n",
    "    morp_phons_yaml_data_small = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "df = []\n",
    "for audiobook_name, info in tqdm(morp_phons_yaml_data_small.items()):\n",
    "    for chapter_name, chapter_info in info.items():\n",
    "        if (\n",
    "            \"morp_pause_str\" not in chapter_info\n",
    "            or \"morp_pause_clip\" not in chapter_info\n",
    "        ):\n",
    "            continue\n",
    "        morp_pause_str = chapter_info[\"morp_pause_str\"]\n",
    "        morp_pause_clip = chapter_info[\"morp_pause_clip\"]\n",
    "\n",
    "        df.append([audiobook_name, chapter_name, morp_pause_str, morp_pause_clip])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df, columns=[\"audiobook_name\", \"chapter_name\", \"morp_pause_str\", \"morp_pause_clip\"]\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_no_pause(ss):\n",
    "    # [NO_PAUSE]ã‚’æŒ¿å…¥ã™ã‚‹\n",
    "    result = []\n",
    "    for i in range(len(ss)):\n",
    "        # ãƒªã‚¹ãƒˆã®å…ˆé ­ã¨æœ€å¾Œã«ã‚‚[NO_PAUSE]ã‚’å…¥ã‚Œã‚‹ãŸã‚ã®æ¡ä»¶åˆ†å²\n",
    "        if i == 0 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        elif i > 0 and \"PAUSE\" not in ss[i-1] and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "        result.append(ss[i])\n",
    "        if i == len(ss) - 1 and \"PAUSE\" not in ss[i]:\n",
    "            result.append(\"[NO_PAUSE]\")\n",
    "    return result\n",
    "\n",
    "# insert_no_pause(df[\"morp_pause_clip\"].iloc[0])\n",
    "\n",
    "df[\"morp_pause_clip_no_pause\"] = df[\"morp_pause_clip\"].apply(insert_no_pause)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon_100ms.csv\", index=False)\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "df.to_pickle(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon_100ms.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopenjtalk_julius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
