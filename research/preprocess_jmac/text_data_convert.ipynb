{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テキスト前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import yaml\n",
    "# import os\n",
    "# import glob\n",
    "# import sys\n",
    "# sys.path.append('/home/takeshun256/PausePrediction/src/analyze-J-MAC')\n",
    "# sys.path.append('/home/takeshun256/PausePrediction/src/vad_tool')\n",
    "# from audiobook_yaml_parser import extract_yaml_data\n",
    "# from py_webrtcvad_test import getVadSection\n",
    "# from vad_tool import VAD_Segmenter\n",
    "# from audiobook_dataset_builder import AudiobookDatasetBuilder\n",
    "# from audiobook_script_extractor import AudiobookScriptExtractor\n",
    "# # python==3.11以上の場合はimportしない\n",
    "# if sys.version_info < (3, 11):\n",
    "#     from text_preprocessing_preprocessor import AudiobookScriptPreprocessor\n",
    "# # from text_preprocessing import AudiobookScriptPreprocessor\n",
    "# from julius_lab_analysis import JuliusLabAnalyzer\n",
    "\n",
    "# import numpy as np\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# import japanize_matplotlib\n",
    "# import webrtcvad\n",
    "# from pprint import pprint\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# from tqdm import tqdm\n",
    "# from typing import List, Tuple, Dict, Any, Union\n",
    "\n",
    "# conda activate pyopenjtalk_julius\n",
    "\n",
    "# set path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "# import standard library\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# import own library\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "from src.analyze_jmac.text_preprocessing import (\n",
    "    AudiobookScriptPreprocessor as Preprocessor,\n",
    ")\n",
    "from src.analyze_jmac.mecab import mecab_wakati_generator, mecab_detailed_generator\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(yaml_file_path, \"r\") as f:\n",
    "    yaml_data = yaml.safe_load(f)\n",
    "pprint(yaml_data[\"audiobook_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original text\n",
    "\n",
    "# txt save path\n",
    "transcript_name = \"transcript_original\"\n",
    "\n",
    "transcript_dict = {}\n",
    "for audiobook_name, info in yaml_data.items():\n",
    "    # audiobookの名称を修正\n",
    "    # audiobook_1 -> AUDIOBOOK01\n",
    "    audiobook_name_fixed = \"AUDIOBOOK\" + audiobook_name.split(\"_\")[-1].zfill(2)\n",
    "    transcript_lines = []\n",
    "    for chapter_idx, chapter_info in enumerate(info[\"text\"]):\n",
    "        chapter_idx_str = str(chapter_idx).zfill(2)\n",
    "        transcript_lines.append(\n",
    "            f\"{audiobook_name_fixed}_{chapter_idx_str}\\t{chapter_info['sent']}\"\n",
    "        )\n",
    "    transcript_dict[audiobook_name_fixed] = transcript_lines\n",
    "\n",
    "pprint(transcript_lines[:3])\n",
    "\n",
    "# save\n",
    "# exp_dir / audiobook_name_fixed 下に {trascript_name}.txt として保存\n",
    "# 1行1文: \"{audiobook_name_fixed}_{chapter_idx_str} {chapter_info[\"sent\"]}\"\n",
    "\n",
    "for audiobook_name_fixed, transcript_lines in transcript_dict.items():\n",
    "    file_path = exp_dir / audiobook_name_fixed / f\"{transcript_name}.txt\"\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(transcript_lines))\n",
    "    print(f\"{file_path} saved.\")\n",
    "\n",
    "# for remove files\n",
    "# shell command\n",
    "# find /data2/takeshun256/03_VAD_Ajusted -name \"transcript_original.txt\"\n",
    "# find /data2/takeshun256/03_VAD_Ajusted -name \"transcript_original.txt\" -exec rm {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blacket removed and save kanji text\n",
    "\n",
    "# 処理対象のファイル名\n",
    "input_transcript_name = \"transcript_original\"\n",
    "\n",
    "# txt save path\n",
    "transcript_name = \"transcript_kanji\"\n",
    "\n",
    "# exp_dirの下にある書くフォルダについて処理\n",
    "input_transcript_dict = {}\n",
    "for audiobook_dir in exp_dir.iterdir():\n",
    "    input_file_path = audiobook_dir / f\"{input_transcript_name}.txt\"\n",
    "    assert input_file_path.exists(), f\"{input_file_path} does not exist.\"\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    input_transcript_dict[audiobook_dir.name] = lines\n",
    "\n",
    "pprint(input_transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "# preprocess\n",
    "transcript_dict = {}\n",
    "lambda_func = (\n",
    "    lambda line: line.split(\"\\t\")[0]\n",
    "    + \"\\t\"\n",
    "    + Preprocessor.remove_brackets_to_kanji(line.split(\"\\t\")[1])\n",
    ")\n",
    "for audiobook_name, transcript_lines in input_transcript_dict.items():\n",
    "    transcript_lines = [lambda_func(line) for line in transcript_lines]\n",
    "    transcript_dict[audiobook_name] = transcript_lines\n",
    "\n",
    "pprint(transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "\n",
    "# save\n",
    "# exp_dir / audiobook_name_fixed 下に {trascript_name}.txt として保存\n",
    "# 1行1文: \"{audiobook_name_fixed}_{chapter_idx_str} {chapter_info[\"sent\"]}\"\n",
    "\n",
    "for audiobook_name_fixed, transcript_lines in transcript_dict.items():\n",
    "    file_path = exp_dir / audiobook_name_fixed / f\"{transcript_name}.txt\"\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(transcript_lines))\n",
    "    print(f\"{file_path} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blacket removed and save kanji text\n",
    "\n",
    "# 処理対象のファイル名\n",
    "input_transcript_name = \"transcript_original\"\n",
    "\n",
    "# txt save path\n",
    "transcript_name = \"transcript_furigana\"\n",
    "\n",
    "# exp_dirの下にある書くフォルダについて処理\n",
    "input_transcript_dict = {}\n",
    "for audiobook_dir in exp_dir.iterdir():\n",
    "    input_file_path = audiobook_dir / f\"{input_transcript_name}.txt\"\n",
    "    assert input_file_path.exists(), f\"{input_file_path} does not exist.\"\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    input_transcript_dict[audiobook_dir.name] = lines\n",
    "\n",
    "pprint(input_transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "# preprocess\n",
    "transcript_dict = {}\n",
    "lambda_func = (\n",
    "    lambda line: line.split(\"\\t\")[0]\n",
    "    + \"\\t\"\n",
    "    + Preprocessor.remove_brackets_to_furigana(line.split(\"\\t\")[1])\n",
    ")\n",
    "for audiobook_name, transcript_lines in input_transcript_dict.items():\n",
    "    transcript_lines = [lambda_func(line) for line in transcript_lines]\n",
    "    transcript_dict[audiobook_name] = transcript_lines\n",
    "\n",
    "pprint(transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "\n",
    "# save\n",
    "# exp_dir / audiobook_name_fixed 下に {trascript_name}.txt として保存\n",
    "# 1行1文: \"{audiobook_name_fixed}_{chapter_idx_str} {chapter_info[\"sent\"]}\"\n",
    "\n",
    "for audiobook_name_fixed, transcript_lines in transcript_dict.items():\n",
    "    file_path = exp_dir / audiobook_name_fixed / f\"{transcript_name}.txt\"\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(transcript_lines))\n",
    "    print(f\"{file_path} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kanji text to wakati text\n",
    "\n",
    "# 処理対象のファイル名\n",
    "input_transcript_name = \"transcript_kanji\"\n",
    "\n",
    "# txt save path\n",
    "transcript_name = \"transcript_wakati\"\n",
    "\n",
    "# exp_dirの下にある書くフォルダについて処理\n",
    "input_transcript_dict = {}\n",
    "for audiobook_dir in exp_dir.iterdir():\n",
    "    input_file_path = audiobook_dir / f\"{input_transcript_name}.txt\"\n",
    "    assert input_file_path.exists(), f\"{input_file_path} does not exist.\"\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    input_transcript_dict[audiobook_dir.name] = lines\n",
    "\n",
    "pprint(input_transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "# preprocess\n",
    "transcript_dict = {}\n",
    "lambda_func = (\n",
    "    lambda line: line.split(\"\\t\")[0]\n",
    "    + \"\\t\"\n",
    "    + \" \".join(mecab_wakati_generator(line.split(\"\\t\")[1]))\n",
    ")\n",
    "for audiobook_name, transcript_lines in input_transcript_dict.items():\n",
    "    transcript_lines = [lambda_func(line) for line in transcript_lines]\n",
    "    transcript_dict[audiobook_name] = transcript_lines\n",
    "\n",
    "pprint(transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "\n",
    "# save\n",
    "# exp_dir / audiobook_name_fixed 下に {trascript_name}.txt として保存\n",
    "# 1行1文: \"{audiobook_name_fixed}_{chapter_idx_str} {chapter_info[\"sent\"]}\"\n",
    "\n",
    "for audiobook_name_fixed, transcript_lines in transcript_dict.items():\n",
    "    file_path = exp_dir / audiobook_name_fixed / f\"{transcript_name}.txt\"\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(transcript_lines))\n",
    "    print(f\"{file_path} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kanji text to morpheme texts\n",
    "\n",
    "# 処理対象のファイル名\n",
    "input_transcript_name = \"transcript_kanji\"\n",
    "\n",
    "# txt save path\n",
    "transcript_dir_name = \"transcript_morpheme\"\n",
    "\n",
    "# exp_dirの下にある書くフォルダについて処理\n",
    "input_transcript_dict = {}\n",
    "for audiobook_dir in exp_dir.iterdir():\n",
    "    input_file_path = audiobook_dir / f\"{input_transcript_name}.txt\"\n",
    "    assert input_file_path.exists(), f\"{input_file_path} does not exist.\"\n",
    "    with open(input_file_path, \"r\") as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    input_transcript_dict[audiobook_dir.name] = lines\n",
    "\n",
    "pprint(input_transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "# preprocess\n",
    "transcript_dict = {}\n",
    "\n",
    "\n",
    "def lambda_func(line):\n",
    "    line = line.split(\"\\t\")\n",
    "    detailed_list = list(mecab_detailed_generator(line[1]))  # namedtupleのリスト\n",
    "    transcirpt_line = pd.DataFrame(detailed_list)\n",
    "    return line[0], transcirpt_line\n",
    "\n",
    "\n",
    "for audiobook_name, transcript_lines in input_transcript_dict.items():\n",
    "    transcript_lines = [lambda_func(line) for line in transcript_lines]\n",
    "    transcript_dict[audiobook_name] = transcript_lines\n",
    "\n",
    "pprint(transcript_dict[\"AUDIOBOOK01\"][:3])\n",
    "\n",
    "\n",
    "# save\n",
    "# exp_dir / audiobook_name_fixed/ transcript_dir_name 下に {trascript_line[0]}.txt として保存\n",
    "\n",
    "for audiobook_name_fixed, transcript_lines in transcript_dict.items():\n",
    "    transcript_dir = exp_dir / audiobook_name_fixed / transcript_dir_name\n",
    "    transcript_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for transcript_line in transcript_lines:\n",
    "        file_path = transcript_dir / f\"{transcript_line[0]}.txt\"\n",
    "        transcript_line[1].to_csv(file_path, sep=\"\\t\", index=False, header=False)\n",
    "    print(f\"{transcript_dir} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopenjtalk_julius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
