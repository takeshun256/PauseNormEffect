{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アライメントを修正する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Julius によるアラインメントが特定のファイルで大きくズレる問題ですが，Julius の中で無音（振幅ゼロ）の区間を削除してからアラインメントをしていることが原因のようです．削除を行った結果の音声データに対するアラインメント結果をそのまま出力しているので，削除区間の長さの分だけどんどんズレていきます．\n",
    "自然な録音環境ではそのようなことは起きないという想定なのだと思いますが，J-MAC のデータは後処理か何かで無音区間が結構な割合で入っているデータがあるため問題になるようです．確か松永さんが以前同じ問題に遭遇したと言っていた気がします．おそらく音声ファイルの方で振幅ゼロのサンプルを取り除くとかで対処したのではないかと思いますが，竹下さんの場合は無音区間が削れてしまうのでそれだとダメです．\n",
    "ログに削除区間の情報が出ているので，それを元にアラインメント結果を修復するプログラムを作りました．添付します．\n",
    "使い方は以下の通り．\n",
    "単一の音声ファイルを処理するとき：\n",
    "``````\n",
    "# <log-file> : Julius のアラインメントツールから出る *.log ファイル\n",
    "# <wav-file> : 元の音声ファイル\n",
    "# <lab-file> : Julius のアラインメントツールから出る *.lab ファイル\n",
    "# <out-file> : 出力ファイル（lab 形式）\n",
    "``````\n",
    "``````\n",
    "$ fix_align.py <log-file> <wav-file> <lab-file> <out-file>\n",
    "```\n",
    "あるディレクトリ以下の *.log, *.wav, *.lab の3つ組み全てについて修正結果を *.lab2 というファイルに入れる：\n",
    "``````\n",
    "$ fix_align.py -d directory\n",
    "``````\n",
    "ログファイルに Warning: strip: sample から始まる行が出ているファイルは上記の問題が起きています．\n",
    "問題が起きてないファイルを処理したときはもとのと同じ結果が出るはずなので，全部 fix_align.py で処理しても大丈夫なはずです（エラーが起きなければ）．\n",
    "竹下さんの結果のディレクトリを見ると，また巨大なログファイルがいくつかできているようです．\n",
    "それは削除してから実行してください（でないとすごい時間がかかると思います）\n",
    "あと細かい点ですが，プログラムの中の restore_silence という関数で threshold という引数があり，デフォルトで 1600 サンプル（= 100ms）を指定してあります．これ以上の長さの無音区間は新しく音素 sp の区間を作るようになっています．長さがそれ未満の無音区間は対応する音素の区間に無音区間の長さを加えています．竹下さんのポーズ検出の都合に合わせて設定してください．元ファイルで促音のところが無音になっており，上記の処理の結果 sp が入ってしまうケースもあります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/analyze_jmac\")\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/vad_tool\")\n",
    "from audiobook_yaml_parser import extract_yaml_data\n",
    "from py_webrtcvad_test import getVadSection\n",
    "from vad_tool import VAD_Segmenter\n",
    "from audiobook_dataset_builder import AudiobookDatasetBuilder\n",
    "from audiobook_script_extractor import AudiobookScriptExtractor\n",
    "\n",
    "# python==3.11以上の場合はimportしない\n",
    "if sys.version_info < (3, 11):\n",
    "    from text_preprocessing_preprocessor import AudiobookScriptPreprocessor\n",
    "# from text_preprocessing import AudiobookScriptPreprocessor\n",
    "from julius_lab_analysis import JuliusLabAnalyzer\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.io import wavfile\n",
    "import scipy.io.wavfile\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import webrtcvad\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import struct\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "import soundfile as sf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_DIR = \"/data2/takeshun256/jmac_split_and_added_lab\"\n",
    "assert os.path.exists(LAB_DIR)\n",
    "\n",
    "# ディレクトリ内のlabファイルを取得\n",
    "lab_files = list(Path(LAB_DIR).glob(\"**/*.lab\"))\n",
    "\n",
    "print(\"labファイル数:\", len(list(lab_files)))\n",
    "print(\"labファイル例:\", list(lab_files)[0])\n",
    "\n",
    "# labファイルを読み込み\n",
    "lab_analyzer = JuliusLabAnalyzer(lab_files)\n",
    "# df_lab = lab_analyzer.load_lab_files()\n",
    "lab_analyzer.set_save_dir(\"/home/takeshun256/PausePrediction/data_pub/jmac\")\n",
    "# lab_analyzer.save_df_lab_to_pickle(df_lab_attached)\n",
    "df_lab_attached = lab_analyzer.load_df_lab_from_pickle()\n",
    "df_lab_attached = df_lab_attached[\n",
    "    [\n",
    "        \"start\",\n",
    "        \"end\",\n",
    "        \"phoneme\",\n",
    "        \"phoneme_idx\",\n",
    "        \"duration\",\n",
    "        \"lab_filepath\",\n",
    "        \"audiobook_id\",\n",
    "        \"audiobook_id_int\",\n",
    "        \"chapter_id\",\n",
    "        \"lab_idx\",\n",
    "        \"chapter_id_int\",\n",
    "        \"author\",\n",
    "        \"book\",\n",
    "        \"text\",\n",
    "        \"character\",\n",
    "        \"to_whom\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# wavファイルのパスを取得\n",
    "df_lab_attached[\"wav_filepath\"] = df_lab_attached[\"lab_filepath\"].apply(\n",
    "    lambda x: str(x).replace(\".lab\", \".wav\")\n",
    ")\n",
    "\n",
    "df_lab_attached.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルを1つ選択して修正実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声波形抽出\n",
    "# wav_path -> wav, sr\n",
    "def extract_waveform(audio_file_path, sr=24000):\n",
    "    waveform, sample_rate = librosa.load(audio_file_path, mono=True)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "\n",
    "# wav -> db変換\n",
    "def convert_db(waveform):\n",
    "    # TODO: これは何が違うのか？どちらが適切か？\n",
    "    # db = librosa.power_to_db(waveform)\n",
    "    db = librosa.amplitude_to_db(waveform)\n",
    "    return db\n",
    "\n",
    "\n",
    "# 連続区間抽出\n",
    "# db -> bool_list\n",
    "def run_length_encoding(arr, min_run_length=3):\n",
    "    diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "    run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "    run_lengths = np.diff(np.concatenate(([0], run_starts, [len(arr)])))  # 連続する範囲の長さを計算\n",
    "    result = np.repeat(run_lengths >= min_run_length, run_lengths)  # 連続する範囲をTrueに変換\n",
    "    return result\n",
    "\n",
    "\n",
    "# Pause区間抽出\n",
    "# db, db_threshold, time_threshold, sr -> pause_bool_list\n",
    "# 閾値を超えたらpauseとみなす\n",
    "def detect_pause_position(\n",
    "    db_sequence, db_threshold=-50, time_threshold=50 / 1000, sample_rate=24000\n",
    "):\n",
    "    \"\"\"dbと音声長の閾値からpauseの位置を判定する。\n",
    "\n",
    "    Args:\n",
    "        db_sequence (np.array): 音声波形をdbに変換した配列\n",
    "        db_threshold (float): 無音区間とするdbの閾値\n",
    "        time_threshold (float): 無音区間が連続した時にpauseとみなす時間の閾値\n",
    "\n",
    "    Returns:\n",
    "        pause_positions (list): pauseの位置のリスト\n",
    "    \"\"\"\n",
    "    under_db_threshold = db_sequence < db_threshold\n",
    "\n",
    "    # 連続区間を抽出\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    is_continuous = run_length_encoding(under_db_threshold, sample_threshold)\n",
    "\n",
    "    # pauseの位置を抽出\n",
    "    pause_positions = under_db_threshold & is_continuous\n",
    "\n",
    "    return pause_positions\n",
    "\n",
    "\n",
    "# pause区間付きの波形の可視化\n",
    "def plot_db_with_pause(db, sr, db_threshold, time_threshold, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax.plot(x, db, label=\"db\")\n",
    "\n",
    "    # dbの閾値を引く\n",
    "    ax.axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    plt.fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 波形の可視化\n",
    "def plot_wavform(waveform, sr, xlim=None):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    x = np.arange(len(waveform)) / sr\n",
    "    ax.plot(x, waveform, label=\"waveform\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 音声再生ボタン生成\n",
    "def play_button(waveform, sr):\n",
    "    display(Audio(waveform, rate=sr, autoplay=True))\n",
    "\n",
    "\n",
    "# アライメントの抽出\n",
    "# lab_path -> df_lab\n",
    "def read_lab(lab_path):\n",
    "    \"\"\"labファイルを読み込む\"\"\"\n",
    "    # labファイルがない場合\n",
    "    if not Path(lab_path).exists():\n",
    "        print(f\"{lab_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # labファイルがある場合\n",
    "    df_lab = []\n",
    "    with open(lab_path, \"r\") as f:\n",
    "        for phoneme_idx, line in enumerate(f):\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            duration = float(end) - float(start)\n",
    "            df_lab.append(\n",
    "                {\n",
    "                    \"start\": float(start),\n",
    "                    \"end\": float(end),\n",
    "                    \"phoneme\": phoneme,\n",
    "                    \"phoneme_idx\": phoneme_idx,\n",
    "                    \"duration\": duration,\n",
    "                }\n",
    "            )\n",
    "    df_lab = pd.DataFrame(df_lab)\n",
    "    return df_lab\n",
    "\n",
    "\n",
    "# アライメントの可視化\n",
    "def plot_phoneme_alignment(df, xlim=None):\n",
    "    \"\"\"Labファイルから音素のアライメントをプロットする\n",
    "\n",
    "    Args:\n",
    "        lab_path (_type_): Labファイルのパス\n",
    "    \"\"\"\n",
    "    # df = read_lab(lab_path)\n",
    "    # display(df[-10:])\n",
    "\n",
    "    # 描画\n",
    "    fig, ax = plt.subplots(figsize=(20, 2))\n",
    "    for start, end, label in df.values:\n",
    "        ax.axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax.text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4, 2]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[2].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[2].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax[2].set_xlim(xlim)\n",
    "    ax[2].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "# 並べて可視化する。\n",
    "def plot_all2(\n",
    "    df_temp, wav_path, sample_rate=24000, db_threshold=-50, time_threshold=50 / 1000\n",
    "):\n",
    "    \"\"\"wavファイル、db、アライメントを並べて可視化する\"\"\"\n",
    "    wav, sr = extract_waveform(wav_path, sr=sample_rate)\n",
    "    db = convert_db(wav)\n",
    "    xlim = (0, len(wav) / sr)\n",
    "\n",
    "    print(wav_path)\n",
    "    print(\"wav.shape:\", wav.shape)\n",
    "    print(\"seconds:\", len(wav) / sr)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        2, 1, figsize=(20, 10), gridspec_kw={\"height_ratios\": [4, 4]}\n",
    "    )\n",
    "    # print(\"spk_id:\", spk_id)\n",
    "    # print(\"wav_id:\", wav_id)\n",
    "    # print(\"xlim:\", xlim)\n",
    "    # print(\"transcript:\", transcript)\n",
    "    # print(\"start ploting...\")\n",
    "\n",
    "    # 波形の可視化\n",
    "    x = np.arange(len(wav)) / sr\n",
    "    ax[0].plot(x, wav, label=\"waveform\")\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # dbの可視化\n",
    "    x = np.arange(len(db)) / sr\n",
    "    ax[1].plot(x, db, label=\"db\")\n",
    "    # dbの閾値を引く\n",
    "    ax[1].axhline(\n",
    "        y=db_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label=\"db_threshold\",\n",
    "    )\n",
    "    # pauseの領域を塗りつぶす\n",
    "    pause_position = detect_pause_position(db, db_threshold, time_threshold, sr)\n",
    "    ax[1].fill_between(x, -80, 0, where=pause_position, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1].set_xlim(xlim)\n",
    "    ax[1].legend()\n",
    "\n",
    "    # アライメントの可視化\n",
    "    # 描画\n",
    "    for start, end, label in df_temp.values:\n",
    "        ax[0].axvline(end, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].axvline(start, color=\"gray\", linestyle=\"--\")\n",
    "        ax[0].text((start + end) / 2, 0.5, label, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    # ax.set_yticks([])\n",
    "    ax[0].set_xlim(xlim)\n",
    "    ax[0].set_xlabel(\"Time (seconds)\")\n",
    "    # ax[2].tight_layout()\n",
    "    ax[0].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    play_button(wav, sr)\n",
    "\n",
    "\n",
    "def classfy_pause(\n",
    "    db_sequence, lab_path, sample_rate=24000, db_threshold=-50, time_threshold=0.05\n",
    "):\n",
    "    \"\"\"ポーズを分類する\n",
    "\n",
    "    Args:\n",
    "        df_jvs (_type_): _description_\n",
    "    \"\"\"\n",
    "    # db_threshold = -50\n",
    "    # time_threshold = 0.05\n",
    "    # sample_rate = 24000\n",
    "\n",
    "    # db_sequence = df_jvs.iloc[0]['db_sequence']\n",
    "    pause_position = detect_pause_position(\n",
    "        db_sequence, db_threshold, time_threshold, sample_rate\n",
    "    )\n",
    "\n",
    "    def run_length_encoding_range(arr, min_run_length=3):\n",
    "        \"\"\"\n",
    "        Run-Length Encoding (RLE)を実行して連続している部分をTrueとしたブール配列を返す関数\n",
    "\n",
    "        Parameters:\n",
    "            arr (numpy.ndarray): 連続している部分を判定したい1次元のNumPy配列\n",
    "            min_run_length (int): 連続していると判定する最小の長さ（デフォルトは3）\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: 連続している部分がTrueとなったブール配列\n",
    "            list: 連続している部分の始点と終点のリスト [(start1, end1), (start2, end2), ...]\n",
    "        \"\"\"\n",
    "        diff = np.diff(arr)  # 隣接要素の差分を計算\n",
    "        run_starts = np.where(diff != 0)[0] + 1  # 差分が0でないインデックスを取得し、連続する範囲の開始位置を得る\n",
    "\n",
    "        starts = np.concatenate(([0], run_starts))\n",
    "        ends = np.concatenate((run_starts, [len(arr)]))\n",
    "        lengths = ends - starts\n",
    "        ranges = list(zip(starts, ends, lengths))\n",
    "\n",
    "        # min_run_length以下の範囲を削除, Trueが連続しているもののみを取り出す\n",
    "        ranges = [r for r in ranges if (r[2] >= min_run_length and arr[r[0]])]\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    sample_threshold = int(time_threshold * sample_rate)\n",
    "    pause_ranges = run_length_encoding_range(pause_position, sample_threshold)\n",
    "\n",
    "    # print(pause_ranges)\n",
    "\n",
    "    # df_lab = read_lab(df_jvs.iloc[0]['lab_path'])\n",
    "    df_lab = read_lab(lab_path)\n",
    "\n",
    "    ans = []\n",
    "    for pause_range in pause_ranges:\n",
    "        # df_labのstartもしくは、endが、start, endの範囲内にあるかどうか\n",
    "        pause_start = pause_range[0]\n",
    "        pause_end = pause_range[1]\n",
    "        phoneme_start = df_lab[\"start\"].values * sample_rate\n",
    "        phoneme_end = df_lab[\"end\"].values * sample_rate\n",
    "        is_start_include = (pause_start <= phoneme_start) & (phoneme_start <= pause_end)\n",
    "        is_end_include = (pause_start <= phoneme_end) & (phoneme_end <= pause_end)\n",
    "\n",
    "        include_phonemes = df_lab[is_start_include | is_end_include][\"phoneme\"].values\n",
    "        print(include_phonemes)\n",
    "        if \"silE\" in include_phonemes:\n",
    "            pause_type = \"silE\"\n",
    "        elif \"silB\" in include_phonemes:\n",
    "            pause_type = \"silB\"\n",
    "        elif \"sil\" in include_phonemes:\n",
    "            pause_type = \"sil\"\n",
    "        elif \"pau\" in include_phonemes:\n",
    "            pause_type = \"pau\"\n",
    "        elif \"sp\" in include_phonemes:\n",
    "            pause_type = \"sp\"\n",
    "        else:\n",
    "            pause_type = \"RP\"\n",
    "\n",
    "        ans.append([pause_range[0], pause_range[1], pause_range[2], pause_type])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もう1つのwavファイル\n",
    "# 波形の上にpauseの位置を可視化する\n",
    "\n",
    "# ----setting----\n",
    "# 閾値の設定\n",
    "db_threshold = -50\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# sample_rate = 16000\n",
    "# ---------------\n",
    "\n",
    "wav_filepath = df_lab_attached.iloc[999][\"wav_filepath\"]\n",
    "wav_filepath = (\n",
    "    \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.wav\"\n",
    ")\n",
    "\n",
    "df_temp = df_lab_attached[df_lab_attached[\"wav_filepath\"] == wav_filepath][\n",
    "    [\"start\", \"end\", \"phoneme\"]\n",
    "]\n",
    "print(df_temp)\n",
    "print(df_lab_attached[df_lab_attached[\"wav_filepath\"] == wav_filepath][\"text\"])\n",
    "\n",
    "plot_all2(\n",
    "    df_temp,\n",
    "    wav_filepath,\n",
    "    sample_rate=sample_rate,\n",
    "    db_threshold=db_threshold,\n",
    "    time_threshold=time_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプル：/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.wav に修正を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.log\" | grep \"Warning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/home/takeshun256/PausePrediction/src/julius_segment/fix_align.py \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.log\" \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.wav\" \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.lab\" \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.lab2\"\n",
    "\n",
    "# !./fix_align_all.sh > \"/home/takeshun256/PausePrediction/logs/fix_align_all_2023-11-01_11:21.log\" 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.lab2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修正後の結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もう1つのwavファイル\n",
    "# 波形の上にpauseの位置を可視化する\n",
    "\n",
    "# ----setting----\n",
    "# 閾値の設定\n",
    "db_threshold = -50\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# sample_rate = 16000\n",
    "# ---------------\n",
    "\n",
    "wav_filepath = (\n",
    "    \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.wav\"\n",
    ")\n",
    "lab_filepath = (\n",
    "    \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.lab2\"\n",
    ")\n",
    "txt_filepath = (\n",
    "    \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_72/audiobook_72_079.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "df_temp = read_lab(lab_filepath)[[\"start\", \"end\", \"phoneme\"]]\n",
    "print(df_temp)\n",
    "with open(txt_filepath, \"r\") as f:\n",
    "    transcript = f.read()\n",
    "print(transcript)\n",
    "\n",
    "plot_all2(\n",
    "    df_temp,\n",
    "    wav_filepath,\n",
    "    sample_rate=sample_rate,\n",
    "    db_threshold=db_threshold,\n",
    "    time_threshold=time_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修正中にエラーが出ているものを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 確認方法\n",
    "    - cat \"/data2/takeshun256/jmac_split_and_added_lab/audiobook_33/audiobook_33_110.log\" | grep War\n",
    "- 結果\n",
    "    - Warning: strip: sample 77378-77398 has zero value, stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もう1つのwavファイル\n",
    "# 波形の上にpauseの位置を可視化する\n",
    "\n",
    "# ----setting----\n",
    "# 閾値の設定\n",
    "db_threshold = -50\n",
    "# time_threshold = 50 / 1000 # 50ms\n",
    "time_threshold = 200 / 1000  # 200ms\n",
    "sample_rate = 24000\n",
    "# sample_rate = 16000\n",
    "# ---------------\n",
    "\n",
    "audiobook_id = 33\n",
    "sample_id = 110\n",
    "\n",
    "wav_filepath = f\"/data2/takeshun256/jmac_split_and_added_lab/audiobook_{audiobook_id}/audiobook_{audiobook_id}_{sample_id:03}.wav\"\n",
    "lab_filepath = f\"/data2/takeshun256/jmac_split_and_added_lab/audiobook_{audiobook_id}/audiobook_{audiobook_id}_{sample_id:03}.lab\"\n",
    "txt_filepath = f\"/data2/takeshun256/jmac_split_and_added_lab/audiobook_{audiobook_id}/audiobook_{audiobook_id}_{sample_id:03}.txt\"\n",
    "\n",
    "\n",
    "df_temp = read_lab(lab_filepath)[[\"start\", \"end\", \"phoneme\"]]\n",
    "print(df_temp)\n",
    "with open(txt_filepath, \"r\") as f:\n",
    "    transcript = f.read()\n",
    "print(transcript)\n",
    "\n",
    "plot_all2(\n",
    "    df_temp,\n",
    "    wav_filepath,\n",
    "    sample_rate=sample_rate,\n",
    "    db_threshold=db_threshold,\n",
    "    time_threshold=time_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvs_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
