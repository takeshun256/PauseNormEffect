{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train.pyで現在行っているデータの前処理を、先にデータとして作成しておく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z_normalize_pause_length.ipynbのノートブックの続き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "# import own library\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "audiobook_yaml_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert audiobook_yaml_path.exists()\n",
    "\n",
    "# audio book data\n",
    "with open(audiobook_yaml_path, \"rb\") as f:\n",
    "    audiobook_dict = yaml.safe_load(f)\n",
    "\n",
    "# データの一覧\n",
    "pause_time_threshold_mss = [80, 100]\n",
    "preprocess_types = [\"none\", \"all\", \"audiobook\", \"narrative\", \"audiobook_narrative\", \"speaker\", \"book\"]\n",
    "num_labels = [1, 2]\n",
    "\n",
    "# 80ms\n",
    "df_train_80ms = pd.read_pickle(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon_80ms_normalized.pkl\")\n",
    "\n",
    "# 100ms\n",
    "df_train_100ms = pd.read_pickle(exp_dir / \"bert_traindata_pause_position_with_length_wo_sokuon_100ms_normalized.pkl\")\n",
    "\n",
    "\n",
    "# output dir\n",
    "output_dir = exp_dir / \"data_bert\"\n",
    "assert output_dir.exists()\n",
    "\n",
    "# それぞれのディレクトリを作成\n",
    "for pause_time_threshold_ms in pause_time_threshold_mss:\n",
    "    for preprocess_type in preprocess_types:\n",
    "        output_dir_each = output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type\n",
    "        output_dir_each.mkdir(parents=True, exist_ok=True)\n",
    "        print(output_dir_each)\n",
    "\n",
    "\n",
    "print(\"audio book data\")\n",
    "print(len(audiobook_dict))\n",
    "pprint(audiobook_dict[list(audiobook_dict.keys())[0]])\n",
    "print(\"80ms\")\n",
    "print(df_train_80ms.shape)\n",
    "print(\"100ms\")\n",
    "print(df_train_100ms.shape)\n",
    "display(df_train_80ms.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_80ms.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_80ms), len(df_train_100ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNが1つでも含まれる行数を数える\n",
    "print(\"80ms\")\n",
    "print(df_train_80ms.isnull().sum().sum())\n",
    "print(\"100ms\")\n",
    "print(df_train_100ms.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80msには存在し、100msには存在しないデータを抽出\n",
    "df_unique_to_80ms = df_train_80ms[~df_train_80ms.set_index([\"audiobook_name\", \"chapter_name\"]).index.isin(df_train_100ms.set_index([\"audiobook_name\", \"chapter_name\"]).index)]\n",
    "display(df_unique_to_80ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練・テストデータのトータルの形態素数と認定したポーズ数 を 80ms, 100ms それぞれで1つの図にまとめる\n",
    "\n",
    "data_type = [[\"train\", \"valid\"], \"test\"]\n",
    "\n",
    "# リスト内でPauseの数を数える\n",
    "def count_pause(x):\n",
    "    c = 0\n",
    "    for i in x:\n",
    "        if \"[PAUSE\" in i:\n",
    "            c += 1\n",
    "    return c\n",
    "def count_not_pause(x):\n",
    "    c = 0\n",
    "    for i in x:\n",
    "        if \"[NO_PAUSE\" in i:\n",
    "            c += 1\n",
    "    return c\n",
    "def count_mora(x):\n",
    "    c = 0\n",
    "    for i in x:\n",
    "        if not (\"[NO_PAUSE\" in i or \"[PAUSE\" in i):\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "df_train_80ms[\"total_mora\"] = df_train_80ms[\"morp_pause_clip_no_pause\"].apply(count_mora)\n",
    "df_train_80ms[\"total_pause\"] = df_train_80ms[\"morp_pause_clip_no_pause\"].apply(count_pause)\n",
    "df_train_80ms[\"total_no_pause\"] = df_train_80ms[\"morp_pause_clip_no_pause\"].apply(count_not_pause)\n",
    "df_train_100ms[\"total_mora\"] = df_train_100ms[\"morp_pause_clip_no_pause\"].apply(count_mora)\n",
    "df_train_100ms[\"total_pause\"] = df_train_100ms[\"morp_pause_clip_no_pause\"].apply(count_pause)\n",
    "df_train_100ms[\"total_no_pause\"] = df_train_100ms[\"morp_pause_clip_no_pause\"].apply(count_not_pause)\n",
    "\n",
    "# check total_mora + total_pause + total_no_pause = len(morp_pause_clip_no_pause)\n",
    "import numpy as np\n",
    "\n",
    "sumlen_80ms = df_train_80ms[\"total_mora\"] + df_train_80ms[\"total_pause\"] + df_train_80ms[\"total_no_pause\"]\n",
    "sumlen_80ms = sumlen_80ms.values\n",
    "sumlen_100ms = df_train_100ms[\"total_mora\"] + df_train_100ms[\"total_pause\"] + df_train_100ms[\"total_no_pause\"]\n",
    "sumlen_100ms = sumlen_100ms.values\n",
    "\n",
    "# 80msのデータの検証\n",
    "expected_len_80ms = df_train_80ms[\"morp_pause_clip_no_pause\"].apply(len).values\n",
    "actual_len_80ms = (df_train_80ms[\"total_mora\"] + df_train_80ms[\"total_pause\"] + df_train_80ms[\"total_no_pause\"]).values\n",
    "assert (actual_len_80ms == expected_len_80ms).all(), f\"80ms: {actual_len_80ms} != {expected_len_80ms}\"\n",
    "\n",
    "# 100msのデータの検証\n",
    "expected_len_100ms = df_train_100ms[\"morp_pause_clip_no_pause\"].apply(len).values\n",
    "actual_len_100ms = (df_train_100ms[\"total_mora\"] + df_train_100ms[\"total_pause\"] + df_train_100ms[\"total_no_pause\"]).values\n",
    "assert (actual_len_100ms == expected_len_100ms).all(), f\"100ms: {actual_len_100ms} != {expected_len_100ms}\"\n",
    "\n",
    "\n",
    "# train_test (train_val_testでtrainはtrain, valはtrain, testはtest)\n",
    "df_train_80ms[\"data_type\"] = df_train_80ms[\"train_val_test\"].replace({\"train\": \"train\", \"val\": \"train\", \"test\": \"test\"})\n",
    "df_train_100ms[\"data_type\"] = df_train_100ms[\"train_val_test\"].replace({\"train\": \"train\", \"val\": \"train\", \"test\": \"test\"})\n",
    "\n",
    "print(df_train_80ms[\"data_type\"].value_counts())\n",
    "\n",
    "# 80ms, 100msそれぞれで、train, testでのtotal_mora, total_pause, total_no_pauseの合計を出す\n",
    "df_train_80ms_total = df_train_80ms.groupby(\"data_type\")[[\"total_mora\", \"total_pause\", \"total_no_pause\"]].sum().reset_index()\n",
    "df_train_100ms_total = df_train_100ms.groupby(\"data_type\")[[\"total_mora\", \"total_pause\", \"total_no_pause\"]].sum().reset_index()\n",
    "\n",
    "# 80msと100msのデータをsubplotsで表示し、total_moraとtotal_pauseのみをプロット\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# 80msのデータをプロット\n",
    "df_train_80ms_total.plot(kind=\"bar\", x=\"data_type\", y=[\"total_mora\", \"total_pause\"], ax=axes[0])\n",
    "axes[0].set_xlabel(\"Number of mora/pause\")\n",
    "axes[0].set_ylabel(\"Data type\")\n",
    "axes[0].set_title(\"80ms: Number of mora and pause in train and test data\")\n",
    "\n",
    "# 100msのデータをプロット\n",
    "df_train_100ms_total.plot(kind=\"bar\", x=\"data_type\", y=[\"total_mora\", \"total_pause\"], ax=axes[1])\n",
    "axes[1].set_xlabel(\"Number of mora/pause\")\n",
    "axes[1].set_ylabel(\"Data type\")\n",
    "axes[1].set_title(\"100ms: Number of mora and pause in train and test data\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train_80ms_total)\n",
    "display(df_train_100ms_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df_train_80ms[\"morp_pause_clip_no_pause\"].loc[0]\n",
    "print(aa)\n",
    "print(count_mora(aa))\n",
    "print(count_pause(aa))\n",
    "print(count_not_pause(aa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユニーク数をカウント\n",
    "print(\"80ms\")\n",
    "print(\"audiobook_name のユニーク数:\", df_train_80ms[\"audiobook_name\"].nunique())\n",
    "print(\"is_narrative のユニーク数:\", df_train_80ms[\"is_narrative\"].nunique())\n",
    "print(\"speaker のユニーク数:\", df_train_80ms[\"speaker\"].nunique())\n",
    "print(\"book のユニーク数:\", df_train_80ms[\"book\"].nunique())\n",
    "\n",
    "print(\"100ms\")\n",
    "print(df_train_100ms[\"audiobook_name\"].nunique())\n",
    "print(df_train_100ms[\"is_narrative\"].nunique())\n",
    "print(df_train_100ms[\"speaker\"].nunique())\n",
    "print(df_train_100ms[\"book\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのカテゴリに含まれる数の最大値と最小値を確認(3未満だと分割した際に未知データになるため)\n",
    "print(f\"audiobook_count: {df_train_80ms['audiobook_name'].value_counts().max()}〜{df_train_80ms['audiobook_name'].value_counts().min()}\")\n",
    "print(f\"narrative_count: {df_train_80ms['is_narrative'].value_counts().max()}〜{df_train_80ms['is_narrative'].value_counts().min()}\")\n",
    "print(f\"speaker_count: {df_train_80ms['speaker'].value_counts().max()}〜{df_train_80ms['speaker'].value_counts().min()}\")\n",
    "print(f\"book_count: {df_train_80ms['book'].value_counts().max()}〜{df_train_80ms['book'].value_counts().min()}\")\n",
    "# audiobook x is_narrative の組み合わせを作成\n",
    "df_train_80ms[\"audiobook_is_narrative\"] = df_train_80ms[\"audiobook_name\"] + \"_\" + df_train_80ms[\"is_narrative\"].astype(str)\n",
    "print(df_train_80ms[\"audiobook_is_narrative\"].nunique())\n",
    "print(f\"audiobook_is_narrative_count: {df_train_80ms['audiobook_is_narrative'].value_counts().max()}〜{df_train_80ms['audiobook_is_narrative'].value_counts().min()}\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# スピーカーの可視化\n",
    "df_train_80ms[\"speaker\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[0, 0], title=\"speaker\")\n",
    "\n",
    "# オーディオブック名の可視化\n",
    "df_train_80ms[\"audiobook_name\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[0, 1], title=\"audiobook_name\")\n",
    "\n",
    "# ナラティブの可視化\n",
    "df_train_80ms[\"is_narrative\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[1, 0], title=\"is_narrative\")\n",
    "\n",
    "# 本のタイトルの可視化\n",
    "df_train_80ms[\"book\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[1, 1], title=\"book\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, pause_time_threshold_ms, preprocess_type, num_labels):\n",
    "    \"\"\"\n",
    "    データフレームの前処理を行う関数\n",
    "\n",
    "    :param df: 前処理を行うデータフレーム\n",
    "    :param pause_time_threshold_ms: ポーズ時間の閾値（ミリ秒）\n",
    "    :param preprocess_type: 前処理のタイプ\n",
    "    :param num_labels: ラベルの数（1: 回帰, 2: 2値分類, 3: 多値分類）\n",
    "    :return: 前処理後のデータフレーム\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    # 列名を決定する辞書\n",
    "    column_dict = {\n",
    "        \"none\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_none\",\n",
    "        \"all\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_all\",\n",
    "        \"narrative\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_narrative\",\n",
    "        \"audiobook\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_audiobook\",\n",
    "        \"audiobook_narrative\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_audiobook_narrative\",\n",
    "        \"speaker\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_speaker\",\n",
    "        \"book\": f\"morp_pause_clip_no_pause_normalized_{pause_time_threshold_ms}ms_book\",\n",
    "    }\n",
    "    column_name = column_dict[preprocess_type]\n",
    "    print(f\"Using {column_name} ...\")\n",
    "\n",
    "    # テキストとラベルを抽出\n",
    "    for a in df[column_name].values:\n",
    "        if len(a) == 0:\n",
    "            texts.append([])\n",
    "            labels.append([])\n",
    "            continue\n",
    "        a = a[1:]  # 最初の要素は、[PAUSE] or [NO_PAUSE] なので削除\n",
    "        a[-1] = \"[NO_PAUSE]\"  # 最後の要素は、文間ポーズなので、[NO_PAUSE] にする\n",
    "        texts.append(a[::2])\n",
    "        labels.append(a[1::2])\n",
    "        assert len(texts[-1]) == len(labels[-1]), f\"{len(texts[-1])}, {texts[-1]} != {len(labels[-1])}, {labels[-1]}\"\n",
    "\n",
    "    df[\"texts\"] = texts\n",
    "    df[\"labels_str\"] = labels\n",
    "\n",
    "    # ラベルの処理\n",
    "    if num_labels == 1:\n",
    "        # 回帰タスク\n",
    "        # [PAUSE 0.5] などの文字列から、0.5 の部分を取得, [NO_PAUSE] は 0 にする。[PAUSE -0.5] などもあり得るので注意\n",
    "        # df[\"labels\"] = df[\"labels_str\"].apply(\n",
    "        #     lambda x: [float(re.findall(r\"\\d+\\.\\d+\", a)[0]) if a.startswith(\"[PAUSE\") else 0 for a in x]\n",
    "        # )\n",
    "        def lam(x):\n",
    "            out = []\n",
    "            for a in x:\n",
    "                if a.startswith(\"[PAUSE\"):\n",
    "                    out.append(float(a.split()[1][:-1]))\n",
    "                else:\n",
    "                    out.append(0)\n",
    "            return out\n",
    "\n",
    "        df[\"labels\"] = df[\"labels_str\"].apply(lam)\n",
    "\n",
    "    elif num_labels == 2:\n",
    "        # 2値分類タスク\n",
    "        # [PAUSE 0.5] などの文字列は 1 に、[NO_PAUSE] は 0 にする\n",
    "        df[\"labels\"] = df[\"labels_str\"].apply(lambda x: [1 if a.startswith(\"[PAUSE\") else 0 for a in x])\n",
    "    else:\n",
    "        raise ValueError(\"num_labels must be 1, 2\")\n",
    "\n",
    "    # 空のテキストやラベルを持つ行を削除\n",
    "    print(f\"削除される行数: {len(df) - len(df[df['texts'].apply(lambda x: len(x) > 0)])}\")\n",
    "    df = df[df[\"texts\"].apply(lambda x: len(x) > 0)]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # 埋め込み用のIDを作成\n",
    "    df[\"id_audiobook\"] = df[\"audiobook_name\"].astype(\"category\").cat.codes\n",
    "    df[\"id_speaker\"] = df[\"speaker\"].astype(\"category\").cat.codes\n",
    "    df[\"id_book\"] = df[\"book\"].astype(\"category\").cat.codes\n",
    "    df[\"id_narrative\"] = df[\"is_narrative\"].astype(\"category\").cat.codes\n",
    "    df[\"id_none\"] = 0\n",
    "    df[\"id_all\"] = 0\n",
    "    # audiobook x is_narrative の組み合わせを作成\n",
    "    df[\"audiobook_narrative\"] = df[\"audiobook_name\"] + \"_\" + df[\"is_narrative\"].astype(str)\n",
    "    df[\"id_audiobook_narrative\"] = df[\"audiobook_narrative\"].astype(\"category\").cat.codes\n",
    "    \n",
    "    # ID変換時の対応表を保存\n",
    "    id_audiobook_dict = dict(enumerate(df[\"audiobook_name\"].astype(\"category\").cat.categories))\n",
    "    id_speaker_dict = dict(enumerate(df[\"speaker\"].astype(\"category\").cat.categories))\n",
    "    id_book_dict = dict(enumerate(df[\"book\"].astype(\"category\").cat.categories))\n",
    "    id_narrative_dict = dict(enumerate(df[\"is_narrative\"].astype(\"category\").cat.categories))\n",
    "    id_audiobook_narrative_dict = dict(enumerate(df[\"audiobook_narrative\"].astype(\"category\").cat.categories))\n",
    "    id_dict = {\"audiobook\": id_audiobook_dict, \"speaker\": id_speaker_dict, \"book\": id_book_dict, \"narrative\": id_narrative_dict, \"audiobook_narrative\": id_audiobook_narrative_dict}\n",
    "    # カレントディレクトリにcsvで保存\n",
    "    for key, value in id_dict.items():\n",
    "        pd.DataFrame(value.items(), columns=[\"id\", key]).to_csv(f\"id_dict/in_sentence/id_{key}.csv\", index=False)\n",
    "    \n",
    "    # 使用する列のみを抽出\n",
    "    # if preprocess_type == \"none\":\n",
    "    #     df = df[[\"audiobook_name\", \"chapter_name\", \"texts\", \"labels\", \"labels_str\", \"id_audiobook\", \"id_speaker\", \"id_book\", \"id_narrative\", \"id_audiobook_narrative\", \"id_none\", \"id_all\", \"means\", \"vars\"]]\n",
    "    #     df[\"means\"] = 0\n",
    "    #     df[\"vars\"] = 1\n",
    "    # else:\n",
    "    # noneも統合されたのでそれを確認\n",
    "    if preprocess_type == \"none\":\n",
    "        assert df[\"mean_none\"].isnull().sum() == 0\n",
    "        assert df[\"var_none\"].isnull().sum() == 0\n",
    "        # mean=0, var=1 にする\n",
    "        assert df[\"mean_none\"].mean() == 0\n",
    "        assert df[\"var_none\"].mean() == 1\n",
    "    \n",
    "    cols = [\"audiobook_name\", \"chapter_name\", \"is_narrative\", \"speaker\", \"book\", \"texts\", \"labels\", \"labels_str\", \"id_audiobook\", \"id_speaker\", \"id_book\", \"id_narrative\", \"id_audiobook_narrative\", \"id_none\", \"id_all\", f\"mean_{preprocess_type}\", f\"var_{preprocess_type}\", \"train_val_test\"]\n",
    "    df = df[cols]\n",
    "    df = df.rename(columns={f\"mean_{preprocess_type}\": \"means\", f\"var_{preprocess_type}\": \"vars\"})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_80ms_all_1label = preprocess_data(df_train_80ms, 80, \"none\", 1)\n",
    "display(df_train_80ms_all_1label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_80ms_all_1label = preprocess_data(df_train_80ms, 80, \"narrative\", 2)\n",
    "display(df_train_80ms_all_1label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pause_time_threshold_ms in pause_time_threshold_mss:\n",
    "    for preprocess_type in preprocess_types:\n",
    "        for num_label in num_labels:\n",
    "            print(f\"pause_time_threshold_ms: {pause_time_threshold_ms}, preprocess_type: {preprocess_type}, num_label: {num_label}\")\n",
    "            if pause_time_threshold_ms == 80:\n",
    "                df_train = df_train_80ms\n",
    "            elif pause_time_threshold_ms == 100:\n",
    "                df_train = df_train_100ms\n",
    "            else:\n",
    "                raise ValueError(\"pause_time_threshold_ms must be 80 or 100\")\n",
    "            df_train_preprocessed = preprocess_data(df_train, pause_time_threshold_ms, preprocess_type, num_label)\n",
    "            df_train_preprocessed.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_{num_label}label.pkl\")\n",
    "            # 分割\n",
    "            # train_val_test列で分割\n",
    "            train_df = df_train_preprocessed[df_train_preprocessed[\"train_val_test\"] == \"train\"]\n",
    "            val_df = df_train_preprocessed[df_train_preprocessed[\"train_val_test\"] == \"val\"]\n",
    "            test_df = df_train_preprocessed[df_train_preprocessed[\"train_val_test\"] == \"test\"]\n",
    "            # test_size = 0.2\n",
    "            # val_size = 0.25\n",
    "            # train_val_df, test_df = train_test_split(df_train_preprocessed, test_size=test_size, random_state=42)\n",
    "            # train_df, val_df = train_test_split(train_val_df, test_size=val_size, random_state=42)\n",
    "            train_df.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_{num_label}label_train.pkl\")\n",
    "            val_df.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_{num_label}label_val.pkl\")\n",
    "            test_df.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_{num_label}label_test.pkl\")\n",
    "\n",
    "            print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvs_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
