{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文間ポーズの学習データを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- オーディオブック内の文章について、文章から、文章の間のポーズの長さを学習する\n",
    "\n",
    "- BERTのモデルを使って、文章の間のポーズの長さを予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction\")\n",
    "\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/analyze_jmac\")\n",
    "sys.path.append(\"/home/takeshun256/PausePrediction/src/vad_tool\")\n",
    "from audiobook_yaml_parser import extract_yaml_data\n",
    "from py_webrtcvad_test import getVadSection\n",
    "from vad_tool import VAD_Segmenter\n",
    "from audiobook_dataset_builder import AudiobookDatasetBuilder\n",
    "from audiobook_script_extractor import AudiobookScriptExtractor\n",
    "\n",
    "\n",
    "from julius_lab_analysis import JuliusLabAnalyzer\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.io import wavfile\n",
    "import scipy.io.wavfile\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import webrtcvad\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import struct\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config import DATA_DIR, DATA_TAKESHUN256_DIR, SRC_DIR, DATA_IN_ROOT_DIR\n",
    "\n",
    "# define path\n",
    "corpus_name = \"jmac\"\n",
    "exp_name = \"03_VAD_Adjusted\"\n",
    "\n",
    "exp_dir = Path(DATA_TAKESHUN256_DIR) / corpus_name / exp_name\n",
    "yaml_file_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "\n",
    "assert exp_dir.exists()\n",
    "assert yaml_file_path.exists()\n",
    "\n",
    "\n",
    "audiobook_yaml_path = Path(DATA_IN_ROOT_DIR) / corpus_name / \"text_audio_dict_new.yaml\"\n",
    "speaker_csv_path = \"/home/takeshun256/PausePrediction/data_pub/jmac/bookdata-speaker.csv\"\n",
    "speaker_gender_csv_path =  \"/home/takeshun256/PausePrediction/data_pub/jmac/speaker_gender.csv\"\n",
    "# audio book data\n",
    "with open(audiobook_yaml_path, \"rb\") as f:\n",
    "    audiobook_dict = yaml.safe_load(f)\n",
    "\n",
    "# speaker data\n",
    "df_speaker = pd.read_csv(speaker_csv_path)\n",
    "df_gender = pd.read_csv(speaker_gender_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80msのtime閾値のデータ作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_data_path = exp_dir / \"pause_ranges\" / \"rule_based\" / \"df_lab_attached_morph_pause_rule_based_detected_-30_0.08.pkl\"\n",
    "\n",
    "df = pd.read_pickle(pause_data_path)\n",
    "df = df[\"phoneme lab_filepath audiobook_id audiobook_id_int chapter_id chapter_id_int ruled_former_pause_-30_0.08 ruled_latter_pause_-30_0.08\".split()]\n",
    "df.rename(columns={\"ruled_former_pause_-30_0.08\": \"former_pause\", \"ruled_latter_pause_-30_0.08\": \"latter_pause\"}, inplace=True)\n",
    "df.rename(columns={\"phoneme\": \"morp\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== 話者 ==============\n",
    "def extract_speaker_label(audiobook_data: dict, speaker_df: pd.DataFrame):\n",
    "    # wavファイル名をキーにして、話者名を取得 (mp3は分割されているため、wavファイル名の方で結合する)\n",
    "    audio_names = []\n",
    "    wavs = []\n",
    "    for audio_name, audio_info in audiobook_data.items():\n",
    "        audio_names.append(audio_name)\n",
    "        wavs.append(Path(audio_info[\"wav\"]).name)\n",
    "    df_audio = pd.DataFrame({\"audiobook_id\": audio_names, \"wav\": wavs})\n",
    "    df_speaker_one = speaker_df.copy()\n",
    "    df_speaker_one[\"speaker\"] = df_speaker_one[\"speaker\"].apply(lambda x: x.split(\",\")[0]) # 複数の話者がいる場合、最初の話者を取得\n",
    "    df_speaker_one = df_speaker_one[[\"speaker\", \"wav\",\"book\"]]\n",
    "    display(df_speaker_one.head())\n",
    "    before = len(df_audio)\n",
    "    df_audio_speaker = pd.merge(df_audio, df_speaker_one, on=\"wav\", how=\"inner\")\n",
    "    after = len(df_audio_speaker)\n",
    "    assert before == after\n",
    "    df_audio_speaker.drop(columns=[\"wav\"], inplace=True)\n",
    "    return df_audio_speaker\n",
    "\n",
    "speaker_label_df = extract_speaker_label(audiobook_dict, df_speaker)\n",
    "display(speaker_label_df.head())\n",
    "\n",
    "df = pd.merge(df, speaker_label_df, on=\"audiobook_id\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audiobook_id, chapter_idをキーとする\n",
    "# morpを結合する\n",
    "df_morp = df[[\"audiobook_id\", \"chapter_id\", \"morp\"]].groupby([\"audiobook_id\", \"chapter_id\"]).agg(list)\n",
    "df_morp.sort_values([\"audiobook_id\", \"chapter_id\"], inplace=True)\n",
    "df_morp.reset_index(inplace=True)\n",
    "df_morp[\"morp\"] = df_morp[\"morp\"].apply(lambda x: \" \".join(x))\n",
    "print(df_morp.shape)\n",
    "display(df_morp.head())\n",
    "\n",
    "# morp以外はaudiobook_id, chapter_idをキーとした場合に一意に定まる\n",
    "df_other = df.drop(columns=[\"morp\"]).drop_duplicates()\n",
    "df_other.sort_values([\"audiobook_id\", \"chapter_id\"], inplace=True)\n",
    "df_other.reset_index(drop=True, inplace=True)\n",
    "print(df_other.shape)\n",
    "display(df_other.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morpとそれ以外を結合する\n",
    "df_merged = pd.merge(df_other, df_morp, on=[\"audiobook_id\", \"chapter_id\"])\n",
    "df_merged[\"text\"] = df_merged[\"morp\"].map(lambda x: x.replace(\" \", \"\").lstrip(\"silB\").rstrip(\"silE\"))\n",
    "df_merged.rename(columns={\"morp\": \"morp_join\"}, inplace=True)\n",
    "df_merged[\"morp_join_no_sil\"] = df_merged[\"morp_join\"].map(lambda x: x.lstrip(\"silB\").rstrip(\"silE\").strip())\n",
    "print(df_merged.shape)\n",
    "display(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "句点はどこかで削除されている。\n",
    "読点はのこっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = exp_dir / \"bert_traindata_pause_between_sentences_80ms_-30db.pkl\"\n",
    "df_merged.to_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100msのtime閾値のデータ作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_data_path = exp_dir / \"pause_ranges\" / \"rule_based\" / \"df_lab_attached_morph_pause_rule_based_detected_-30_0.1.pkl\"\n",
    "\n",
    "df = pd.read_pickle(pause_data_path)\n",
    "df = df[\"phoneme lab_filepath audiobook_id audiobook_id_int chapter_id chapter_id_int ruled_former_pause_-30_0.1 ruled_latter_pause_-30_0.1\".split()]\n",
    "df.rename(columns={\"ruled_former_pause_-30_0.1\": \"former_pause\", \"ruled_latter_pause_-30_0.1\": \"latter_pause\"}, inplace=True)\n",
    "df.rename(columns={\"phoneme\": \"morp\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== 話者 ==============\n",
    "def extract_speaker_label(audiobook_data: dict, speaker_df: pd.DataFrame):\n",
    "    # wavファイル名をキーにして、話者名を取得 (mp3は分割されているため、wavファイル名の方で結合する)\n",
    "    audio_names = []\n",
    "    wavs = []\n",
    "    for audio_name, audio_info in audiobook_data.items():\n",
    "        audio_names.append(audio_name)\n",
    "        wavs.append(Path(audio_info[\"wav\"]).name)\n",
    "    df_audio = pd.DataFrame({\"audiobook_id\": audio_names, \"wav\": wavs})\n",
    "    df_speaker_one = speaker_df.copy()\n",
    "    df_speaker_one[\"speaker\"] = df_speaker_one[\"speaker\"].apply(lambda x: x.split(\",\")[0]) # 複数の話者がいる場合、最初の話者を取得\n",
    "    df_speaker_one = df_speaker_one[[\"speaker\", \"wav\",\"book\"]]\n",
    "    display(df_speaker_one.head())\n",
    "    before = len(df_audio)\n",
    "    df_audio_speaker = pd.merge(df_audio, df_speaker_one, on=\"wav\", how=\"inner\")\n",
    "    after = len(df_audio_speaker)\n",
    "    assert before == after\n",
    "    df_audio_speaker.drop(columns=[\"wav\"], inplace=True)\n",
    "    return df_audio_speaker\n",
    "\n",
    "speaker_label_df = extract_speaker_label(audiobook_dict, df_speaker)\n",
    "display(speaker_label_df.head())\n",
    "\n",
    "df = pd.merge(df, speaker_label_df, on=\"audiobook_id\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audiobook_id, chapter_idをキーとする\n",
    "# morpを結合する\n",
    "df_morp = df[[\"audiobook_id\", \"chapter_id\", \"morp\"]].groupby([\"audiobook_id\", \"chapter_id\"]).agg(list)\n",
    "df_morp.sort_values([\"audiobook_id\", \"chapter_id\"], inplace=True)\n",
    "df_morp.reset_index(inplace=True)\n",
    "df_morp[\"morp\"] = df_morp[\"morp\"].apply(lambda x: \" \".join(x))\n",
    "print(df_morp.shape)\n",
    "display(df_morp.head())\n",
    "\n",
    "# morp以外はaudiobook_id, chapter_idをキーとした場合に一意に定まる\n",
    "df_other = df.drop(columns=[\"morp\"]).drop_duplicates()\n",
    "df_other.sort_values([\"audiobook_id\", \"chapter_id\"], inplace=True)\n",
    "df_other.reset_index(drop=True, inplace=True)\n",
    "print(df_other.shape)\n",
    "display(df_other.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morpとそれ以外を結合する\n",
    "df_merged = pd.merge(df_other, df_morp, on=[\"audiobook_id\", \"chapter_id\"])\n",
    "df_merged[\"text\"] = df_merged[\"morp\"].map(lambda x: x.replace(\" \", \"\").lstrip(\"silB\").rstrip(\"silE\"))\n",
    "df_merged.rename(columns={\"morp\": \"morp_join\"}, inplace=True)\n",
    "df_merged[\"morp_join_no_sil\"] = df_merged[\"morp_join\"].map(lambda x: x.lstrip(\"silB\").rstrip(\"silE\").strip())\n",
    "print(df_merged.shape)\n",
    "display(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = exp_dir / \"bert_traindata_pause_between_sentences_100ms_-30db.pkl\"\n",
    "df_merged.to_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ポーズ長の正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユニーク数をカウント\n",
    "print(\"80ms\")\n",
    "print(\"audiobook_name のユニーク数:\", df_merged[\"audiobook_id\"].nunique())\n",
    "print(\"speaker のユニーク数:\", df_merged[\"speaker\"].nunique())\n",
    "print(\"book のユニーク数:\", df_merged[\"book\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのカテゴリに含まれる数の最大値と最小値を確認(3未満だと分割した際に未知データになるため)\n",
    "print(f\"audiobook_count: {df_merged['audiobook_id'].value_counts().max()}〜{df_merged['audiobook_id'].value_counts().min()}\")\n",
    "print(f\"speaker_count: {df_merged['speaker'].value_counts().max()}〜{df_merged['speaker'].value_counts().min()}\")\n",
    "print(f\"book_count: {df_merged['book'].value_counts().max()}〜{df_merged['book'].value_counts().min()}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# スピーカーの可視化\n",
    "df_merged[\"speaker\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[0, 0], title=\"speaker\")\n",
    "\n",
    "# オーディオブックIDの可視化\n",
    "df_merged[\"audiobook_id\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[0, 1], title=\"audiobook_id\")\n",
    "\n",
    "# 本のタイトルの可視化\n",
    "df_merged[\"book\"].astype(\"category\").cat.codes.value_counts().sort_index().plot(kind=\"bar\", ax=axes[1, 1], title=\"book\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの一覧\n",
    "pause_time_threshold_mss = [80, 100]\n",
    "# preprocess_types = [\"none\", \"all\", \"audiobook\", \"narrative\", \"audiobook_narrative\", \"speaker\", \"book\"]\n",
    "preprocess_types = [\"none\", \"all\", \"audiobook\", \"speaker\", \"book\"]\n",
    "num_labels = [1, 2]\n",
    "\n",
    "# output dir\n",
    "output_dir = exp_dir / \"data_bert\"\n",
    "assert output_dir.exists()\n",
    "\n",
    "# それぞれのディレクトリを作成\n",
    "for pause_time_threshold_ms in pause_time_threshold_mss:\n",
    "    for preprocess_type in preprocess_types:\n",
    "        output_dir_each = output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type\n",
    "        output_dir_each.mkdir(parents=True, exist_ok=True)\n",
    "        print(output_dir_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def preprocess_data_between_sentence(df_input: pd.DataFrame, preprocess_type, num_labels) -> pd.DataFrame:\n",
    "    df = df_input.copy()\n",
    "    # テキストに句点がない場合は、句点を追加する\n",
    "    # df[\"text\"] = df[\"text\"].map(lambda x: x if x[-1] == \"。\" else x + \"。\") # 文章的に怪しいものもあるので、一旦コメントアウト\n",
    "\n",
    "    # テキストの結合, textについて次のtextと結合する。。次というのはchapter_idが1つ大きいもの\n",
    "    df['next_text'] = None  # 新しい列next_textを初期化\n",
    "\n",
    "    for i in range(len(df) - 1):\n",
    "        if df.loc[i, \"chapter_id_int\"] + 1 == df.loc[i + 1, \"chapter_id_int\"]:\n",
    "            df.loc[i, 'next_text'] = df.loc[i + 1, 'text']\n",
    "\n",
    "    # どれくらいの割合で次のテキストが見つかったか確認\n",
    "    print(\"次のテキストが見つかった割合: \", len(df[df[\"next_text\"].notnull()]),  \"/\" ,len(df))\n",
    "\n",
    "    # テキストを [SEP] で結合する\n",
    "    df[\"concat_text\"] = df[\"text\"] + \" [SEP] \" + df[\"next_text\"]\n",
    "    \n",
    "    # テキストの長さが0のものを除外 text=next_text=0のもの\n",
    "    print(f\"concat_textの長さが0のものを除外前のdf.shape: {df.shape}\")\n",
    "    df = df[df[\"concat_text\"].notnull()]\n",
    "    df = df[df[\"concat_text\"] != \" [SEP] \"]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"concat_textの長さが0のものを除外後のdf.shape: {df.shape}\")\n",
    "\n",
    "    # ラベルとするポーズの割り当て latter_pauseをラベルとする\n",
    "    df[\"label\"] = df[\"latter_pause\"].values\n",
    "\n",
    "    # ラベルの割合を確認 0 かいなか\n",
    "    print(\"ラベルの割合: \", len(df[df[\"label\"] <= 0.2]),  \"/\" ,len(df))\n",
    "\n",
    "    # 分類用のラベルを作成\n",
    "    df[\"label_class\"] = df[\"label\"].map(lambda x: 1 if x <= 0.2 else 0)\n",
    "\n",
    "    # 外れ値の割合を確認 0未満か10以上のもの\n",
    "    print(\"外れ値の割合: \", len(df[(df[\"label\"] < 0) | (df[\"label\"] > 10)]),  \"/\" ,len(df))\n",
    "\n",
    "    # 外れ値を除外\n",
    "    df = df[(df[\"label\"] >= 0) & (df[\"label\"] <= 10)]\n",
    "\n",
    "    # 必要な列のみに絞る\n",
    "    df = df[[\"audiobook_id\", \"chapter_id\", \"speaker\", \"book\", \"concat_text\", \"label\", \"label_class\"]]\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 表示\n",
    "    print(f\"はずれ値除去後のdf.shape: {df.shape}\")\n",
    "    \n",
    "    # audiobookのグループ数がthreshold未満のものを除外\n",
    "    threshold = 10\n",
    "    audiobook_counts = df[\"audiobook_id\"].value_counts()\n",
    "    print(f\"audiobookのグループ数が{threshold}未満のaudiobook_id: {audiobook_counts[audiobook_counts < threshold]}\")\n",
    "    audiobook_counts = audiobook_counts[audiobook_counts >= threshold]\n",
    "    df = df[df[\"audiobook_id\"].isin(audiobook_counts.index)]\n",
    "    \n",
    "    # train, val, testに分割する関数を定義\n",
    "    def train_val_test_split(df: pd.DataFrame, test_size: float = 0.2, val_size: float = 0.25) -> pd.DataFrame:\n",
    "        \"\"\"train_test_splitを行って、train, val, testの列を追加する関数\"\"\"\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        # ここではaudiobook_idをstratifyの基準として使用\n",
    "        stratify_col = df[\"audiobook_id\"]\n",
    "        df_train, df_test = train_test_split(df, test_size=test_size, random_state=42, stratify=stratify_col)\n",
    "        # stratify_colをdf_trainに基づいて再計算\n",
    "        stratify_col_train = df_train[\"audiobook_id\"]\n",
    "        df_train, df_val = train_test_split(df_train, test_size=val_size, random_state=42, stratify=stratify_col_train)\n",
    "        df_train[\"train_val_test\"] = \"train\"\n",
    "        df_val[\"train_val_test\"] = \"val\"\n",
    "        df_test[\"train_val_test\"] = \"test\"\n",
    "        assert len(set(df_train.index) & set(df_val.index)) == 0, \"trainとvalに共通のインデックスが存在します\"\n",
    "        assert len(set(df_train.index) & set(df_test.index)) == 0, \"trainとtestに共通のインデックスが存在します\"\n",
    "        assert len(set(df_val.index) & set(df_test.index)) == 0, \"valとtestに共通のインデックスが存在します\"\n",
    "        return pd.concat([df_train, df_val, df_test])\n",
    "\n",
    "    # train, val, testに分割\n",
    "    df = train_val_test_split(df)\n",
    "    \n",
    "    # train, val, testごとにグループ数を計測する関数\n",
    "    def count_groups_in_train_val_test(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"train, val, testごとにグループ数を計測する関数\"\"\"\n",
    "        nunique_audiobook = df.groupby(\"train_val_test\")[\"audiobook_id\"].nunique()\n",
    "        nunique_speaker = df.groupby(\"train_val_test\")[\"speaker\"].nunique()\n",
    "        nunique_book = df.groupby(\"train_val_test\")[\"book\"].nunique()\n",
    "        group_counts = pd.DataFrame({\n",
    "            \"audiobook\": nunique_audiobook,\n",
    "            \"speaker\": nunique_speaker,\n",
    "            \"book\": nunique_book\n",
    "        })\n",
    "        return group_counts\n",
    "\n",
    "    # train, val, testごとにグループ数を計測して表示\n",
    "    group_counts = count_groups_in_train_val_test(df)\n",
    "    print(group_counts)\n",
    "    \n",
    "    # 正規化\n",
    "    # 訓練データでmeanとvarを計算\n",
    "    df_train = df[df[\"train_val_test\"] == \"train\"]\n",
    "    mean_all = df_train[\"label\"].mean()\n",
    "    var_all = df_train[\"label\"].var()\n",
    "    df[\"mean_all\"] = mean_all\n",
    "    df[\"var_all\"] = var_all\n",
    "    print(f\"mean_all: {mean_all}\")\n",
    "    print(f\"var_all: {var_all}\")\n",
    "    \n",
    "    # audiobook_idごとに訓練データのmean, varを計算して、mean_audiobook_id, var_audiobook_idとして結合する\n",
    "    df_mean = df_train.groupby(\"audiobook_id\")[\"label\"].mean().reset_index(name=\"mean_audiobook_id\")\n",
    "    df_var = df_train.groupby(\"audiobook_id\")[\"label\"].var().reset_index(name=\"var_audiobook_id\")\n",
    "    df = pd.merge(df, df_mean, on=\"audiobook_id\", how=\"left\")\n",
    "    df = pd.merge(df, df_var, on=\"audiobook_id\", how=\"left\")\n",
    "\n",
    "    # speakerごとに訓練データのmean, varを計算して、mean_speaker, var_speakerとして結合する\n",
    "    df_mean = df_train.groupby(\"speaker\")[\"label\"].mean().reset_index(name=\"mean_speaker\")\n",
    "    df_var = df_train.groupby(\"speaker\")[\"label\"].var().reset_index(name=\"var_speaker\")\n",
    "    df = pd.merge(df, df_mean, on=\"speaker\", how=\"left\")\n",
    "    df = pd.merge(df, df_var, on=\"speaker\", how=\"left\")\n",
    "    \n",
    "    # bookごとに訓練データのmean, varを計算して、mean_book, var_bookとして結合する\n",
    "    df_mean = df_train.groupby(\"book\")[\"label\"].mean().reset_index(name=\"mean_book\")\n",
    "    df_var = df_train.groupby(\"book\")[\"label\"].var().reset_index(name=\"var_book\")\n",
    "    df = pd.merge(df, df_mean, on=\"book\", how=\"left\")\n",
    "    df = pd.merge(df, df_var, on=\"book\", how=\"left\")\n",
    "    \n",
    "    print(f\"df.shape: {df.shape}\")\n",
    "    print(f\"分類用のラベルの割合: {len(df[df['label_class'] == 1])}\", \"/\", f\"{len(df)}\")\n",
    "    # display(df.head())\n",
    "    \n",
    "    # 正規化とでーたの選別\n",
    "    if preprocess_type == \"none\":\n",
    "        # df[\"means\"] = df[\"mean_all\"]\n",
    "        # df[\"vars\"] = df[\"var_all\"]\n",
    "        df[\"means\"] = 0\n",
    "        df[\"vars\"] = 1\n",
    "    elif preprocess_type == \"all\":\n",
    "        df[\"label\"] = (df[\"label\"] - df[\"mean_all\"]) / np.sqrt(df[\"var_all\"])\n",
    "        df[\"means\"] = df[\"mean_all\"]\n",
    "        df[\"vars\"] = df[\"var_all\"]\n",
    "    elif preprocess_type == \"audiobook\":\n",
    "        df[\"label\"] = (df[\"label\"] - df[\"mean_audiobook_id\"]) / np.sqrt(df[\"var_audiobook_id\"])\n",
    "        df[\"means\"] = df[\"mean_audiobook_id\"]\n",
    "        df[\"vars\"] = df[\"var_audiobook_id\"]\n",
    "    elif preprocess_type == \"speaker\":\n",
    "        df[\"label\"] = (df[\"label\"] - df[\"mean_speaker\"]) / np.sqrt(df[\"var_speaker\"])\n",
    "        df[\"means\"] = df[\"mean_speaker\"]\n",
    "        df[\"vars\"] = df[\"var_speaker\"]\n",
    "    elif preprocess_type == \"book\":\n",
    "        df[\"label\"] = (df[\"label\"] - df[\"mean_book\"]) / np.sqrt(df[\"var_book\"])\n",
    "        df[\"means\"] = df[\"mean_book\"]\n",
    "        df[\"vars\"] = df[\"var_book\"]\n",
    "    else:\n",
    "        raise ValueError(\"preprocess_type is invalid\")\n",
    "    \n",
    "    \n",
    "    # 埋め込み用のIDを作成\n",
    "    df[\"id_audiobook\"] = df[\"audiobook_id\"].astype(\"category\").cat.codes\n",
    "    df[\"id_speaker\"] = df[\"speaker\"].astype(\"category\").cat.codes\n",
    "    df[\"id_book\"] = df[\"book\"].astype(\"category\").cat.codes\n",
    "    df[\"id_none\"] = 0\n",
    "    df[\"id_all\"] = 0\n",
    "    \n",
    "    # ID変換時の対応表を保存\n",
    "    id_audiobook_dict = dict(enumerate(df[\"audiobook_id\"].astype(\"category\").cat.categories))\n",
    "    id_speaker_dict = dict(enumerate(df[\"speaker\"].astype(\"category\").cat.categories))\n",
    "    id_book_dict = dict(enumerate(df[\"book\"].astype(\"category\").cat.categories))\n",
    "    id_dict = {\"audiobook\": id_audiobook_dict, \"speaker\": id_speaker_dict, \"book\": id_book_dict}\n",
    "    # カレントディレクトリにcsvで保存\n",
    "    for key, value in id_dict.items():\n",
    "        pd.DataFrame(value.items(), columns=[\"id\", key]).to_csv(f\"id_dict/between_sentence/id_{key}.csv\", index=False)\n",
    "    \n",
    "    df = df[[\"audiobook_id\", \"chapter_id\", \"concat_text\", \"label\", \"label_class\", \"means\", \"vars\", \"id_audiobook\", \"id_speaker\", \"id_book\", \"id_none\", \"id_all\"]]\n",
    "    df.rename(columns={\"concat_text\": \"texts\"}, inplace=True)\n",
    "    if num_labels == 1:\n",
    "        df = df[[\"audiobook_id\", \"chapter_id\", \"texts\", \"label\", \"means\", \"vars\", \"id_audiobook\", \"id_speaker\", \"id_book\", \"id_none\", \"id_all\"]]\n",
    "        df.rename(columns={\"label\": \"labels\"}, inplace=True)\n",
    "    elif num_labels == 2:\n",
    "        df = df[[\"audiobook_id\", \"chapter_id\", \"texts\", \"label_class\", \"means\", \"vars\", \"id_audiobook\", \"id_speaker\", \"id_book\", \"id_none\", \"id_all\"]]\n",
    "        df.rename(columns={\"label_class\": \"labels\"}, inplace=True)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"df.shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80msの場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正規化方法を考える\n",
    "  - none: 正規化しない\n",
    "  - all: 全体のデータを使って標準化\n",
    "  - audiobook: オーディオブックごとに標準化\n",
    "  - (speaker: 話者ごとに標準化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle( exp_dir / \"bert_traindata_pause_between_sentences_80ms_-30db.pkl\")\n",
    "preprocess_data_between_sentence(df, \"none\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規化する前に、テキストの結合と、ポーズの割り当てと、外れ値除去を行う, 句点がなぜか削除されてしまっているので付け足す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_80ms = pd.read_pickle( exp_dir / \"bert_traindata_pause_between_sentences_80ms_-30db.pkl\")\n",
    "df_train_100ms = pd.read_pickle( exp_dir / \"bert_traindata_pause_between_sentences_100ms_-30db.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pause_time_threshold_ms in pause_time_threshold_mss:\n",
    "    for preprocess_type in preprocess_types:\n",
    "        for num_label in num_labels:\n",
    "            print(f\"pause_time_threshold_ms: {pause_time_threshold_ms}, preprocess_type: {preprocess_type}\", f\"num_label: {num_label}\")\n",
    "            if pause_time_threshold_ms == 80:\n",
    "                df_train = df_train_80ms.copy()\n",
    "            elif pause_time_threshold_ms == 100:\n",
    "                df_train = df_train_100ms.copy()\n",
    "            else:\n",
    "                raise ValueError(\"pause_time_threshold_msが不正です\")\n",
    "            df_train_preprocessed = preprocess_data_between_sentence(df_train, preprocess_type, num_label)\n",
    "            df_train_preprocessed.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_BetweenSentences_{num_label}label.pkl\")\n",
    "            # 分割\n",
    "            test_size = 0.2\n",
    "            val_size = 0.25\n",
    "            train_val_df, test_df = train_test_split(df_train_preprocessed, test_size=test_size, random_state=42)\n",
    "            train_df, val_df = train_test_split(train_val_df, test_size=val_size, random_state=42)\n",
    "            train_df.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_BetweenSentences_{num_label}label_train.pkl\")\n",
    "            val_df.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_BetweenSentences_{num_label}label_val.pkl\")\n",
    "            test_df.to_pickle(output_dir / f\"{pause_time_threshold_ms}ms\" / preprocess_type / f\"bert_traindata_BetweenSentences_{num_label}label_test.pkl\")\n",
    "\n",
    "            print(\"train_df.shape: \", train_df.shape, \"val_df.shape: \", val_df.shape, \"test_df.shape: \", test_df.shape)\n",
    "            print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下は未実行(2024/02/03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化しない\n",
    "df[\"former_pause_none\"] = df[\"former_pause\"]\n",
    "df[\"latter_pause_none\"] = df[\"latter_pause\"]\n",
    "\n",
    "# 全体のポーズ長の平均と分散を計算する\n",
    "# ハズレ値を除外する\n",
    "mask = (df[\"former_pause\"] < 30) & (df[\"latter_pause\"] < 30)\n",
    "mean_former_pause = df[\"former_pause_none\"][mask].mean()\n",
    "mean_latter_pause = df[\"latter_pause_none\"][mask].mean()\n",
    "std_former_pause = df[\"former_pause_none\"][mask].std()\n",
    "std_latter_pause = df[\"latter_pause_none\"][mask].std()\n",
    "print(f\"mean_former_pause: {mean_former_pause}\")\n",
    "print(f\"mean_latter_pause: {mean_latter_pause}\")\n",
    "print(f\"std_former_pause: {std_former_pause}\")\n",
    "print(f\"std_latter_pause: {std_latter_pause}\")\n",
    "\n",
    "# 全体のポーズ長の平均と分散で標準化する\n",
    "df[\"former_pause_all\"] = df[\"former_pause\"].map(lambda x: (x - mean_former_pause) / std_former_pause)\n",
    "df[\"latter_pause_all\"] = df[\"latter_pause\"].map(lambda x: (x - mean_latter_pause) / std_latter_pause)\n",
    "\n",
    "# audiobook_idごとにポーズ長の平均と分散を計算する\n",
    "df_audiobook_mean = df[mask].groupby(\"audiobook_id\").agg({\"former_pause\": \"mean\", \"latter_pause\": \"mean\"})\n",
    "df_audiobook_std = df[mask].groupby(\"audiobook_id\").agg({\"former_pause\": \"std\", \"latter_pause\": \"std\"})\n",
    "df_audiobook_mean.rename(columns={\"former_pause\": \"mean_former_pause_audiobook\", \"latter_pause\": \"mean_latter_pause_audiobook\"}, inplace=True)\n",
    "df_audiobook_std.rename(columns={\"former_pause\": \"std_former_pause_audiobook\", \"latter_pause\": \"std_latter_pause_audiobook\"}, inplace=True)\n",
    "\n",
    "# audiobook_idごとにポーズ長の平均と分散で標準化する\n",
    "df = pd.merge(df, df_audiobook_mean, on=\"audiobook_id\")\n",
    "df = pd.merge(df, df_audiobook_std, on=\"audiobook_id\")\n",
    "df[\"former_pause_audiobook\"] = df.apply(lambda x: (x[\"former_pause\"] - x[\"mean_former_pause_audiobook\"]) / x[\"std_former_pause_audiobook\"], axis=1)\n",
    "df[\"latter_pause_audiobook\"] = df.apply(lambda x: (x[\"latter_pause\"] - x[\"mean_latter_pause_audiobook\"]) / x[\"std_latter_pause_audiobook\"], axis=1)\n",
    "df.drop(columns=[\"mean_former_pause_audiobook\", \"mean_latter_pause_audiobook\", \"std_former_pause_audiobook\", \"std_latter_pause_audiobook\"], inplace=True)\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(exp_dir / \"bert_traindata_pause_between_sentences_80ms_-30db_normalized.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100msの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle( exp_dir / \"bert_traindata_pause_between_sentences_100ms_-30db.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化しない\n",
    "df[\"former_pause_none\"] = df[\"former_pause\"]\n",
    "df[\"latter_pause_none\"] = df[\"latter_pause\"]\n",
    "\n",
    "# 全体のポーズ長の平均と分散を計算する\n",
    "# ハズレ値を除外する\n",
    "mask = (df[\"former_pause\"] < 30) & (df[\"latter_pause\"] < 30)\n",
    "mean_former_pause = df[\"former_pause_none\"][mask].mean()\n",
    "mean_latter_pause = df[\"latter_pause_none\"][mask].mean()\n",
    "std_former_pause = df[\"former_pause_none\"][mask].std()\n",
    "std_latter_pause = df[\"latter_pause_none\"][mask].std()\n",
    "print(f\"mean_former_pause: {mean_former_pause}\")\n",
    "print(f\"mean_latter_pause: {mean_latter_pause}\")\n",
    "print(f\"std_former_pause: {std_former_pause}\")\n",
    "print(f\"std_latter_pause: {std_latter_pause}\")\n",
    "\n",
    "# 全体のポーズ長の平均と分散で標準化する\n",
    "df[\"former_pause_all\"] = df[\"former_pause\"].map(lambda x: (x - mean_former_pause) / std_former_pause)\n",
    "df[\"latter_pause_all\"] = df[\"latter_pause\"].map(lambda x: (x - mean_latter_pause) / std_latter_pause)\n",
    "\n",
    "# audiobook_idごとにポーズ長の平均と分散を計算する\n",
    "df_audiobook_mean = df[mask].groupby(\"audiobook_id\").agg({\"former_pause\": \"mean\", \"latter_pause\": \"mean\"})\n",
    "df_audiobook_std = df[mask].groupby(\"audiobook_id\").agg({\"former_pause\": \"std\", \"latter_pause\": \"std\"})\n",
    "df_audiobook_mean.rename(columns={\"former_pause\": \"mean_former_pause_audiobook\", \"latter_pause\": \"mean_latter_pause_audiobook\"}, inplace=True)\n",
    "df_audiobook_std.rename(columns={\"former_pause\": \"std_former_pause_audiobook\", \"latter_pause\": \"std_latter_pause_audiobook\"}, inplace=True)\n",
    "\n",
    "# audiobook_idごとにポーズ長の平均と分散で標準化する\n",
    "df = pd.merge(df, df_audiobook_mean, on=\"audiobook_id\")\n",
    "df = pd.merge(df, df_audiobook_std, on=\"audiobook_id\")\n",
    "df[\"former_pause_audiobook\"] = df.apply(lambda x: (x[\"former_pause\"] - x[\"mean_former_pause_audiobook\"]) / x[\"std_former_pause_audiobook\"], axis=1)\n",
    "df[\"latter_pause_audiobook\"] = df.apply(lambda x: (x[\"latter_pause\"] - x[\"mean_latter_pause_audiobook\"]) / x[\"std_latter_pause_audiobook\"], axis=1)\n",
    "df.drop(columns=[\"mean_former_pause_audiobook\", \"mean_latter_pause_audiobook\", \"std_former_pause_audiobook\", \"std_latter_pause_audiobook\"], inplace=True)\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(exp_dir / \"bert_traindata_pause_between_sentences_100ms_-30db_normalized.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正規化前後の分布の比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80msの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle( exp_dir / \"bert_traindata_pause_between_sentences_80ms_-30db_normalized.pkl\")\n",
    "display(df.describe())\n",
    "display(df.head())\n",
    "\n",
    "# ハズレ値を除外する\n",
    "mask = (df[\"former_pause\"] < 30) & (df[\"latter_pause\"] < 30)\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化前\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Pause length distribution not normalized (80ms)\", fontsize=20)\n",
    "plt.hist(df[\"former_pause_none\"], bins=100)\n",
    "# 平均と分散を計算する\n",
    "mean_former_pause = df[\"former_pause_none\"].mean()\n",
    "std_former_pause = df[\"former_pause_none\"].std()\n",
    "print(f\"mean_former_pause: {mean_former_pause}\")\n",
    "print(f\"std_former_pause: {std_former_pause}\")\n",
    "plt.axvline(mean_former_pause, color=\"red\", linestyle=\"dashed\", label=f\"mean: {mean_former_pause:.2f}\")\n",
    "plt.axvline(mean_former_pause + std_former_pause, color=\"green\", linestyle=\"dashed\", label=f\"mean + std: {mean_former_pause + std_former_pause:.2f}\")\n",
    "plt.axvline(mean_former_pause - std_former_pause, color=\"green\", linestyle=\"dashed\", label=f\"mean - std: {mean_former_pause - std_former_pause:.2f}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.suptitle(\"Pause Length Between Sentences Distributions 80ms\", fontsize=20)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"normalized by all\", fontsize=20)\n",
    "plt.hist(df[\"former_pause_all\"], bins=100, color=\"skyblue\", edgecolor=\"black\")\n",
    "# plt.xlim([-30, 30])\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"normalized by audiobook\", fontsize=20)\n",
    "plt.hist(df[\"former_pause_audiobook\"], bins=100, color=\"lightgreen\", edgecolor=\"black\")\n",
    "# plt.xlim([-30, 30])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100msの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle( exp_dir / \"bert_traindata_pause_between_sentences_100ms_-30db_normalized.pkl\")\n",
    "display(df.describe())\n",
    "\n",
    "# ハズレ値を除外する\n",
    "mask = (df[\"former_pause\"] < 30) & (df[\"latter_pause\"] < 30)\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化前\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Pause length distribution not normalized (100ms)\", fontsize=20)\n",
    "plt.hist(df[\"former_pause_none\"], bins=100)\n",
    "# 平均と分散を計算する\n",
    "mean_former_pause = df[\"former_pause_none\"].mean()\n",
    "std_former_pause = df[\"former_pause_none\"].std()\n",
    "print(f\"mean_former_pause: {mean_former_pause}\")\n",
    "print(f\"std_former_pause: {std_former_pause}\")\n",
    "plt.axvline(mean_former_pause, color=\"red\", linestyle=\"dashed\", label=f\"mean: {mean_former_pause:.2f}\")\n",
    "plt.axvline(mean_former_pause + std_former_pause, color=\"green\", linestyle=\"dashed\", label=f\"mean + std: {mean_former_pause + std_former_pause:.2f}\")\n",
    "plt.axvline(mean_former_pause - std_former_pause, color=\"green\", linestyle=\"dashed\", label=f\"mean - std: {mean_former_pause - std_former_pause:.2f}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.suptitle(\"Pause Length Between Sentences Distributions 100ms\", fontsize=20)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"normalized by all\", fontsize=20)\n",
    "plt.hist(df[\"former_pause_all\"], bins=100, color=\"skyblue\", edgecolor=\"black\")\n",
    "# plt.xlim([-30, 30])\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"normalized by audiobook\", fontsize=20)\n",
    "plt.hist(df[\"former_pause_audiobook\"], bins=100, color=\"lightgreen\", edgecolor=\"black\")\n",
    "# plt.xlim([-30, 30])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80msと100msはほぼ同じ分布になっている。\n",
    "=> これは、閾値が影響するのは silBとsilEのみであるためと考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopenjtalk_julius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
